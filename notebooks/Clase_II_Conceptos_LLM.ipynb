{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgevatschnaider/IA-Teoria-Practica/blob/main/notebooks/Clase_II_Conceptos_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8rYIQftS3hZ9",
        "outputId": "59f1aea5-4780-4024-91ee-f65567bf0493"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "  <meta charset=\"UTF-8\">\n",
              "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "  <title>Clase II – Conceptos LLM</title>\n",
              "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
              "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
              "  <style>\n",
              "    /* ----------  Variables y tema ---------- */\n",
              "    :root{\n",
              "      --bg-primary:linear-gradient(135deg,#667eea 0%,#764ba2 100%);\n",
              "      --bg-secondary:#ffffff;\n",
              "      --bg-tertiary:#f8fafc;\n",
              "      --text-primary:#1e293b;\n",
              "      --text-secondary:#64748b;\n",
              "      --text-accent:#3b82f6;\n",
              "      --border-color:#e2e8f0;\n",
              "      --shadow-sm:0 1px 2px 0 rgb(0 0 0 / .05);\n",
              "      --shadow-md:0 4px 6px -1px rgb(0 0 0 / .1),0 2px 4px -2px rgb(0 0 0 / .1);\n",
              "      --shadow-lg:0 10px 15px -3px rgb(0 0 0 / .1),0 4px 6px -4px rgb(0 0 0 / .1);\n",
              "      --shadow-xl:0 20px 25px -5px rgb(0 0 0 / .1),0 8px 10px -6px rgb(0 0 0 / .1);\n",
              "\n",
              "      --color-blue:#3b82f6;\n",
              "      --color-emerald:#10b981;\n",
              "      --color-purple:#8b5cf6;\n",
              "      --color-rose:#f43f5e;\n",
              "      --color-amber:#f59e0b;\n",
              "    }\n",
              "    [data-theme=\"dark\"]{\n",
              "      --bg-primary:linear-gradient(135deg,#1e293b 0%,#334155 100%);\n",
              "      --bg-secondary:#0f172a;\n",
              "      --bg-tertiary:#1e293b;\n",
              "      --text-primary:#f1f5f9;\n",
              "      --text-secondary:#94a3b8;\n",
              "      --text-accent:#60a5fa;\n",
              "      --border-color:#334155;\n",
              "      --shadow-sm:0 1px 2px 0 rgb(0 0 0 / .3);\n",
              "      --shadow-md:0 4px 6px -1px rgb(0 0 0 / .3),0 2px 4px -2px rgb(0 0 0 / .3);\n",
              "      --shadow-lg:0 10px 15px -3px rgb(0 0 0 / .3),0 4px 6px -4px rgb(0 0 0 / .3);\n",
              "      --shadow-xl:0 20px 25px -5px rgb(0 0 0 / .3),0 8px 10px -6px rgb(0 0 0 / .3);\n",
              "    }\n",
              "    *{margin:0;padding:0;box-sizing:border-box;}\n",
              "    body{\n",
              "      font-family:'Inter',-apple-system,BlinkMacSystemFont,sans-serif;\n",
              "      line-height:1.7;\n",
              "      background:var(--bg-primary);\n",
              "      color:var(--text-primary);\n",
              "      min-height:100vh;\n",
              "      overflow-x:hidden;\n",
              "    }\n",
              "    .container{max-width:1200px;margin:0 auto;padding:2rem;position:relative;}\n",
              "\n",
              "    /* ----------  Cabecera ---------- */\n",
              "    .header{text-align:center;margin-bottom:3rem;position:relative;z-index:10;}\n",
              "    .header::before{\n",
              "      content:'';position:absolute;top:-50px;left:50%;transform:translateX(-50%);\n",
              "      width:100px;height:100px;background:var(--color-blue);border-radius:50%;opacity:.1;\n",
              "      animation:pulse 2s ease-in-out infinite;\n",
              "    }\n",
              "    @keyframes pulse{0%,100%{transform:translateX(-50%) scale(1);opacity:.1;}50%{transform:translateX(-50%) scale(1.1);opacity:.2;}}\n",
              "    .main-title{\n",
              "      font-size:clamp(2.5rem,5vw,4rem);font-weight:700;\n",
              "      background:linear-gradient(135deg,var(--color-blue),var(--color-purple));\n",
              "      -webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;\n",
              "      margin-bottom:1rem;position:relative;\n",
              "    }\n",
              "    .subtitle{font-size:1.25rem;color:var(--text-secondary);font-weight:400;max-width:680px;margin:0 auto 1.5rem auto;}\n",
              "\n",
              "    .author-credit{display:flex;align-items:center;justify-content:center;gap:.5rem;font-size:1rem;color:var(--text-secondary);\n",
              "      background:var(--bg-secondary);padding:.75rem 1.5rem;border-radius:2rem;border:1px solid var(--border-color);\n",
              "      box-shadow:var(--shadow-sm);max-width:fit-content;margin:0 auto;transition:all .3s ease;}\n",
              "    .author-credit:hover{transform:translateY(-2px);box-shadow:var(--shadow-md);border-color:var(--text-accent);}\n",
              "    .author-credit i{color:var(--text-accent);font-size:.9rem;}\n",
              "    .author-credit strong{color:var(--text-primary);font-weight:600;}\n",
              "\n",
              "    /* ----------  Botón tema ---------- */\n",
              "    .theme-toggle{\n",
              "      position:fixed;top:2rem;right:2rem;width:60px;height:60px;border:none;border-radius:50%;\n",
              "      background:var(--bg-secondary);box-shadow:var(--shadow-lg);cursor:pointer;\n",
              "      display:flex;align-items:center;justify-content:center;font-size:1.5rem;color:var(--text-primary);\n",
              "      transition:all .3s cubic-bezier(.4,0,.2,1);z-index:1000;backdrop-filter:blur(10px);\n",
              "    }\n",
              "    .theme-toggle:hover{transform:translateY(-2px) scale(1.05);box-shadow:var(--shadow-xl);}\n",
              "    .theme-toggle:active{transform:translateY(0) scale(.95);}\n",
              "\n",
              "    /* ----------  Secciones ---------- */\n",
              "    .section-card{background:var(--bg-secondary);border-radius:1rem;margin-bottom:1.5rem;box-shadow:var(--shadow-md);\n",
              "      overflow:hidden;transition:all .3s cubic-bezier(.4,0,.2,1);border:1px solid var(--border-color);}\n",
              "    .section-card:hover{transform:translateY(-4px);box-shadow:var(--shadow-xl);}\n",
              "    .section-header{background:none;border:none;width:100%;padding:1.5rem 2rem;text-align:left;cursor:pointer;\n",
              "      display:flex;align-items:center;justify-content:space-between;transition:all .3s ease;position:relative;overflow:hidden;}\n",
              "    .section-header::before{content:'';position:absolute;top:0;left:-100%;width:100%;height:100%;\n",
              "      background:linear-gradient(90deg,transparent,rgba(255,255,255,.1),transparent);transition:left .5s ease;}\n",
              "    .section-header:hover::before{left:100%;}\n",
              "    .section-title{font-size:1.5rem;font-weight:600;color:var(--text-primary);display:flex;align-items:center;gap:.75rem;}\n",
              "    .section-icon{width:24px;height:24px;color:var(--text-accent);}\n",
              "    .expand-icon{font-size:1.25rem;color:var(--text-secondary);transition:transform .3s cubic-bezier(.4,0,.2,1);}\n",
              "    .section-header[aria-expanded=\"true\"] .expand-icon{transform:rotate(180deg);}\n",
              "    .section-content{max-height:0;overflow:hidden;transition:max-height .4s cubic-bezier(.4,0,.2,1),padding .4s cubic-bezier(.4,0,.2,1);\n",
              "      background:var(--bg-tertiary);}\n",
              "    .section-content.expanded{max-height:2000px;padding:2rem;}\n",
              "    .section-content p{margin-bottom:1.25rem;line-height:1.8;color:var(--text-primary);}\n",
              "    .section-content ul{margin:1.25rem 0;padding-left:1.5rem;}\n",
              "    .section-content li{margin-bottom:.75rem;color:var(--text-primary);}\n",
              "    .section-content li::marker{color:var(--text-accent);}\n",
              "\n",
              "    /* ----------  Índice ---------- */\n",
              "    .index-item{background:var(--bg-secondary);border-radius:.75rem;margin:1rem 0;border:1px solid var(--border-color);overflow:hidden;}\n",
              "    .index-header{padding:1rem 1.5rem;background:linear-gradient(135deg,var(--color-emerald),var(--color-blue));\n",
              "      color:#fff;font-weight:500;display:flex;align-items:center;justify-content:space-between;cursor:pointer;transition:all .3s ease;}\n",
              "    .index-header:hover{background:linear-gradient(135deg,#059669,#2563eb);}\n",
              "    .index-content{padding:1.5rem;background:var(--bg-tertiary);border-top:1px solid var(--border-color);}\n",
              "    .index-content p{margin-bottom:.75rem;font-size:.95rem;color:var(--text-secondary);}\n",
              "\n",
              "    /* ----------  Efectos ---------- */\n",
              "    .floating-shapes{position:fixed;top:0;left:0;width:100%;height:100%;pointer-events:none;z-index:-1;overflow:hidden;}\n",
              "    .shape{position:absolute;background:var(--color-blue);border-radius:50%;opacity:.05;animation:float 6s ease-in-out infinite;}\n",
              "    .shape:nth-child(1){width:80px;height:80px;top:20%;left:10%;animation-delay:0s;}\n",
              "    .shape:nth-child(2){width:120px;height:120px;top:60%;right:15%;animation-delay:2s;background:var(--color-purple);}\n",
              "    .shape:nth-child(3){width:60px;height:60px;bottom:20%;left:20%;animation-delay:4s;background:var(--color-emerald);}\n",
              "    @keyframes float{0%,100%{transform:translateY(0) rotate(0deg);}33%{transform:translateY(-20px) rotate(120deg);}66%{transform:translateY(10px) rotate(240deg);}}\n",
              "\n",
              "    /* ----------  Responsive ---------- */\n",
              "    @media(max-width:768px){\n",
              "      .container{padding:1rem;}\n",
              "      .section-header{padding:1.25rem 1.5rem;}\n",
              "      .section-content.expanded{padding:1.5rem;}\n",
              "      .theme-toggle{width:50px;height:50px;top:1rem;right:1rem;font-size:1.25rem;}\n",
              "      .main-title{font-size:2.5rem;}\n",
              "    }\n",
              "\n",
              "    /* ----------  Animaciones ---------- */\n",
              "    .fade-in{opacity:0;transform:translateY(20px);animation:fadeInUp .6s ease forwards;}\n",
              "    @keyframes fadeInUp{to{opacity:1;transform:translateY(0);} }\n",
              "  </style>\n",
              "</head>\n",
              "<body>\n",
              "  <div class=\"floating-shapes\">\n",
              "    <div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div>\n",
              "  </div>\n",
              "\n",
              "  <button class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema\">\n",
              "    <i class=\"fas fa-moon\" id=\"theme-icon\"></i>\n",
              "  </button>\n",
              "\n",
              "  <div class=\"container\">\n",
              "    <header class=\"header\">\n",
              "      <h1 class=\"main-title fade-in\">Conceptos LLM</h1>\n",
              "      <p class=\"subtitle fade-in\">Clase II – Funcionamiento interno de los modelos de lenguaje de gran escala</p>\n",
              "      <div class=\"author-credit fade-in\">\n",
              "        <i class=\"fas fa-user-edit\"></i><span>Elaborado por <strong>Sergio Gevatschnaider</strong></span>\n",
              "      </div>\n",
              "    </header>\n",
              "\n",
              "    <!-- Introducción -->\n",
              "    <div class=\"section-card fade-in\">\n",
              "      <button class=\"section-header\" onclick=\"toggleSection('intro')\" aria-expanded=\"false\">\n",
              "        <div class=\"section-title\"><i class=\"fas fa-rocket section-icon\"></i>Introducción</div>\n",
              "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "      </button>\n",
              "      <div class=\"section-content\" id=\"intro\">\n",
              "        <p>En los últimos años, los <strong>modelos de lenguaje de gran escala (LLMs)</strong>, como GPT, BERT o PaLM, han transformado la forma en que interactuamos con la inteligencia artificial. Capaces de redactar textos, traducir idiomas, razonar lógicamente e incluso programar, estos sistemas parecen “comprender” el lenguaje humano con asombrosa <strong>facilidad</strong>. Pero ¿qué ocurre realmente dentro de estas redes neuronales cuando les planteamos una pregunta?</p>\n",
              "        <p>Esta clase se propone revelar el engranaje interno de los LLMs: desde el <em>pre‑entrenamiento</em> sobre corpus masivos de texto hasta la generación de una respuesta <em>token por token</em>. Comprenderemos los principios del <strong>Transformer</strong>, el recorrido de un <em>prompt</em> por las etapas de tokenización, embeddings y auto‑atención, y los retos éticos y computacionales que acompañan a estos avances. Más que una exposición teórica, el objetivo es dotarte de criterios críticos para aprovechar —y cuestionar— las capacidades de la IA lingüística actual.</p>\n",
              "      </div>\n",
              "    </div>\n",
              "\n",
              "    <!-- Objetivo -->\n",
              "    <div class=\"section-card fade-in\">\n",
              "      <button class=\"section-header\" onclick=\"toggleSection('objetivo')\" aria-expanded=\"false\">\n",
              "        <div class=\"section-title\"><i class=\"fas fa-target section-icon\"></i>Objetivo</div>\n",
              "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "      </button>\n",
              "      <div class=\"section-content\" id=\"objetivo\">\n",
              "        <p>Brindar a los estudiantes una comprensión profunda y crítica del funcionamiento de los modelos de lenguaje de gran escala, analizando sus componentes esenciales —pre‑entrenamiento, arquitectura Transformer, tokenización, embeddings y flujo de generación— para que puedan:</p>\n",
              "        <ul>\n",
              "          <li><strong>Explicar</strong> cómo un LLM procesa, “comprende” y produce lenguaje natural.</li>\n",
              "          <li><strong>Evaluar</strong> las ventajas y limitaciones de los LLMs en diferentes aplicaciones de IA.</li>\n",
              "          <li><strong>Diseñar</strong> prompts y flujos de <em>fine‑tuning</em> con fundamento técnico.</li>\n",
              "          <li><strong>Identificar</strong> desafíos éticos (sesgos, impacto ambiental, interpretabilidad) y proponer buenas prácticas de uso responsable.</li>\n",
              "        </ul>\n",
              "      </div>\n",
              "    </div>\n",
              "\n",
              "    <!-- Índice -->\n",
              "    <div class=\"section-card fade-in\">\n",
              "      <button class=\"section-header\" onclick=\"toggleSection('indice')\" aria-expanded=\"false\">\n",
              "        <div class=\"section-title\"><i class=\"fas fa-list section-icon\"></i>Índice general de la clase</div>\n",
              "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "      </button>\n",
              "      <div class=\"section-content\" id=\"indice\">\n",
              "\n",
              "        <!-- 1 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-1')\">\n",
              "            <span>1. Introducción</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-1\" style=\"display:none;\">\n",
              "            <p>Motivación y contexto general de los LLMs.</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 2 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-2')\">\n",
              "            <span>2. Pre‑entrenamiento: La base del conocimiento</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-2\" style=\"display:none;\">\n",
              "            <p>2.1 Definición y propósito</p>\n",
              "            <p>2.2 Tareas de pre‑entrenamiento (CLM, MLM, NSP)</p>\n",
              "            <p>2.3 Arquitectura Transformer y auto‑atención</p>\n",
              "            <p>2.4 Ejemplo práctico</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 3 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-3')\">\n",
              "            <span>3. Fine‑tuning: Especialización a partir del conocimiento general</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-3\" style=\"display:none;\">\n",
              "            <p>3.1 Proceso, costos y beneficios</p>\n",
              "            <p>3.2 Casos de uso representativos</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 4 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-4')\">\n",
              "            <span>4. Impacto y desafíos</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-4\" style=\"display:none;\">\n",
              "            <p>4.1 Avances en NLP gracias al pre‑entrenamiento</p>\n",
              "            <p>4.2 Sesgos, consumo energético e interpretabilidad</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 5 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-5')\">\n",
              "            <span>5. El viaje de un prompt</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-5\" style=\"display:none;\">\n",
              "            <p>5.1 Definición y buenas prácticas de ingeniería de prompts</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 6 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-6')\">\n",
              "            <span>6. Flujo interno de un LLM</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-6\" style=\"display:none;\">\n",
              "            <p>6.1 Tokenización</p>\n",
              "            <p>6.2 Embeddings y espacio latente</p>\n",
              "            <p>6.3 Procesamiento contextual con Transformers</p>\n",
              "            <p>6.4 Generación de tokens</p>\n",
              "            <p>6.5 Decodificación a texto</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 7 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-7')\">\n",
              "            <span>7. Resumen visual del proceso</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-7\" style=\"display:none;\">\n",
              "            <p>Tabla y diagrama de etapas clave.</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "        <!-- 8 -->\n",
              "        <div class=\"index-item\">\n",
              "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-8')\">\n",
              "            <span>8. Conclusión</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
              "          </div>\n",
              "          <div class=\"index-content\" id=\"idx-8\" style=\"display:none;\">\n",
              "            <p>Principales aprendizajes y proyección futura.</p>\n",
              "          </div>\n",
              "        </div>\n",
              "\n",
              "      </div>\n",
              "    </div>\n",
              "  </div>\n",
              "\n",
              "  <script>\n",
              "    function toggleTheme(){\n",
              "      const body=document.body;const icon=document.getElementById('theme-icon');\n",
              "      if(body.getAttribute('data-theme')==='dark'){body.removeAttribute('data-theme');icon.className='fas fa-moon';localStorage.setItem('theme','light');}\n",
              "      else{body.setAttribute('data-theme','dark');icon.className='fas fa-sun';localStorage.setItem('theme','dark');}\n",
              "    }\n",
              "    function toggleSection(id){\n",
              "      const content=document.getElementById(id);const btn=content.previousElementSibling;\n",
              "      if(content.classList.contains('expanded')){content.classList.remove('expanded');btn.setAttribute('aria-expanded','false');}\n",
              "      else{content.classList.add('expanded');btn.setAttribute('aria-expanded','true');}\n",
              "    }\n",
              "    function toggleIndexItem(id){\n",
              "      const c=document.getElementById(id);const h=c.previousElementSibling;const ic=h.querySelector('.expand-icon');\n",
              "      if(c.style.display==='none'||c.style.display===''){c.style.display='block';ic.style.transform='rotate(180deg)';}\n",
              "      else{c.style.display='none';ic.style.transform='rotate(0deg)';}\n",
              "    }\n",
              "    window.addEventListener('DOMContentLoaded',()=>{\n",
              "      const savedTheme=localStorage.getItem('theme');const icon=document.getElementById('theme-icon');\n",
              "      if(savedTheme==='dark'){document.body.setAttribute('data-theme','dark');icon.className='fas fa-sun';}\n",
              "      const cards=document.querySelectorAll('.section-card');cards.forEach((card,i)=>{setTimeout(()=>{card.classList.add('fade-in');},i*100);});\n",
              "      document.documentElement.style.scrollBehavior='smooth';\n",
              "    });\n",
              "    window.addEventListener('scroll',()=>{\n",
              "      const y=window.pageYOffset;document.querySelectorAll('.shape').forEach((s,i)=>{const sp=.5+i*.1;s.style.transform=`translateY(${y*sp}px)`;});\n",
              "    });\n",
              "  </script>\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>Clase II – Conceptos LLM</title>\n",
        "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
        "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
        "  <style>\n",
        "    /* ----------  Variables y tema ---------- */\n",
        "    :root{\n",
        "      --bg-primary:linear-gradient(135deg,#667eea 0%,#764ba2 100%);\n",
        "      --bg-secondary:#ffffff;\n",
        "      --bg-tertiary:#f8fafc;\n",
        "      --text-primary:#1e293b;\n",
        "      --text-secondary:#64748b;\n",
        "      --text-accent:#3b82f6;\n",
        "      --border-color:#e2e8f0;\n",
        "      --shadow-sm:0 1px 2px 0 rgb(0 0 0 / .05);\n",
        "      --shadow-md:0 4px 6px -1px rgb(0 0 0 / .1),0 2px 4px -2px rgb(0 0 0 / .1);\n",
        "      --shadow-lg:0 10px 15px -3px rgb(0 0 0 / .1),0 4px 6px -4px rgb(0 0 0 / .1);\n",
        "      --shadow-xl:0 20px 25px -5px rgb(0 0 0 / .1),0 8px 10px -6px rgb(0 0 0 / .1);\n",
        "\n",
        "      --color-blue:#3b82f6;\n",
        "      --color-emerald:#10b981;\n",
        "      --color-purple:#8b5cf6;\n",
        "      --color-rose:#f43f5e;\n",
        "      --color-amber:#f59e0b;\n",
        "    }\n",
        "    [data-theme=\"dark\"]{\n",
        "      --bg-primary:linear-gradient(135deg,#1e293b 0%,#334155 100%);\n",
        "      --bg-secondary:#0f172a;\n",
        "      --bg-tertiary:#1e293b;\n",
        "      --text-primary:#f1f5f9;\n",
        "      --text-secondary:#94a3b8;\n",
        "      --text-accent:#60a5fa;\n",
        "      --border-color:#334155;\n",
        "      --shadow-sm:0 1px 2px 0 rgb(0 0 0 / .3);\n",
        "      --shadow-md:0 4px 6px -1px rgb(0 0 0 / .3),0 2px 4px -2px rgb(0 0 0 / .3);\n",
        "      --shadow-lg:0 10px 15px -3px rgb(0 0 0 / .3),0 4px 6px -4px rgb(0 0 0 / .3);\n",
        "      --shadow-xl:0 20px 25px -5px rgb(0 0 0 / .3),0 8px 10px -6px rgb(0 0 0 / .3);\n",
        "    }\n",
        "    *{margin:0;padding:0;box-sizing:border-box;}\n",
        "    body{\n",
        "      font-family:'Inter',-apple-system,BlinkMacSystemFont,sans-serif;\n",
        "      line-height:1.7;\n",
        "      background:var(--bg-primary);\n",
        "      color:var(--text-primary);\n",
        "      min-height:100vh;\n",
        "      overflow-x:hidden;\n",
        "    }\n",
        "    .container{max-width:1200px;margin:0 auto;padding:2rem;position:relative;}\n",
        "\n",
        "    /* ----------  Cabecera ---------- */\n",
        "    .header{text-align:center;margin-bottom:3rem;position:relative;z-index:10;}\n",
        "    .header::before{\n",
        "      content:'';position:absolute;top:-50px;left:50%;transform:translateX(-50%);\n",
        "      width:100px;height:100px;background:var(--color-blue);border-radius:50%;opacity:.1;\n",
        "      animation:pulse 2s ease-in-out infinite;\n",
        "    }\n",
        "    @keyframes pulse{0%,100%{transform:translateX(-50%) scale(1);opacity:.1;}50%{transform:translateX(-50%) scale(1.1);opacity:.2;}}\n",
        "    .main-title{\n",
        "      font-size:clamp(2.5rem,5vw,4rem);font-weight:700;\n",
        "      background:linear-gradient(135deg,var(--color-blue),var(--color-purple));\n",
        "      -webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;\n",
        "      margin-bottom:1rem;position:relative;\n",
        "    }\n",
        "    .subtitle{font-size:1.25rem;color:var(--text-secondary);font-weight:400;max-width:680px;margin:0 auto 1.5rem auto;}\n",
        "\n",
        "    .author-credit{display:flex;align-items:center;justify-content:center;gap:.5rem;font-size:1rem;color:var(--text-secondary);\n",
        "      background:var(--bg-secondary);padding:.75rem 1.5rem;border-radius:2rem;border:1px solid var(--border-color);\n",
        "      box-shadow:var(--shadow-sm);max-width:fit-content;margin:0 auto;transition:all .3s ease;}\n",
        "    .author-credit:hover{transform:translateY(-2px);box-shadow:var(--shadow-md);border-color:var(--text-accent);}\n",
        "    .author-credit i{color:var(--text-accent);font-size:.9rem;}\n",
        "    .author-credit strong{color:var(--text-primary);font-weight:600;}\n",
        "\n",
        "    /* ----------  Botón tema ---------- */\n",
        "    .theme-toggle{\n",
        "      position:fixed;top:2rem;right:2rem;width:60px;height:60px;border:none;border-radius:50%;\n",
        "      background:var(--bg-secondary);box-shadow:var(--shadow-lg);cursor:pointer;\n",
        "      display:flex;align-items:center;justify-content:center;font-size:1.5rem;color:var(--text-primary);\n",
        "      transition:all .3s cubic-bezier(.4,0,.2,1);z-index:1000;backdrop-filter:blur(10px);\n",
        "    }\n",
        "    .theme-toggle:hover{transform:translateY(-2px) scale(1.05);box-shadow:var(--shadow-xl);}\n",
        "    .theme-toggle:active{transform:translateY(0) scale(.95);}\n",
        "\n",
        "    /* ----------  Secciones ---------- */\n",
        "    .section-card{background:var(--bg-secondary);border-radius:1rem;margin-bottom:1.5rem;box-shadow:var(--shadow-md);\n",
        "      overflow:hidden;transition:all .3s cubic-bezier(.4,0,.2,1);border:1px solid var(--border-color);}\n",
        "    .section-card:hover{transform:translateY(-4px);box-shadow:var(--shadow-xl);}\n",
        "    .section-header{background:none;border:none;width:100%;padding:1.5rem 2rem;text-align:left;cursor:pointer;\n",
        "      display:flex;align-items:center;justify-content:space-between;transition:all .3s ease;position:relative;overflow:hidden;}\n",
        "    .section-header::before{content:'';position:absolute;top:0;left:-100%;width:100%;height:100%;\n",
        "      background:linear-gradient(90deg,transparent,rgba(255,255,255,.1),transparent);transition:left .5s ease;}\n",
        "    .section-header:hover::before{left:100%;}\n",
        "    .section-title{font-size:1.5rem;font-weight:600;color:var(--text-primary);display:flex;align-items:center;gap:.75rem;}\n",
        "    .section-icon{width:24px;height:24px;color:var(--text-accent);}\n",
        "    .expand-icon{font-size:1.25rem;color:var(--text-secondary);transition:transform .3s cubic-bezier(.4,0,.2,1);}\n",
        "    .section-header[aria-expanded=\"true\"] .expand-icon{transform:rotate(180deg);}\n",
        "    .section-content{max-height:0;overflow:hidden;transition:max-height .4s cubic-bezier(.4,0,.2,1),padding .4s cubic-bezier(.4,0,.2,1);\n",
        "      background:var(--bg-tertiary);}\n",
        "    .section-content.expanded{max-height:2000px;padding:2rem;}\n",
        "    .section-content p{margin-bottom:1.25rem;line-height:1.8;color:var(--text-primary);}\n",
        "    .section-content ul{margin:1.25rem 0;padding-left:1.5rem;}\n",
        "    .section-content li{margin-bottom:.75rem;color:var(--text-primary);}\n",
        "    .section-content li::marker{color:var(--text-accent);}\n",
        "\n",
        "    /* ----------  Índice ---------- */\n",
        "    .index-item{background:var(--bg-secondary);border-radius:.75rem;margin:1rem 0;border:1px solid var(--border-color);overflow:hidden;}\n",
        "    .index-header{padding:1rem 1.5rem;background:linear-gradient(135deg,var(--color-emerald),var(--color-blue));\n",
        "      color:#fff;font-weight:500;display:flex;align-items:center;justify-content:space-between;cursor:pointer;transition:all .3s ease;}\n",
        "    .index-header:hover{background:linear-gradient(135deg,#059669,#2563eb);}\n",
        "    .index-content{padding:1.5rem;background:var(--bg-tertiary);border-top:1px solid var(--border-color);}\n",
        "    .index-content p{margin-bottom:.75rem;font-size:.95rem;color:var(--text-secondary);}\n",
        "\n",
        "    /* ----------  Efectos ---------- */\n",
        "    .floating-shapes{position:fixed;top:0;left:0;width:100%;height:100%;pointer-events:none;z-index:-1;overflow:hidden;}\n",
        "    .shape{position:absolute;background:var(--color-blue);border-radius:50%;opacity:.05;animation:float 6s ease-in-out infinite;}\n",
        "    .shape:nth-child(1){width:80px;height:80px;top:20%;left:10%;animation-delay:0s;}\n",
        "    .shape:nth-child(2){width:120px;height:120px;top:60%;right:15%;animation-delay:2s;background:var(--color-purple);}\n",
        "    .shape:nth-child(3){width:60px;height:60px;bottom:20%;left:20%;animation-delay:4s;background:var(--color-emerald);}\n",
        "    @keyframes float{0%,100%{transform:translateY(0) rotate(0deg);}33%{transform:translateY(-20px) rotate(120deg);}66%{transform:translateY(10px) rotate(240deg);}}\n",
        "\n",
        "    /* ----------  Responsive ---------- */\n",
        "    @media(max-width:768px){\n",
        "      .container{padding:1rem;}\n",
        "      .section-header{padding:1.25rem 1.5rem;}\n",
        "      .section-content.expanded{padding:1.5rem;}\n",
        "      .theme-toggle{width:50px;height:50px;top:1rem;right:1rem;font-size:1.25rem;}\n",
        "      .main-title{font-size:2.5rem;}\n",
        "    }\n",
        "\n",
        "    /* ----------  Animaciones ---------- */\n",
        "    .fade-in{opacity:0;transform:translateY(20px);animation:fadeInUp .6s ease forwards;}\n",
        "    @keyframes fadeInUp{to{opacity:1;transform:translateY(0);} }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"floating-shapes\">\n",
        "    <div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div>\n",
        "  </div>\n",
        "\n",
        "  <button class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema\">\n",
        "    <i class=\"fas fa-moon\" id=\"theme-icon\"></i>\n",
        "  </button>\n",
        "\n",
        "  <div class=\"container\">\n",
        "    <header class=\"header\">\n",
        "      <h1 class=\"main-title fade-in\">Conceptos LLM</h1>\n",
        "      <p class=\"subtitle fade-in\">Clase II – Funcionamiento interno de los modelos de lenguaje de gran escala</p>\n",
        "      <div class=\"author-credit fade-in\">\n",
        "        <i class=\"fas fa-user-edit\"></i><span>Elaborado por <strong>Sergio Gevatschnaider</strong></span>\n",
        "      </div>\n",
        "    </header>\n",
        "\n",
        "    <!-- Introducción -->\n",
        "    <div class=\"section-card fade-in\">\n",
        "      <button class=\"section-header\" onclick=\"toggleSection('intro')\" aria-expanded=\"false\">\n",
        "        <div class=\"section-title\"><i class=\"fas fa-rocket section-icon\"></i>Introducción</div>\n",
        "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "      </button>\n",
        "      <div class=\"section-content\" id=\"intro\">\n",
        "        <p>En los últimos años, los <strong>modelos de lenguaje de gran escala (LLMs)</strong>, como GPT, BERT o PaLM, han transformado la forma en que interactuamos con la inteligencia artificial. Capaces de redactar textos, traducir idiomas, razonar lógicamente e incluso programar, estos sistemas parecen “comprender” el lenguaje humano con asombrosa <strong>facilidad</strong>. Pero ¿qué ocurre realmente dentro de estas redes neuronales cuando les planteamos una pregunta?</p>\n",
        "        <p>Esta clase se propone revelar el engranaje interno de los LLMs: desde el <em>pre‑entrenamiento</em> sobre corpus masivos de texto hasta la generación de una respuesta <em>token por token</em>. Comprenderemos los principios del <strong>Transformer</strong>, el recorrido de un <em>prompt</em> por las etapas de tokenización, embeddings y auto‑atención, y los retos éticos y computacionales que acompañan a estos avances. Más que una exposición teórica, el objetivo es dotarte de criterios críticos para aprovechar —y cuestionar— las capacidades de la IA lingüística actual.</p>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Objetivo -->\n",
        "    <div class=\"section-card fade-in\">\n",
        "      <button class=\"section-header\" onclick=\"toggleSection('objetivo')\" aria-expanded=\"false\">\n",
        "        <div class=\"section-title\"><i class=\"fas fa-target section-icon\"></i>Objetivo</div>\n",
        "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "      </button>\n",
        "      <div class=\"section-content\" id=\"objetivo\">\n",
        "        <p>Brindar a los estudiantes una comprensión profunda y crítica del funcionamiento de los modelos de lenguaje de gran escala, analizando sus componentes esenciales —pre‑entrenamiento, arquitectura Transformer, tokenización, embeddings y flujo de generación— para que puedan:</p>\n",
        "        <ul>\n",
        "          <li><strong>Explicar</strong> cómo un LLM procesa, “comprende” y produce lenguaje natural.</li>\n",
        "          <li><strong>Evaluar</strong> las ventajas y limitaciones de los LLMs en diferentes aplicaciones de IA.</li>\n",
        "          <li><strong>Diseñar</strong> prompts y flujos de <em>fine‑tuning</em> con fundamento técnico.</li>\n",
        "          <li><strong>Identificar</strong> desafíos éticos (sesgos, impacto ambiental, interpretabilidad) y proponer buenas prácticas de uso responsable.</li>\n",
        "        </ul>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <!-- Índice -->\n",
        "    <div class=\"section-card fade-in\">\n",
        "      <button class=\"section-header\" onclick=\"toggleSection('indice')\" aria-expanded=\"false\">\n",
        "        <div class=\"section-title\"><i class=\"fas fa-list section-icon\"></i>Índice general de la clase</div>\n",
        "        <i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "      </button>\n",
        "      <div class=\"section-content\" id=\"indice\">\n",
        "\n",
        "        <!-- 1 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-1')\">\n",
        "            <span>1. Introducción</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-1\" style=\"display:none;\">\n",
        "            <p>Motivación y contexto general de los LLMs.</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 2 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-2')\">\n",
        "            <span>2. Pre‑entrenamiento: La base del conocimiento</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-2\" style=\"display:none;\">\n",
        "            <p>2.1 Definición y propósito</p>\n",
        "            <p>2.2 Tareas de pre‑entrenamiento (CLM, MLM, NSP)</p>\n",
        "            <p>2.3 Arquitectura Transformer y auto‑atención</p>\n",
        "            <p>2.4 Ejemplo práctico</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 3 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-3')\">\n",
        "            <span>3. Fine‑tuning: Especialización a partir del conocimiento general</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-3\" style=\"display:none;\">\n",
        "            <p>3.1 Proceso, costos y beneficios</p>\n",
        "            <p>3.2 Casos de uso representativos</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 4 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-4')\">\n",
        "            <span>4. Impacto y desafíos</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-4\" style=\"display:none;\">\n",
        "            <p>4.1 Avances en NLP gracias al pre‑entrenamiento</p>\n",
        "            <p>4.2 Sesgos, consumo energético e interpretabilidad</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 5 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-5')\">\n",
        "            <span>5. El viaje de un prompt</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-5\" style=\"display:none;\">\n",
        "            <p>5.1 Definición y buenas prácticas de ingeniería de prompts</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 6 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-6')\">\n",
        "            <span>6. Flujo interno de un LLM</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-6\" style=\"display:none;\">\n",
        "            <p>6.1 Tokenización</p>\n",
        "            <p>6.2 Embeddings y espacio latente</p>\n",
        "            <p>6.3 Procesamiento contextual con Transformers</p>\n",
        "            <p>6.4 Generación de tokens</p>\n",
        "            <p>6.5 Decodificación a texto</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 7 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-7')\">\n",
        "            <span>7. Resumen visual del proceso</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-7\" style=\"display:none;\">\n",
        "            <p>Tabla y diagrama de etapas clave.</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- 8 -->\n",
        "        <div class=\"index-item\">\n",
        "          <div class=\"index-header\" onclick=\"toggleIndexItem('idx-8')\">\n",
        "            <span>8. Conclusión</span><i class=\"fas fa-chevron-down expand-icon\"></i>\n",
        "          </div>\n",
        "          <div class=\"index-content\" id=\"idx-8\" style=\"display:none;\">\n",
        "            <p>Principales aprendizajes y proyección futura.</p>\n",
        "          </div>\n",
        "        </div>\n",
        "\n",
        "      </div>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    function toggleTheme(){\n",
        "      const body=document.body;const icon=document.getElementById('theme-icon');\n",
        "      if(body.getAttribute('data-theme')==='dark'){body.removeAttribute('data-theme');icon.className='fas fa-moon';localStorage.setItem('theme','light');}\n",
        "      else{body.setAttribute('data-theme','dark');icon.className='fas fa-sun';localStorage.setItem('theme','dark');}\n",
        "    }\n",
        "    function toggleSection(id){\n",
        "      const content=document.getElementById(id);const btn=content.previousElementSibling;\n",
        "      if(content.classList.contains('expanded')){content.classList.remove('expanded');btn.setAttribute('aria-expanded','false');}\n",
        "      else{content.classList.add('expanded');btn.setAttribute('aria-expanded','true');}\n",
        "    }\n",
        "    function toggleIndexItem(id){\n",
        "      const c=document.getElementById(id);const h=c.previousElementSibling;const ic=h.querySelector('.expand-icon');\n",
        "      if(c.style.display==='none'||c.style.display===''){c.style.display='block';ic.style.transform='rotate(180deg)';}\n",
        "      else{c.style.display='none';ic.style.transform='rotate(0deg)';}\n",
        "    }\n",
        "    window.addEventListener('DOMContentLoaded',()=>{\n",
        "      const savedTheme=localStorage.getItem('theme');const icon=document.getElementById('theme-icon');\n",
        "      if(savedTheme==='dark'){document.body.setAttribute('data-theme','dark');icon.className='fas fa-sun';}\n",
        "      const cards=document.querySelectorAll('.section-card');cards.forEach((card,i)=>{setTimeout(()=>{card.classList.add('fade-in');},i*100);});\n",
        "      document.documentElement.style.scrollBehavior='smooth';\n",
        "    });\n",
        "    window.addEventListener('scroll',()=>{\n",
        "      const y=window.pageYOffset;document.querySelectorAll('.shape').forEach((s,i)=>{const sp=.5+i*.1;s.style.transform=`translateY(${y*sp}px)`;});\n",
        "    });\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2PHcF9g_3xcF",
        "outputId": "1c90a393-ed4a-4a8f-ce9f-6a193e386eff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title><strong class=\"keyword\">Pre-entrenamiento</strong>: La Base del Conocimiento en Modelos de Lenguaje Modernos</title>\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #1e88e5; /* Azul más vibrante */\n",
              "  --secondary-color: #00acc1; /* Cian */\n",
              "  --text-color: #37474f; /* Gris oscuro azulado */\n",
              "  --bg-color: #eceff1; /* Gris muy claro */\n",
              "  --container-bg: #ffffff;\n",
              "  --keyword-bg: #e0f7fa; /* Cian muy pálido */\n",
              "  --keyword-text: #00796b; /* Teal oscuro */\n",
              "  --shadow-color: rgba(0,0,0,0.1);\n",
              "  --pre-bg: #f5f5f5;\n",
              "  --pre-text: #212121;\n",
              "  --blockquote-bg: #e8f5e9; /* Verde muy pálido */\n",
              "  --blockquote-border: var(--secondary-color);\n",
              "  --table-border-color: #cfd8dc;\n",
              "  --row-bg-odd: #f9f9f9;\n",
              "  --row-bg-even: #ffffff;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #42a5f5; /* Azul claro */\n",
              "  --secondary-color: #26c6da; /* Cian claro */\n",
              "  --text-color: #e0e0e0; /* Gris claro */\n",
              "  --bg-color: #212121; /* Gris muy oscuro */\n",
              "  --container-bg: #303030; /* Gris oscuro */\n",
              "  --keyword-bg: #455a64; /* Gris azulado oscuro */\n",
              "  --keyword-text: #80deea; /* Cian pálido */\n",
              "  --shadow-color: rgba(0,0,0,0.4);\n",
              "  --pre-bg: #263238; /* Azul grisáceo oscuro */\n",
              "  --pre-text: #eceff1;\n",
              "  --blockquote-bg: #37474f; /* Gris azulado oscuro */\n",
              "  --blockquote-border: var(--secondary-color);\n",
              "  --table-border-color: #455a64;\n",
              "  --row-bg-odd: #3a3a3a;\n",
              "  --row-bg-even: #303030;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Roboto', 'Arial', sans-serif;\n",
              "  line-height: 1.75;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 20px;\n",
              "  margin: 0;\n",
              "}\n",
              ".container {\n",
              "  max-width: 950px;\n",
              "  margin: 30px auto;\n",
              "  padding: 25px 35px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 12px;\n",
              "  box-shadow: 0 5px 20px var(--shadow-color);\n",
              "  border-top: 7px solid var(--primary-color);\n",
              "  transition: background-color .3s, box-shadow .3s;\n",
              "}\n",
              "h1 {\n",
              "    color: var(--primary-color);\n",
              "    font-size: 2.4em;\n",
              "    margin-top: 0.5em;\n",
              "    margin-bottom: 0.6em;\n",
              "    border-bottom: 2px solid var(--secondary-color);\n",
              "    padding-bottom: 0.3em;\n",
              "}\n",
              "h2 {\n",
              "    color: var(--secondary-color);\n",
              "    margin-top: 2.2em;\n",
              "    margin-bottom: 0.8em;\n",
              "    font-size: 1.8em;\n",
              "    border-bottom: 1px solid #eee;\n",
              "    padding-bottom: 0.2em;\n",
              "}\n",
              "body.dark-mode h2 {\n",
              "    border-bottom: 1px solid #444;\n",
              "}\n",
              "h3 { /* Si se usan h3, este sería un buen estilo */\n",
              "    color: var(--primary-color);\n",
              "    margin-top: 1.8em;\n",
              "    margin-bottom: 0.6em;\n",
              "    font-size: 1.4em;\n",
              "}\n",
              "ul, ol {\n",
              "    margin-bottom:1.3em;\n",
              "    padding-left: 25px;\n",
              "}\n",
              "li {\n",
              "    margin-bottom:0.6em;\n",
              "}\n",
              "p {\n",
              "    margin-bottom: 1.2em;\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.18em 0.4em;\n",
              "  border-radius: 5px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              "pre {\n",
              "    background: var(--pre-bg);\n",
              "    color: var(--pre-text);\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    border-radius: 8px;\n",
              "    padding: 12px 16px;\n",
              "    font-size: 0.95em;\n",
              "    line-height: 1.5;\n",
              "    overflow-x: auto;\n",
              "    margin: 1em 0;\n",
              "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);\n",
              "}\n",
              "blockquote {\n",
              "    background: var(--blockquote-bg);\n",
              "    border-left: 6px solid var(--blockquote-border);\n",
              "    margin: 1.5em 0;\n",
              "    padding: 1em 1.5em;\n",
              "    font-style: italic;\n",
              "    border-radius: 0 8px 8px 0;\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--primary-color);\n",
              "  color: white;\n",
              "  border: none;\n",
              "  padding: 10px 18px;\n",
              "  border-radius: 6px;\n",
              "  cursor: pointer;\n",
              "  position: fixed; /* Fijado en la pantalla */\n",
              "  top: 20px;\n",
              "  right: 25px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, transform .2s;\n",
              "  z-index: 1000;\n",
              "  box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--secondary-color);\n",
              "    transform: translateY(-2px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 3px solid var(--secondary-color);\n",
              "    outline-offset: 2px;\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">Modo Oscuro</button>\n",
              "<div class=\"container\">\n",
              "  <h1><strong class=\"keyword\">Pre-entrenamiento</strong>: La Base del Conocimiento en Modelos de Lenguaje Modernos</h1>\n",
              "  \n",
              "<p>El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es la fase inicial y crucial en la creación de los potentes <b>modelos de lenguaje</b> (LLMs) que conocemos hoy. Durante esta etapa, el modelo se expone a cantidades masivas de datos textuales no estructurados (un vasto <b><strong class=\"keyword\">corpus textual</strong></b>) provenientes de internet, libros, artículos y otras fuentes. La clave es que este aprendizaje es <b><strong class=\"keyword\">no supervisado</strong></b> o, más precisamente, <b><strong class=\"keyword\">auto-supervisado</strong></b>: el modelo aprende a identificar patrones, estructuras y <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> inherentes al lenguaje humano sin necesidad de etiquetas o anotaciones manuales específicas para una <b><strong class=\"keyword\">tarea específica</strong></b>.</p>\n",
              "\n",
              "  \n",
              "<h2>¿Cuál es el Objetivo Primordial del <strong class=\"keyword\">Pre-entrenamiento</strong>?</h2>\n",
              "El objetivo central del <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es dotar al <b><strong class=\"keyword\">modelo de lenguaje</strong></b> de una comprensión fundamental y amplia del lenguaje natural. Se busca que el modelo, a través de la exposición a terabytes de texto, aprenda autónomamente:\n",
              "<ul>\n",
              "    <li>La sintaxis y gramática del lenguaje.</li>\n",
              "    <li>El significado de las palabras (semántica) y cómo este cambia según el <b>contexto</b>.</li>\n",
              "    <li>Relaciones comunes entre palabras y conceptos (ej., \"rey\" está relacionado con \"reina\", \"trono\", \"reino\").</li>\n",
              "    <li>Un cierto grado de \"conocimiento del mundo\" implícito en los textos (hechos, eventos, ideas).</li>\n",
              "</ul>\n",
              "En esencia, el modelo construye <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> internas (a menudo en forma de <b><strong class=\"keyword\">embeddings</strong></b>) que capturan estas regularidades, las cuales se almacenan en sus millones o billones de <b><strong class=\"keyword\">parámetros</strong></b>.\n",
              "\n",
              "  \n",
              "<h2>¿Qué Aprende y Cómo lo Aprende el Modelo Durante el <strong class=\"keyword\">Pre-entrenamiento</strong>?</h2>\n",
              "Durante la fase de <b><strong class=\"keyword\">pre-entrenamiento</strong></b>, el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> no se entrena para una <b><strong class=\"keyword\">tarea específica</strong></b> como traducir o resumir. En su lugar, se le asignan tareas \"pretexto\" que lo obligan a entender y predecir el lenguaje. Las más comunes incluyen:\n",
              "<ul>\n",
              "  <li><b>Modelado de Lenguaje <strong class=\"keyword\">Causal</strong> (<strong class=\"keyword\">Causal</strong> Language Modeling - CLM)</b>: Típico de modelos como <b><strong class=\"keyword\">GPT</strong></b> (Generative Pre-trained <strong class=\"keyword\">Transformer</strong>). El modelo aprende a predecir el siguiente <b>token</b> (palabra o subpalabra) en una secuencia de <b><strong class=\"keyword\">tokens</strong></b>. Dado \"El gato se sentó en la...\", el modelo debe predecir \"alfombra\" o una palabra similarmente probable.</li>\n",
              "  <li><b>Modelado de Lenguaje <strong class=\"keyword\">Enmascarado</strong> (Masked Language Modeling - MLM)</b>: Característico de modelos como <b><strong class=\"keyword\">BERT</strong></b> (Bidirectional Encoder Representations from Transformers). En esta tarea, algunos <b><strong class=\"keyword\">tokens</strong></b> de la secuencia de entrada son aleatoriamente \"enmascarados\" (reemplazados por un <b>token</b> especial como `[MASK]`), y el modelo debe predecir cuáles eran los <b><strong class=\"keyword\">tokens</strong></b> originales basándose en el <b>contexto</b> de los <b><strong class=\"keyword\">tokens</strong></b> no enmascarados a su alrededor (tanto a la izquierda como a la derecha).</li>\n",
              "  <li><b>Predicción de la Siguiente Oración (Next Sentence Prediction - NSP)</b>: Utilizado originalmente por <b><strong class=\"keyword\">BERT</strong></b>, donde el modelo aprende a determinar si dos frases presentadas son consecutivas en el texto original o no. Aunque su utilidad ha sido debatida y a veces se omite en modelos más recientes.</li>\n",
              "</ul>\n",
              "A través de la optimización para estas tareas en un gigantesco <b><strong class=\"keyword\">corpus textual</strong></b>, el modelo ajusta sus <b><strong class=\"keyword\">parámetros</strong></b> mediante algoritmos de <b><strong class=\"keyword\">aprendizaje profundo</strong></b>, internalizando patrones estadísticos y semánticos complejos. Estas <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> aprendidas son la base del <b><strong class=\"keyword\">conocimiento general</strong></b> del modelo.\n",
              "\n",
              "  \n",
              "<h2>Arquitectura Predominante: El Poder del <strong class=\"keyword\">Transformer</strong></h2>\n",
              "La mayoría de los <b>modelos de lenguaje</b> modernos se basan en la arquitectura <b><strong class=\"keyword\">Transformer</strong></b>, introducida en 2017. Esta arquitectura es particularmente efectiva para procesar datos secuenciales como el lenguaje natural debido a varias razones:\n",
              "<ul>\n",
              "  <li><b>Mecanismos de <strong class=\"keyword\">Auto-atención</strong> (<strong class=\"keyword\">Self-attention</strong>)</b>: Permiten al modelo sopesar la importancia de diferentes <b><strong class=\"keyword\">tokens</strong></b> en una secuencia al calcular la representación de cada <b>token</b>. Esto significa que puede capturar dependencias a larga distancia y entender cómo las palabras se relacionan entre sí, sin importar cuán separadas estén en el texto.</li>\n",
              "  <li><b>Procesamiento Paralelo</b>: A diferencia de arquitecturas recurrentes anteriores (como LSTMs o GRUs), los <b>Transformers</b> pueden procesar todos los <b><strong class=\"keyword\">tokens</strong></b> de una secuencia simultáneamente, lo que los hace altamente <b>escalables</b> y eficientes para entrenar en hardware moderno como <b>GPUs</b> (Unidades de Procesamiento Gráfico) y <b>TPUs</b> (Unidades de Procesamiento Tensorial).</li>\n",
              "  <li><b>Codificadores y Decodificadores</b>: Los modelos tipo <b><strong class=\"keyword\">BERT</strong></b> suelen usar la parte del \"codificador\" del <b><strong class=\"keyword\">Transformer</strong></b> para generar ricas <b><strong class=\"keyword\">representaciones lingüísticas</strong></b>. Los modelos tipo <b><strong class=\"keyword\">GPT</strong></b> utilizan la parte del \"decodificador\" para la generación de texto de manera <b><strong class=\"keyword\">causal</strong></b>.</li>\n",
              "</ul>\n",
              "El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> de estos modelos implica optimizar arquitecturas con cientos de millones (ej. <strong class=\"keyword\">BERT</strong>-base) hasta billones (ej. <strong class=\"keyword\">GPT</strong>-3, PaLM) de <b><strong class=\"keyword\">parámetros</strong></b>, un proceso que es computacionalmente muy <b><strong class=\"keyword\">costoso</strong></b>.\n",
              "\n",
              "  \n",
              "<h2>Características Clave del <strong class=\"keyword\">Pre-entrenamiento</strong></h2>\n",
              "El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> se distingue por varias características fundamentales:\n",
              "<ul>\n",
              "  <li><b><strong class=\"keyword\">Auto-supervisado</strong> (o <strong class=\"keyword\">No Supervisado</strong>)</b>: El modelo genera sus propias señales de supervisión a partir de los datos de entrada sin procesar (ej., predecir la siguiente palabra o una palabra enmascarada). No requiere etiquetas humanas costosas.</li>\n",
              "  <li><b><strong class=\"keyword\">Escalable</strong></b>: El rendimiento del <b><strong class=\"keyword\">modelo de lenguaje</strong></b> generalmente mejora con más datos, más <b><strong class=\"keyword\">parámetros</strong></b> y más cómputo. Esta propiedad de escalabilidad ha impulsado la creación de modelos cada vez más grandes y capaces.</li>\n",
              "  <li><b><strong class=\"keyword\">Transferible</strong> y Fundacional</b>: El <b><strong class=\"keyword\">conocimiento general</strong></b> y las <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> aprendidas durante el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> son altamente <b>transferibles</b>. Sirven como una base sólida que luego puede ser adaptada a una amplia gama de tareas específicas de procesamiento del lenguaje natural mediante un proceso llamado <b><strong class=\"keyword\">fine-tuning</strong></b>.</li>\n",
              "  <li><b><strong class=\"keyword\">Costoso</strong></b>: Debido a la enorme cantidad de datos y al tamaño de los modelos, el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es una tarea computacionalmente intensiva y, por lo tanto, <b>costosa</b>, requiriendo semanas o meses de entrenamiento en clústeres de <b>GPUs</b> o <b>TPUs</b>.</li>\n",
              "</ul>\n",
              "\n",
              "  \n",
              "<h2>Ejemplo Práctico: ¿Cómo \"Sabe\" el Modelo?</h2>\n",
              "Imaginemos un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> como <b><strong class=\"keyword\">GPT</strong></b> durante su <b><strong class=\"keyword\">pre-entrenamiento</strong></b>. Se le presenta la secuencia de <b><strong class=\"keyword\">tokens</strong></b>: <code>\"El sol brilla intensamente en el cielo...\"</code>. La tarea del modelo es predecir el siguiente <b>token</b>.\n",
              "<ul>\n",
              "    <li>Inicialmente, sus predicciones serán aleatorias.</li>\n",
              "    <li>Pero después de ver millones de ejemplos en su <b><strong class=\"keyword\">corpus textual</strong></b> donde secuencias similares son seguidas por palabras como \"azul\", \"despejado\", o signos de puntuación, el modelo ajusta sus <b><strong class=\"keyword\">parámetros</strong></b>.</li>\n",
              "    <li>Comienza a asignar una mayor <b>probabilidad</b> a \"azul\" después de \"El sol brilla intensamente en el cielo\".</li>\n",
              "</ul>\n",
              "No es que \"sepa\" conscientemente que el cielo es azul; más bien, ha aprendido una fuerte correlación estadística y contextual. Si se le da <code>“La capital de Francia es…”</code>, y ha visto innumerables veces \"La capital de Francia es París\" en sus datos de <b><strong class=\"keyword\">pre-entrenamiento</strong></b>, aprenderá a predecir \"París\" con alta <b>probabilidad</b> en ese <b>contexto</b>.\n",
              "\n",
              "  \n",
              "<h2>Relación Crucial con el <strong class=\"keyword\">Fine-tuning</strong></h2>\n",
              "El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> dota al <b><strong class=\"keyword\">modelo de lenguaje</strong></b> de un vasto <b><strong class=\"keyword\">conocimiento general</strong></b> sobre el lenguaje y el mundo, tal como está representado en el texto. Sin embargo, para que el modelo sea útil en una <b><strong class=\"keyword\">tarea específica</strong></b> (como clasificación de sentimientos, respuesta a preguntas médicas, o generación de código), necesita una segunda fase de entrenamiento llamada <b><strong class=\"keyword\">fine-tuning</strong></b> (ajuste fino).\n",
              "<ul>\n",
              "    <li>Durante el <b><strong class=\"keyword\">fine-tuning</strong></b>, el modelo pre-entrenado se entrena adicionalmente con un conjunto de datos más pequeño y específico para la tarea, que sí suele estar etiquetado.</li>\n",
              "    <li>Este proceso adapta las <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> generales aprendidas durante el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> a los matices de la <b><strong class=\"keyword\">tarea específica</strong></b>.</li>\n",
              "    <li>El <b><strong class=\"keyword\">fine-tuning</strong></b> es significativamente menos <b><strong class=\"keyword\">costoso</strong></b> y requiere muchos menos datos que el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> desde cero, gracias al conocimiento ya adquirido.</li>\n",
              "</ul>\n",
              "El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es, por tanto, el cimiento sobre el cual se construyen modelos especializados mediante <b><strong class=\"keyword\">fine-tuning</strong></b>.\n",
              "\n",
              "  \n",
              "<h2>Impacto y Desafíos del <strong class=\"keyword\">Pre-entrenamiento</strong></h2>\n",
              "El paradigma del <b><strong class=\"keyword\">pre-entrenamiento</strong></b> seguido de <b><strong class=\"keyword\">fine-tuning</strong></b> ha revolucionado el campo del Procesamiento del Lenguaje Natural (NLP), llevando a avances significativos en una multitud de aplicaciones.\n",
              "<p><b>Impacto:</b></p>\n",
              "<ul>\n",
              "    <li><b>Mejora del Rendimiento:</b> Los modelos pre-entrenados establecen consistentemente el estado del arte en muchos benchmarks de NLP.</li>\n",
              "    <li><b>Democratización (parcial):</b> Aunque el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es <b><strong class=\"keyword\">costoso</strong></b>, los modelos pre-entrenados suelen publicarse, permitiendo a investigadores y desarrolladores con menos recursos realizar <b><strong class=\"keyword\">fine-tuning</strong></b> para sus propias aplicaciones.</li>\n",
              "    <li><b>Nuevas Capacidades:</b> Han surgido capacidades como la generación de texto coherente y creativo, la traducción de alta calidad y la respuesta a preguntas complejas.</li>\n",
              "</ul>\n",
              "<p><b>Desafíos:</b></p>\n",
              "<ul>\n",
              "    <li><b>Sesgos en los Datos:</b> Los modelos pueden aprender y amplificar sesgos (sociales, de género, raciales) presentes en el masivo <b><strong class=\"keyword\">corpus textual</strong></b> de <b><strong class=\"keyword\">pre-entrenamiento</strong></b>.</li>\n",
              "    <li><b>Costo Computacional y Ambiental:</b> El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> de los modelos más grandes consume una cantidad significativa de energía, lo que plantea preocupaciones ambientales.</li>\n",
              "    <li><b>Interpretabilidad:</b> Entender por qué un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> grande toma una decisión particular (su \"razonamiento\") sigue siendo un área activa de investigación. Son a menudo \"cajas negras\".</li>\n",
              "    <li><b>Conocimiento Desactualizado:</b> El conocimiento del modelo está congelado al momento de su <b><strong class=\"keyword\">pre-entrenamiento</strong></b> y puede volverse obsoleto.</li>\n",
              "</ul>\n",
              "\n",
              "  \n",
              "<h2>Conclusión: El Pilar de la Inteligencia Lingüística Artificial</h2>\n",
              "El <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es, sin lugar a dudas, uno de los avances más significativos en la inteligencia artificial moderna. Al permitir que los <b>modelos de lenguaje</b> aprendan <b><strong class=\"keyword\">representaciones lingüísticas</strong></b> ricas y un amplio <b><strong class=\"keyword\">conocimiento general</strong></b> de manera <b>auto-supervisada</b> a partir de vastos corpus textuales, ha sentado las bases para la actual generación de LLMs. La arquitectura <b><strong class=\"keyword\">Transformer</strong></b>, con su mecanismo de <b><strong class=\"keyword\">auto-atención</strong></b>, ha sido el vehículo principal para este logro.\n",
              "<br><br>\n",
              "A pesar de ser un proceso <b><strong class=\"keyword\">costoso</strong></b> y presentar desafíos como los sesgos y la interpretabilidad, el conocimiento <b><strong class=\"keyword\">transferible</strong></b> obtenido durante el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es lo que permite luego, mediante <b><strong class=\"keyword\">fine-tuning</strong></b>, adaptar estos modelos a una miríada de tareas específicas con una eficiencia sin precedentes. Comprender el <b><strong class=\"keyword\">pre-entrenamiento</strong></b> es esencial para entender las capacidades y limitaciones de los <b>modelos de lenguaje</b> actuales y futuros.\n",
              "\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "    }\n",
              "}\n",
              "\n",
              "function initializeTheme(buttonElement) {\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "\n",
              "    if (savedTheme === \"dark\" || (!savedTheme && prefersDark)) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        if (buttonElement) buttonElement.textContent = \"Modo Claro\";\n",
              "    } else {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        if (buttonElement) buttonElement.textContent = \"Modo Oscuro\";\n",
              "    }\n",
              "}\n",
              "\n",
              "window.onload = function() {\n",
              "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    if (!themeToggleButton) {\n",
              "        const button = document.createElement('button');\n",
              "        button.id = \"theme-toggle-btn\";\n",
              "        button.className = \"theme-toggle\";\n",
              "        button.title = \"Cambiar tema de color\";\n",
              "        button.onclick = toggleTheme;\n",
              "        // Añadir el botón al body si no existe\n",
              "        document.body.appendChild(button);\n",
              "        themeToggleButton = button; // Asignar el botón recién creado\n",
              "    }\n",
              "    initializeTheme(themeToggleButton);\n",
              "};\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "import re\n",
        "\n",
        "# Función para resaltar palabras clave\n",
        "def highlight_keywords(text, keywords):\n",
        "    # Ordenar keywords por longitud descendente para evitar coincidencias parciales\n",
        "    keywords_sorted = sorted(keywords, key=len, reverse=True)\n",
        "    pattern = '|'.join(r'(?<![\\w])(?:' + re.escape(kw) + r')(?![\\w])' for kw in keywords_sorted)\n",
        "    def replacer(match):\n",
        "        return f'<strong class=\"keyword\">{match.group(0)}</strong>'\n",
        "    return re.sub(pattern, replacer, text, flags=re.IGNORECASE)\n",
        "\n",
        "# Palabras clave a resaltar\n",
        "keywords = [\n",
        "    \"pre-entrenamiento\", \"modelo de lenguaje\", \"fine-tuning\", \"Transformer\",\n",
        "    \"auto-atención\", \"self-attention\", \"parámetros\", \"aprendizaje profundo\",\n",
        "    \"tokens\", \"no supervisado\", \"auto-supervisado\", \"escalable\",\n",
        "    \"transferible\", \"costoso\", \"representaciones lingüísticas\",\n",
        "    \"causal\", \"enmascarado\", \"GPT\", \"BERT\", \"GPU\", \"TPU\", \"corpus textual\",\n",
        "    \"embeddings\", \"conocimiento general\", \"tarea específica\"\n",
        "]\n",
        "\n",
        "# Texto con secciones\n",
        "title = \"Pre-entrenamiento: La Base del Conocimiento en Modelos de Lenguaje Modernos\"\n",
        "\n",
        "intro = \"\"\"\n",
        "<p>El <b>pre-entrenamiento</b> es la fase inicial y crucial en la creación de los potentes <b>modelos de lenguaje</b> (LLMs) que conocemos hoy. Durante esta etapa, el modelo se expone a cantidades masivas de datos textuales no estructurados (un vasto <b>corpus textual</b>) provenientes de internet, libros, artículos y otras fuentes. La clave es que este aprendizaje es <b>no supervisado</b> o, más precisamente, <b>auto-supervisado</b>: el modelo aprende a identificar patrones, estructuras y <b>representaciones lingüísticas</b> inherentes al lenguaje humano sin necesidad de etiquetas o anotaciones manuales específicas para una <b>tarea específica</b>.</p>\n",
        "\"\"\"\n",
        "\n",
        "objetivo = \"\"\"\n",
        "<h2>¿Cuál es el Objetivo Primordial del Pre-entrenamiento?</h2>\n",
        "El objetivo central del <b>pre-entrenamiento</b> es dotar al <b>modelo de lenguaje</b> de una comprensión fundamental y amplia del lenguaje natural. Se busca que el modelo, a través de la exposición a terabytes de texto, aprenda autónomamente:\n",
        "<ul>\n",
        "    <li>La sintaxis y gramática del lenguaje.</li>\n",
        "    <li>El significado de las palabras (semántica) y cómo este cambia según el <b>contexto</b>.</li>\n",
        "    <li>Relaciones comunes entre palabras y conceptos (ej., \"rey\" está relacionado con \"reina\", \"trono\", \"reino\").</li>\n",
        "    <li>Un cierto grado de \"conocimiento del mundo\" implícito en los textos (hechos, eventos, ideas).</li>\n",
        "</ul>\n",
        "En esencia, el modelo construye <b>representaciones lingüísticas</b> internas (a menudo en forma de <b>embeddings</b>) que capturan estas regularidades, las cuales se almacenan en sus millones o billones de <b>parámetros</b>.\n",
        "\"\"\"\n",
        "\n",
        "aprendizaje = \"\"\"\n",
        "<h2>¿Qué Aprende y Cómo lo Aprende el Modelo Durante el Pre-entrenamiento?</h2>\n",
        "Durante la fase de <b>pre-entrenamiento</b>, el <b>modelo de lenguaje</b> no se entrena para una <b>tarea específica</b> como traducir o resumir. En su lugar, se le asignan tareas \"pretexto\" que lo obligan a entender y predecir el lenguaje. Las más comunes incluyen:\n",
        "<ul>\n",
        "  <li><b>Modelado de Lenguaje Causal (Causal Language Modeling - CLM)</b>: Típico de modelos como <b>GPT</b> (Generative Pre-trained Transformer). El modelo aprende a predecir el siguiente <b>token</b> (palabra o subpalabra) en una secuencia de <b>tokens</b>. Dado \"El gato se sentó en la...\", el modelo debe predecir \"alfombra\" o una palabra similarmente probable.</li>\n",
        "  <li><b>Modelado de Lenguaje Enmascarado (Masked Language Modeling - MLM)</b>: Característico de modelos como <b>BERT</b> (Bidirectional Encoder Representations from Transformers). En esta tarea, algunos <b>tokens</b> de la secuencia de entrada son aleatoriamente \"enmascarados\" (reemplazados por un <b>token</b> especial como `[MASK]`), y el modelo debe predecir cuáles eran los <b>tokens</b> originales basándose en el <b>contexto</b> de los <b>tokens</b> no enmascarados a su alrededor (tanto a la izquierda como a la derecha).</li>\n",
        "  <li><b>Predicción de la Siguiente Oración (Next Sentence Prediction - NSP)</b>: Utilizado originalmente por <b>BERT</b>, donde el modelo aprende a determinar si dos frases presentadas son consecutivas en el texto original o no. Aunque su utilidad ha sido debatida y a veces se omite en modelos más recientes.</li>\n",
        "</ul>\n",
        "A través de la optimización para estas tareas en un gigantesco <b>corpus textual</b>, el modelo ajusta sus <b>parámetros</b> mediante algoritmos de <b>aprendizaje profundo</b>, internalizando patrones estadísticos y semánticos complejos. Estas <b>representaciones lingüísticas</b> aprendidas son la base del <b>conocimiento general</b> del modelo.\n",
        "\"\"\"\n",
        "\n",
        "arquitectura = \"\"\"\n",
        "<h2>Arquitectura Predominante: El Poder del Transformer</h2>\n",
        "La mayoría de los <b>modelos de lenguaje</b> modernos se basan en la arquitectura <b>Transformer</b>, introducida en 2017. Esta arquitectura es particularmente efectiva para procesar datos secuenciales como el lenguaje natural debido a varias razones:\n",
        "<ul>\n",
        "  <li><b>Mecanismos de Auto-atención (Self-attention)</b>: Permiten al modelo sopesar la importancia de diferentes <b>tokens</b> en una secuencia al calcular la representación de cada <b>token</b>. Esto significa que puede capturar dependencias a larga distancia y entender cómo las palabras se relacionan entre sí, sin importar cuán separadas estén en el texto.</li>\n",
        "  <li><b>Procesamiento Paralelo</b>: A diferencia de arquitecturas recurrentes anteriores (como LSTMs o GRUs), los <b>Transformers</b> pueden procesar todos los <b>tokens</b> de una secuencia simultáneamente, lo que los hace altamente <b>escalables</b> y eficientes para entrenar en hardware moderno como <b>GPUs</b> (Unidades de Procesamiento Gráfico) y <b>TPUs</b> (Unidades de Procesamiento Tensorial).</li>\n",
        "  <li><b>Codificadores y Decodificadores</b>: Los modelos tipo <b>BERT</b> suelen usar la parte del \"codificador\" del <b>Transformer</b> para generar ricas <b>representaciones lingüísticas</b>. Los modelos tipo <b>GPT</b> utilizan la parte del \"decodificador\" para la generación de texto de manera <b>causal</b>.</li>\n",
        "</ul>\n",
        "El <b>pre-entrenamiento</b> de estos modelos implica optimizar arquitecturas con cientos de millones (ej. BERT-base) hasta billones (ej. GPT-3, PaLM) de <b>parámetros</b>, un proceso que es computacionalmente muy <b>costoso</b>.\n",
        "\"\"\"\n",
        "\n",
        "caracteristicas = \"\"\"\n",
        "<h2>Características Clave del Pre-entrenamiento</h2>\n",
        "El <b>pre-entrenamiento</b> se distingue por varias características fundamentales:\n",
        "<ul>\n",
        "  <li><b>Auto-supervisado (o No Supervisado)</b>: El modelo genera sus propias señales de supervisión a partir de los datos de entrada sin procesar (ej., predecir la siguiente palabra o una palabra enmascarada). No requiere etiquetas humanas costosas.</li>\n",
        "  <li><b>Escalable</b>: El rendimiento del <b>modelo de lenguaje</b> generalmente mejora con más datos, más <b>parámetros</b> y más cómputo. Esta propiedad de escalabilidad ha impulsado la creación de modelos cada vez más grandes y capaces.</li>\n",
        "  <li><b>Transferible y Fundacional</b>: El <b>conocimiento general</b> y las <b>representaciones lingüísticas</b> aprendidas durante el <b>pre-entrenamiento</b> son altamente <b>transferibles</b>. Sirven como una base sólida que luego puede ser adaptada a una amplia gama de tareas específicas de procesamiento del lenguaje natural mediante un proceso llamado <b>fine-tuning</b>.</li>\n",
        "  <li><b>Costoso</b>: Debido a la enorme cantidad de datos y al tamaño de los modelos, el <b>pre-entrenamiento</b> es una tarea computacionalmente intensiva y, por lo tanto, <b>costosa</b>, requiriendo semanas o meses de entrenamiento en clústeres de <b>GPUs</b> o <b>TPUs</b>.</li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "ejemplo = \"\"\"\n",
        "<h2>Ejemplo Práctico: ¿Cómo \"Sabe\" el Modelo?</h2>\n",
        "Imaginemos un <b>modelo de lenguaje</b> como <b>GPT</b> durante su <b>pre-entrenamiento</b>. Se le presenta la secuencia de <b>tokens</b>: <code>\"El sol brilla intensamente en el cielo...\"</code>. La tarea del modelo es predecir el siguiente <b>token</b>.\n",
        "<ul>\n",
        "    <li>Inicialmente, sus predicciones serán aleatorias.</li>\n",
        "    <li>Pero después de ver millones de ejemplos en su <b>corpus textual</b> donde secuencias similares son seguidas por palabras como \"azul\", \"despejado\", o signos de puntuación, el modelo ajusta sus <b>parámetros</b>.</li>\n",
        "    <li>Comienza a asignar una mayor <b>probabilidad</b> a \"azul\" después de \"El sol brilla intensamente en el cielo\".</li>\n",
        "</ul>\n",
        "No es que \"sepa\" conscientemente que el cielo es azul; más bien, ha aprendido una fuerte correlación estadística y contextual. Si se le da <code>“La capital de Francia es…”</code>, y ha visto innumerables veces \"La capital de Francia es París\" en sus datos de <b>pre-entrenamiento</b>, aprenderá a predecir \"París\" con alta <b>probabilidad</b> en ese <b>contexto</b>.\n",
        "\"\"\"\n",
        "\n",
        "relacion = \"\"\"\n",
        "<h2>Relación Crucial con el Fine-tuning</h2>\n",
        "El <b>pre-entrenamiento</b> dota al <b>modelo de lenguaje</b> de un vasto <b>conocimiento general</b> sobre el lenguaje y el mundo, tal como está representado en el texto. Sin embargo, para que el modelo sea útil en una <b>tarea específica</b> (como clasificación de sentimientos, respuesta a preguntas médicas, o generación de código), necesita una segunda fase de entrenamiento llamada <b>fine-tuning</b> (ajuste fino).\n",
        "<ul>\n",
        "    <li>Durante el <b>fine-tuning</b>, el modelo pre-entrenado se entrena adicionalmente con un conjunto de datos más pequeño y específico para la tarea, que sí suele estar etiquetado.</li>\n",
        "    <li>Este proceso adapta las <b>representaciones lingüísticas</b> generales aprendidas durante el <b>pre-entrenamiento</b> a los matices de la <b>tarea específica</b>.</li>\n",
        "    <li>El <b>fine-tuning</b> es significativamente menos <b>costoso</b> y requiere muchos menos datos que el <b>pre-entrenamiento</b> desde cero, gracias al conocimiento ya adquirido.</li>\n",
        "</ul>\n",
        "El <b>pre-entrenamiento</b> es, por tanto, el cimiento sobre el cual se construyen modelos especializados mediante <b>fine-tuning</b>.\n",
        "\"\"\"\n",
        "\n",
        "impacto_desafios = \"\"\"\n",
        "<h2>Impacto y Desafíos del Pre-entrenamiento</h2>\n",
        "El paradigma del <b>pre-entrenamiento</b> seguido de <b>fine-tuning</b> ha revolucionado el campo del Procesamiento del Lenguaje Natural (NLP), llevando a avances significativos en una multitud de aplicaciones.\n",
        "<p><b>Impacto:</b></p>\n",
        "<ul>\n",
        "    <li><b>Mejora del Rendimiento:</b> Los modelos pre-entrenados establecen consistentemente el estado del arte en muchos benchmarks de NLP.</li>\n",
        "    <li><b>Democratización (parcial):</b> Aunque el <b>pre-entrenamiento</b> es <b>costoso</b>, los modelos pre-entrenados suelen publicarse, permitiendo a investigadores y desarrolladores con menos recursos realizar <b>fine-tuning</b> para sus propias aplicaciones.</li>\n",
        "    <li><b>Nuevas Capacidades:</b> Han surgido capacidades como la generación de texto coherente y creativo, la traducción de alta calidad y la respuesta a preguntas complejas.</li>\n",
        "</ul>\n",
        "<p><b>Desafíos:</b></p>\n",
        "<ul>\n",
        "    <li><b>Sesgos en los Datos:</b> Los modelos pueden aprender y amplificar sesgos (sociales, de género, raciales) presentes en el masivo <b>corpus textual</b> de <b>pre-entrenamiento</b>.</li>\n",
        "    <li><b>Costo Computacional y Ambiental:</b> El <b>pre-entrenamiento</b> de los modelos más grandes consume una cantidad significativa de energía, lo que plantea preocupaciones ambientales.</li>\n",
        "    <li><b>Interpretabilidad:</b> Entender por qué un <b>modelo de lenguaje</b> grande toma una decisión particular (su \"razonamiento\") sigue siendo un área activa de investigación. Son a menudo \"cajas negras\".</li>\n",
        "    <li><b>Conocimiento Desactualizado:</b> El conocimiento del modelo está congelado al momento de su <b>pre-entrenamiento</b> y puede volverse obsoleto.</li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "conclusion_final = \"\"\"\n",
        "<h2>Conclusión: El Pilar de la Inteligencia Lingüística Artificial</h2>\n",
        "El <b>pre-entrenamiento</b> es, sin lugar a dudas, uno de los avances más significativos en la inteligencia artificial moderna. Al permitir que los <b>modelos de lenguaje</b> aprendan <b>representaciones lingüísticas</b> ricas y un amplio <b>conocimiento general</b> de manera <b>auto-supervisada</b> a partir de vastos corpus textuales, ha sentado las bases para la actual generación de LLMs. La arquitectura <b>Transformer</b>, con su mecanismo de <b>auto-atención</b>, ha sido el vehículo principal para este logro.\n",
        "<br><br>\n",
        "A pesar de ser un proceso <b>costoso</b> y presentar desafíos como los sesgos y la interpretabilidad, el conocimiento <b>transferible</b> obtenido durante el <b>pre-entrenamiento</b> es lo que permite luego, mediante <b>fine-tuning</b>, adaptar estos modelos a una miríada de tareas específicas con una eficiencia sin precedentes. Comprender el <b>pre-entrenamiento</b> es esencial para entender las capacidades y limitaciones de los <b>modelos de lenguaje</b> actuales y futuros.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# HTML + CSS visual y modo claro/oscuro\n",
        "css = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #1e88e5; /* Azul más vibrante */\n",
        "  --secondary-color: #00acc1; /* Cian */\n",
        "  --text-color: #37474f; /* Gris oscuro azulado */\n",
        "  --bg-color: #eceff1; /* Gris muy claro */\n",
        "  --container-bg: #ffffff;\n",
        "  --keyword-bg: #e0f7fa; /* Cian muy pálido */\n",
        "  --keyword-text: #00796b; /* Teal oscuro */\n",
        "  --shadow-color: rgba(0,0,0,0.1);\n",
        "  --pre-bg: #f5f5f5;\n",
        "  --pre-text: #212121;\n",
        "  --blockquote-bg: #e8f5e9; /* Verde muy pálido */\n",
        "  --blockquote-border: var(--secondary-color);\n",
        "  --table-border-color: #cfd8dc;\n",
        "  --row-bg-odd: #f9f9f9;\n",
        "  --row-bg-even: #ffffff;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #42a5f5; /* Azul claro */\n",
        "  --secondary-color: #26c6da; /* Cian claro */\n",
        "  --text-color: #e0e0e0; /* Gris claro */\n",
        "  --bg-color: #212121; /* Gris muy oscuro */\n",
        "  --container-bg: #303030; /* Gris oscuro */\n",
        "  --keyword-bg: #455a64; /* Gris azulado oscuro */\n",
        "  --keyword-text: #80deea; /* Cian pálido */\n",
        "  --shadow-color: rgba(0,0,0,0.4);\n",
        "  --pre-bg: #263238; /* Azul grisáceo oscuro */\n",
        "  --pre-text: #eceff1;\n",
        "  --blockquote-bg: #37474f; /* Gris azulado oscuro */\n",
        "  --blockquote-border: var(--secondary-color);\n",
        "  --table-border-color: #455a64;\n",
        "  --row-bg-odd: #3a3a3a;\n",
        "  --row-bg-even: #303030;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Roboto', 'Arial', sans-serif;\n",
        "  line-height: 1.75;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 20px;\n",
        "  margin: 0;\n",
        "}\n",
        ".container {\n",
        "  max-width: 950px;\n",
        "  margin: 30px auto;\n",
        "  padding: 25px 35px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 12px;\n",
        "  box-shadow: 0 5px 20px var(--shadow-color);\n",
        "  border-top: 7px solid var(--primary-color);\n",
        "  transition: background-color .3s, box-shadow .3s;\n",
        "}\n",
        "h1 {\n",
        "    color: var(--primary-color);\n",
        "    font-size: 2.4em;\n",
        "    margin-top: 0.5em;\n",
        "    margin-bottom: 0.6em;\n",
        "    border-bottom: 2px solid var(--secondary-color);\n",
        "    padding-bottom: 0.3em;\n",
        "}\n",
        "h2 {\n",
        "    color: var(--secondary-color);\n",
        "    margin-top: 2.2em;\n",
        "    margin-bottom: 0.8em;\n",
        "    font-size: 1.8em;\n",
        "    border-bottom: 1px solid #eee;\n",
        "    padding-bottom: 0.2em;\n",
        "}\n",
        "body.dark-mode h2 {\n",
        "    border-bottom: 1px solid #444;\n",
        "}\n",
        "h3 { /* Si se usan h3, este sería un buen estilo */\n",
        "    color: var(--primary-color);\n",
        "    margin-top: 1.8em;\n",
        "    margin-bottom: 0.6em;\n",
        "    font-size: 1.4em;\n",
        "}\n",
        "ul, ol {\n",
        "    margin-bottom:1.3em;\n",
        "    padding-left: 25px;\n",
        "}\n",
        "li {\n",
        "    margin-bottom:0.6em;\n",
        "}\n",
        "p {\n",
        "    margin-bottom: 1.2em;\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.18em 0.4em;\n",
        "  border-radius: 5px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        "pre {\n",
        "    background: var(--pre-bg);\n",
        "    color: var(--pre-text);\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 0.95em;\n",
        "    line-height: 1.5;\n",
        "    overflow-x: auto;\n",
        "    margin: 1em 0;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);\n",
        "}\n",
        "blockquote {\n",
        "    background: var(--blockquote-bg);\n",
        "    border-left: 6px solid var(--blockquote-border);\n",
        "    margin: 1.5em 0;\n",
        "    padding: 1em 1.5em;\n",
        "    font-style: italic;\n",
        "    border-radius: 0 8px 8px 0;\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--primary-color);\n",
        "  color: white;\n",
        "  border: none;\n",
        "  padding: 10px 18px;\n",
        "  border-radius: 6px;\n",
        "  cursor: pointer;\n",
        "  position: fixed; /* Fijado en la pantalla */\n",
        "  top: 20px;\n",
        "  right: 25px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, transform .2s;\n",
        "  z-index: 1000;\n",
        "  box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--secondary-color);\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 3px solid var(--secondary-color);\n",
        "    outline-offset: 2px;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "    }\n",
        "}\n",
        "\n",
        "function initializeTheme(buttonElement) {\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "\n",
        "    if (savedTheme === \"dark\" || (!savedTheme && prefersDark)) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        if (buttonElement) buttonElement.textContent = \"Modo Claro\";\n",
        "    } else {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        if (buttonElement) buttonElement.textContent = \"Modo Oscuro\";\n",
        "    }\n",
        "}\n",
        "\n",
        "window.onload = function() {\n",
        "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    if (!themeToggleButton) {\n",
        "        const button = document.createElement('button');\n",
        "        button.id = \"theme-toggle-btn\";\n",
        "        button.className = \"theme-toggle\";\n",
        "        button.title = \"Cambiar tema de color\";\n",
        "        button.onclick = toggleTheme;\n",
        "        // Añadir el botón al body si no existe\n",
        "        document.body.appendChild(button);\n",
        "        themeToggleButton = button; // Asignar el botón recién creado\n",
        "    }\n",
        "    initializeTheme(themeToggleButton);\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Armar el HTML final\n",
        "html_output = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{highlight_keywords(title, keywords)}</title>\n",
        "    {css}\n",
        "</head>\n",
        "<body>\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">Modo Oscuro</button>\n",
        "<div class=\"container\">\n",
        "  <h1>{highlight_keywords(title, keywords)}</h1>\n",
        "  {highlight_keywords(intro, keywords)}\n",
        "  {highlight_keywords(objetivo, keywords)}\n",
        "  {highlight_keywords(aprendizaje, keywords)}\n",
        "  {highlight_keywords(arquitectura, keywords)}\n",
        "  {highlight_keywords(caracteristicas, keywords)}\n",
        "  {highlight_keywords(ejemplo, keywords)}\n",
        "  {highlight_keywords(relacion, keywords)}\n",
        "  {highlight_keywords(impacto_desafios, keywords)}\n",
        "  {highlight_keywords(conclusion_final, keywords)}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHYIQfIo2RBa",
        "outputId": "932adc3d-219c-4d62-f59a-85d51426d9d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>El Viaje de un Prompt: De la Idea a la Respuesta del LLM</title>\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #1e88e5; /* Azul más vibrante */\n",
              "  --secondary-color: #00acc1; /* Cian */\n",
              "  --text-color: #37474f; /* Gris oscuro azulado */\n",
              "  --bg-color: #eceff1; /* Gris muy claro */\n",
              "  --container-bg: #ffffff;\n",
              "  --keyword-bg: #e0f7fa; /* Cian muy pálido */\n",
              "  --keyword-text: #00796b; /* Teal oscuro */\n",
              "  --shadow-color: rgba(0,0,0,0.1);\n",
              "  --pre-bg: #f5f5f5;\n",
              "  --pre-text: #212121;\n",
              "  --blockquote-bg: #e8f5e9; /* Verde muy pálido */\n",
              "  --blockquote-border: var(--secondary-color);\n",
              "  --table-border-color: #cfd8dc;\n",
              "  --row-bg-odd: #f9f9f9;\n",
              "  --row-bg-even: #ffffff;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #42a5f5; /* Azul claro */\n",
              "  --secondary-color: #26c6da; /* Cian claro */\n",
              "  --text-color: #e0e0e0; /* Gris claro */\n",
              "  --bg-color: #212121; /* Gris muy oscuro */\n",
              "  --container-bg: #303030; /* Gris oscuro */\n",
              "  --keyword-bg: #455a64; /* Gris azulado oscuro */\n",
              "  --keyword-text: #80deea; /* Cian pálido */\n",
              "  --shadow-color: rgba(0,0,0,0.4);\n",
              "  --pre-bg: #263238; /* Azul grisáceo oscuro */\n",
              "  --pre-text: #eceff1;\n",
              "  --blockquote-bg: #37474f; /* Gris azulado oscuro */\n",
              "  --blockquote-border: var(--secondary-color);\n",
              "  --table-border-color: #455a64;\n",
              "  --row-bg-odd: #3a3a3a;\n",
              "  --row-bg-even: #303030;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Roboto', 'Arial', sans-serif;\n",
              "  line-height: 1.75;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 20px;\n",
              "  margin: 0;\n",
              "}\n",
              ".container {\n",
              "  max-width: 950px;\n",
              "  margin: 30px auto;\n",
              "  padding: 25px 35px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 12px;\n",
              "  box-shadow: 0 5px 20px var(--shadow-color);\n",
              "  border-top: 7px solid var(--primary-color);\n",
              "  transition: background-color .3s, box-shadow .3s;\n",
              "}\n",
              "h1 {\n",
              "    color: var(--primary-color);\n",
              "    font-size: 2.4em;\n",
              "    margin-bottom: 0.6em;\n",
              "    border-bottom: 2px solid var(--secondary-color);\n",
              "    padding-bottom: 0.3em;\n",
              "}\n",
              "h2 {\n",
              "    color: var(--secondary-color);\n",
              "    margin-top: 2.2em;\n",
              "    margin-bottom: 0.8em;\n",
              "    font-size: 1.8em;\n",
              "    border-bottom: 1px solid #eee;\n",
              "    padding-bottom: 0.2em;\n",
              "}\n",
              "body.dark-mode h2 {\n",
              "    border-bottom: 1px solid #444;\n",
              "}\n",
              "h3 {\n",
              "    color: var(--primary-color);\n",
              "    margin-top: 1.8em;\n",
              "    margin-bottom: 0.6em;\n",
              "    font-size: 1.4em;\n",
              "}\n",
              "ul, ol {\n",
              "    margin-bottom:1.3em;\n",
              "    padding-left: 25px;\n",
              "}\n",
              "li {\n",
              "    margin-bottom:0.6em;\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.18em 0.4em;\n",
              "  border-radius: 5px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              "pre {\n",
              "    background: var(--pre-bg);\n",
              "    color: var(--pre-text);\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    border-radius: 8px;\n",
              "    padding: 12px 16px;\n",
              "    font-size: 0.95em;\n",
              "    line-height: 1.5;\n",
              "    overflow-x: auto;\n",
              "    margin: 1em 0;\n",
              "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);\n",
              "}\n",
              "blockquote {\n",
              "    background: var(--blockquote-bg);\n",
              "    border-left: 6px solid var(--blockquote-border);\n",
              "    margin: 1.5em 0;\n",
              "    padding: 1em 1.5em;\n",
              "    font-style: italic;\n",
              "    border-radius: 0 8px 8px 0;\n",
              "}\n",
              "table th, table td {\n",
              "    text-align: left;\n",
              "    vertical-align: top;\n",
              "}\n",
              "table th { font-weight: 600; }\n",
              "\n",
              ".theme-toggle {\n",
              "  background-color: var(--primary-color);\n",
              "  color: white;\n",
              "  border: none;\n",
              "  padding: 10px 18px;\n",
              "  border-radius: 6px;\n",
              "  cursor: pointer;\n",
              "  position: fixed; /* Fijado en la pantalla */\n",
              "  top: 20px;\n",
              "  right: 25px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, transform .2s;\n",
              "  z-index: 1000;\n",
              "  box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--secondary-color);\n",
              "    transform: translateY(-2px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 3px solid var(--secondary-color);\n",
              "    outline-offset: 2px;\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">Modo Oscuro</button>\n",
              "<div class=\"container\">\n",
              "  <h1>El Viaje de un <strong class=\"keyword\">Prompt</strong>: De la Idea a la Respuesta del LLM</h1>\n",
              "  \n",
              "<p>Los <b>modelos de lenguaje</b> grandes (LLMs) han revolucionado la forma en que interactuamos con la inteligencia artificial, capaces de generar texto, traducir idiomas, responder preguntas y mucho más. Pero, ¿qué sucede realmente cuando ingresamos un <b><strong class=\"keyword\">prompt</strong></b>? Este documento desglosa el fascinante flujo de procesamiento interno.</p>\n",
              "\n",
              "  \n",
              "<h2>¿Qué es un <strong class=\"keyword\">Prompt</strong>? El Punto de Partida</h2>\n",
              "El término <b><strong class=\"keyword\">prompt</strong></b> se refiere al <b><strong class=\"keyword\">texto inicial</strong>, instrucción o pregunta</b> que se le proporciona a un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> para guiar su comportamiento y solicitar una respuesta. Es el estímulo que desencadena la <b><strong class=\"keyword\">generación</strong></b> de texto, funcionando como el punto de partida que <b>define el <strong class=\"keyword\">contexto</strong></b>, la intención, el formato deseado y el estilo esperado del resultado.<br>\n",
              "Un <b><strong class=\"keyword\">prompt</strong></b> puede adoptar distintas formas:\n",
              "<ul>\n",
              "    <li>Una pregunta directa: <code>¿Cuáles son las aplicaciones principales de la <b><strong class=\"keyword\">auto-atención</strong></b> en los <b>Transformers</b>?</code></li>\n",
              "    <li>Una frase incompleta para continuar: <code>El futuro de la inteligencia artificial es prometedor porque...</code></li>\n",
              "    <li>Una orden o instrucción: <code>Resume el siguiente artículo sobre <b>embeddings</b> en tres frases:</code></li>\n",
              "    <li>Ejemplos que demuestran el formato o tarea deseada (aprendizaje por pocos disparos o <i>few-shot learning</i>): <br><code>Texto: ¡Qué película tan emocionante! → Sentimiento: positivo.<br>Texto: No me gustó nada el servicio. → Sentimiento: negativo.<br>Texto: El día estuvo bastante normal. → Sentimiento:</code></li>\n",
              "</ul>\n",
              "\n",
              "  \n",
              "<h3>La Importancia Crítica del <strong class=\"keyword\">Prompt</strong></h3>\n",
              "La <b>calidad, especificidad y claridad del <strong class=\"keyword\">prompt</strong></b> son fundamentales para obtener salidas coherentes, relevantes y útiles de un <b><strong class=\"keyword\">modelo de lenguaje</strong></b>. Un <b><strong class=\"keyword\">prompt</strong></b> bien diseñado:\n",
              "<ul>\n",
              "    <li>Reduce la ambigüedad y enfoca la tarea.</li>\n",
              "    <li>Establece el <b>tono, estilo, formato y contenido</b> esperado de la respuesta.</li>\n",
              "    <li>Aumenta significativamente la <b><strong class=\"keyword\">probabilidad</strong></b> de obtener una respuesta precisa y alineada con la intención del usuario.</li>\n",
              "    <li>Activa los <b>conocimientos y patrones relevantes</b> aprendidos por la <strong class=\"keyword\"><strong class=\"keyword\">red neuronal</strong></strong> durante su entrenamiento, guiándola hacia la información pertinente dentro de sus vastos <b><strong class=\"keyword\">parámetros</strong></b>.</li>\n",
              "</ul>\n",
              "\n",
              "  \n",
              "<h2>El Flujo Interno: ¿Qué Ocurre con un <strong class=\"keyword\">Prompt</strong> Dentro del Modelo?</h2>\n",
              "Una vez que el usuario introduce un <b><strong class=\"keyword\">prompt</strong></b>, el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> inicia un sofisticado proceso interno que se puede resumir en <b>cinco etapas clave</b>:\n",
              "<ol>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong></b> del <b><strong class=\"keyword\">texto inicial</strong></b>.</li>\n",
              "    <li><b>Conversión a Embeddings</b> (representación en el <b><strong class=\"keyword\">espacio latente</strong></b>).</li>\n",
              "    <li><b><strong class=\"keyword\">Procesamiento Contextual</strong></b> (usualmente mediante la arquitectura <b><strong class=\"keyword\">Transformer</strong></b> y su mecanismo de <b><strong class=\"keyword\">auto-atención</strong></b>).</li>\n",
              "    <li><b><strong class=\"keyword\">Generación</strong> del Siguiente <strong class=\"keyword\">Token</strong></b> (predicción basada en <b><strong class=\"keyword\">probabilidad</strong></b>).</li>\n",
              "    <li><b><strong class=\"keyword\">Decodificación</strong></b> a texto legible.</li>\n",
              "</ol>\n",
              "Este ciclo se repite para generar la respuesta completa, <b><strong class=\"keyword\">token</strong></b> por <b><strong class=\"keyword\">token</strong></b>.\n",
              "\n",
              "  \n",
              "<h3>1. <strong class=\"keyword\">Tokenización</strong>: Descomponiendo el Lenguaje</h3>\n",
              "El primer paso es la <b><strong class=\"keyword\">tokenización</strong></b>. El <b><strong class=\"keyword\">modelo de lenguaje</strong></b> convierte el <b><strong class=\"keyword\">texto inicial</strong></b> del <b><strong class=\"keyword\">prompt</strong></b> en una secuencia de unidades más pequeñas llamadas <b>tokens</b>. Estos <b>tokens</b> pueden ser palabras completas, subpalabras (ej., \"inteligentemente\" podría dividirse en \"inteligente\" y \"mente\"), o incluso caracteres individuales, dependiendo del tokenizador específico utilizado por el modelo.<br>\n",
              "A cada <b><strong class=\"keyword\">token</strong></b> se le asigna un <b><strong class=\"keyword\">ID de token</strong></b> único, que es un número entero. Estos números son la forma en que la <strong class=\"keyword\"><strong class=\"keyword\">red neuronal</strong></strong> puede procesar y entender el texto computacionalmente.\n",
              "<br>\n",
              "Ejemplo:\n",
              "<pre>\n",
              "<strong class=\"keyword\">Prompt</strong>: \"La inteligencia artificial cambiará el mundo.\"\n",
              "<strong class=\"keyword\">Tokenización</strong>: [\"La\", \" inteligencia\", \" artificial\", \" cambiará\", \" el\", \" mundo\", \".\"]\n",
              "IDs de tokens: [203, 15421, 3456, 8763, 132, 9231, 25] (Estos IDs son ilustrativos)\n",
              "</pre>\n",
              "La elección del vocabulario de <b>tokens</b> y el algoritmo de <b><strong class=\"keyword\">tokenización</strong></b> son cruciales para el rendimiento del modelo.\n",
              "\n",
              "  \n",
              "<h3>2. Conversión a Embeddings: Del <strong class=\"keyword\">Token</strong> al <strong class=\"keyword\">Espacio Latente</strong></h3>\n",
              "Una vez que el <b><strong class=\"keyword\">prompt</strong></b> está tokenizado, cada <b><strong class=\"keyword\">ID de token</strong></b> se convierte en un <b><strong class=\"keyword\">vector</strong> numérico denso de alta dimensión</b>, conocido como <b><strong class=\"keyword\">embedding</strong></b>. Estos <b>vectores</b> residen en un complejo <b><strong class=\"keyword\">espacio latente</strong></b> aprendido por el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> durante su fase de pre-entrenamiento con cantidades masivas de texto. <br>\n",
              "Las dimensiones de estos <b>vectores</b> pueden variar (ej., 768, 1024, 4096 o más, dependiendo del modelo).\n",
              "<ul>\n",
              "    <li>En este <b><strong class=\"keyword\">espacio latente</strong></b>, <b>tokens</b> con significados o usos contextuales similares tienden a tener <b>vectores</b> cercanos entre sí.</li>\n",
              "    <li>Este mapeo captura relaciones semánticas y sintácticas profundas entre los <b>tokens</b>.</li>\n",
              "</ul>\n",
              "Ejemplo (conceptual):\n",
              "<pre>\n",
              "<strong class=\"keyword\">ID de token</strong> 15421 (\"inteligencia\") → <b><strong class=\"keyword\">Embedding</strong></b>: [0.12, -0.45, 0.33, ..., -0.09, 0.07]  (un <b><strong class=\"keyword\">vector</strong></b>, por ejemplo, de 768 dimensiones)\n",
              "</pre>\n",
              "Estos <b>embeddings</b> son la entrada real para las capas de procesamiento de la <strong class=\"keyword\"><strong class=\"keyword\">red neuronal</strong></strong>.\n",
              "\n",
              "  \n",
              "<h3>3. <strong class=\"keyword\">Procesamiento Contextual</strong>: Entendiendo las Relaciones con Transformers</h3>\n",
              "Los <b>embeddings</b> de los <b>tokens</b> del <b><strong class=\"keyword\">prompt</strong></b> se procesan a través de las capas de la arquitectura <b><strong class=\"keyword\">Transformer</strong></b>, el corazón de la mayoría de los LLMs modernos. La característica clave aquí es el mecanismo de <b><strong class=\"keyword\">auto-atención</strong></b> (<i><strong class=\"keyword\">self-attention</strong></i>).\n",
              "<ul>\n",
              "    <li>La <b><strong class=\"keyword\">auto-atención</strong></b> permite al modelo sopesar la importancia de cada <b><strong class=\"keyword\">token</strong></b> en relación con todos los demás <b>tokens</b> del <b><strong class=\"keyword\">prompt</strong></b>. De esta forma, la representación de cada <b><strong class=\"keyword\">token</strong></b> se enriquece con información de su <b><strong class=\"keyword\">contexto</strong></b> completo.</li>\n",
              "    <li>El modelo evalúa cómo cada palabra (o <b><strong class=\"keyword\">token</strong></b>) se relaciona con las demás, sin importar su distancia en la secuencia.</li>\n",
              "    <li>Estos <b>vectores</b> contextualizados pasan a través de múltiples capas de la <strong class=\"keyword\"><strong class=\"keyword\">red neuronal</strong></strong> (apiladas en bloques <b><strong class=\"keyword\">Transformer</strong></b>), refinando progresivamente la comprensión del <b><strong class=\"keyword\">texto inicial</strong></b>. Cada capa combina la información de la capa anterior con los pesos aprendidos (<b><strong class=\"keyword\">parámetros</strong></b> del modelo).</li>\n",
              "</ul>\n",
              "Resultado: El modelo obtiene una comprensión profunda no solo del significado individual de cada <b><strong class=\"keyword\">token</strong></b>, sino de <b>su función y relevancia dentro del <strong class=\"keyword\"><strong class=\"keyword\">contexto</strong></strong> global</b> del <b><strong class=\"keyword\">prompt</strong></b>. Se crea una representación rica y contextualizada de la entrada.\n",
              "\n",
              "  \n",
              "<h3>4. <strong class=\"keyword\">Generación</strong> del Siguiente <strong class=\"keyword\">Token</strong>: La Predicción Creativa</h3>\n",
              "Con la representación contextualizada del <b><strong class=\"keyword\">prompt</strong></b> (y de los <b>tokens</b> ya generados en pasos anteriores, si los hay), el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> está listo para la <b><strong class=\"keyword\">generación</strong></b>.\n",
              "<ul>\n",
              "    <li>El modelo utiliza su estado interno para predecir el siguiente <b><strong class=\"keyword\">token</strong></b> más probable que debería seguir en la secuencia.</li>\n",
              "    <li>Esto se hace calculando una distribución de <b><strong class=\"keyword\">probabilidad</strong></b> sobre todo su vocabulario de <b>tokens</b>. Cada <b><strong class=\"keyword\">token</strong></b> en el vocabulario recibe una puntuación de <b><strong class=\"keyword\">probabilidad</strong></b>.</li>\n",
              "    <li>Generalmente, el <b><strong class=\"keyword\">token</strong></b> con la mayor <b><strong class=\"keyword\">probabilidad</strong></b> se selecciona (esto se conoce como <strong class=\"keyword\">decodificación</strong> voraz o <i>greedy decoding</i>), aunque existen otras estrategias de muestreo (top-k, nucleus sampling) para introducir variabilidad y creatividad.</li>\n",
              "    <li>Este nuevo <b><strong class=\"keyword\">token</strong></b> generado se añade a la secuencia de salida.</li>\n",
              "</ul>\n",
              "Este proceso es inherentemente auto-regresivo: el <b><strong class=\"keyword\">token</strong></b> recién generado se convierte en parte del <b><strong class=\"keyword\">contexto</strong></b> para la predicción del siguiente <b><strong class=\"keyword\">token</strong></b>.\n",
              "\n",
              "  \n",
              "<h3>5. <strong class=\"keyword\">Decodificación</strong>: De IDs de <strong class=\"keyword\">Token</strong> a Texto Humano</h3>\n",
              "El proceso de <b><strong class=\"keyword\">generación</strong></b> produce una secuencia de <b>IDs de <strong class=\"keyword\">token</strong></b>. La etapa final es la <b><strong class=\"keyword\">decodificación</strong></b>, que es el proceso inverso a la <b><strong class=\"keyword\">tokenización</strong></b>.\n",
              "<ul>\n",
              "    <li>Cada <b><strong class=\"keyword\">ID de token</strong></b> en la secuencia generada se convierte de nuevo en su representación textual (palabra, subpalabra o carácter).</li>\n",
              "    <li>Estos <b>tokens</b> se concatenan para formar la respuesta completa en lenguaje natural, legible por el usuario.</li>\n",
              "</ul>\n",
              "Ejemplo de salida tras la <b><strong class=\"keyword\">decodificación</strong></b>:\n",
              "<blockquote>\n",
              "<b>La inteligencia artificial cambiará el mundo</b>, especialmente en áreas como la medicina, la educación y la industria automotriz, impulsando innovaciones sin precedentes.\n",
              "</blockquote>\n",
              "El proceso de <b><strong class=\"keyword\">generación</strong></b> (paso 4) y <b><strong class=\"keyword\">decodificación</strong></b> (paso 5, para el <b><strong class=\"keyword\">token</strong></b> actual) se repite iterativamente hasta que el modelo genera un <b><strong class=\"keyword\">token</strong></b> especial de finalización (ej., `[EOS]`) o alcanza una longitud máxima predefinida.\n",
              "\n",
              "  \n",
              "<h2>Conclusión: Un Ciclo Sofisticado de Transformación</h2>\n",
              "El <b><strong class=\"keyword\">prompt</strong></b> es mucho más que una simple entrada; es la semilla que, mediante un sofisticado proceso de <b><strong class=\"keyword\">tokenización</strong></b>, mapeo a un <b><strong class=\"keyword\">espacio latente</strong></b> mediante <b>embeddings</b>, <b><strong class=\"keyword\">procesamiento contextual</strong></b> profundo con arquitecturas <b><strong class=\"keyword\">Transformer</strong></b> y su poderosa <b><strong class=\"keyword\">auto-atención</strong></b>, y una <b><strong class=\"keyword\">generación</strong></b> probabilística de <b>tokens</b> seguida de <b><strong class=\"keyword\">decodificación</strong></b>, florece en una <b>respuesta coherente y contextualmente relevante</b>.\n",
              "<br><br>\n",
              "Comprender este flujo, desde el <b><strong class=\"keyword\">texto inicial</strong></b> hasta la salida final, es clave no solo para apreciar la complejidad de estas <strong class=\"keyword\">redes neuronales</strong>, sino también para interactuar más eficazmente con cualquier <b><strong class=\"keyword\">modelo de lenguaje</strong></b> y diseñar <b>prompts</b> que maximicen su potencial.\n",
              "\n",
              "  \n",
              "<h3>Flujo Resumido en Etapas Clave</h3>\n",
              "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
              "<thead>\n",
              "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Etapa</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción Breve</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Entrada Principal</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Salida Principal</th>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Prompt</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Texto inicial</strong></b> proporcionado por el usuario.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">N/A (Inicio del proceso)</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (el <b><strong class=\"keyword\">prompt</strong></b>)</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Tokenización</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Fragmentación del texto en unidades básicas (<b>tokens</b>) y conversión a <b>IDs de <strong class=\"keyword\">token</strong></b> numéricos.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (<b><strong class=\"keyword\">prompt</strong></b>)</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de <strong class=\"keyword\">token</strong></b></td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Embeddings</b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cada <b><strong class=\"keyword\">ID de token</strong></b> se transforma en un <b><strong class=\"keyword\">vector</strong></b> numérico denso en el <b><strong class=\"keyword\">espacio latente</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de <strong class=\"keyword\">token</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>vectores</b> (<b>embeddings</b>)</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Procesamiento Contextual</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b>embeddings</b> son procesados por la <strong class=\"keyword\"><strong class=\"keyword\">red neuronal</strong></strong> (ej. <b><strong class=\"keyword\">Transformer</strong></b> con <b><strong class=\"keyword\">auto-atención</strong></b>) para entender el <b><strong class=\"keyword\">contexto</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>embeddings</b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>vectores</b> contextualizados</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Generación</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">El modelo predice el siguiente <b><strong class=\"keyword\">ID de token</strong></b> más probable basado en el <b><strong class=\"keyword\">contexto</strong></b> actual.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Representación contextualizada</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Un nuevo <b><strong class=\"keyword\">ID de token</strong></b> (y su <b><strong class=\"keyword\">probabilidad</strong></b>)</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Decodificación</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b>IDs de <strong class=\"keyword\">token</strong></b> generados se convierten de nuevo en texto legible.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de <strong class=\"keyword\">token</strong></b> generados</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (respuesta del modelo)</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "    }\n",
              "}\n",
              "\n",
              "function initializeTheme(buttonElement) {\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "\n",
              "    if (savedTheme === \"dark\" || (!savedTheme && prefersDark)) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        if (buttonElement) buttonElement.textContent = \"Modo Claro\";\n",
              "    } else {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        if (buttonElement) buttonElement.textContent = \"Modo Oscuro\";\n",
              "    }\n",
              "}\n",
              "\n",
              "window.onload = function() {\n",
              "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    if (!themeToggleButton) {\n",
              "        // Si el botón no está en el HTML inicial (puede pasar en algunos entornos como Colab a veces)\n",
              "        // crearlo y añadirlo al body.\n",
              "        const button = document.createElement('button');\n",
              "        button.id = \"theme-toggle-btn\";\n",
              "        button.className = \"theme-toggle\";\n",
              "        button.title = \"Cambiar tema de color\";\n",
              "        button.onclick = toggleTheme;\n",
              "        document.body.appendChild(button);\n",
              "        themeToggleButton = button; // Asignar el botón recién creado\n",
              "    }\n",
              "    initializeTheme(themeToggleButton);\n",
              "};\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "import re\n",
        "\n",
        "# Función para resaltar palabras clave\n",
        "def highlight_keywords(text, keywords):\n",
        "    # Ordenar keywords por longitud descendente para evitar coincidencias parciales (ej. \"token\" antes de \"tokenización\")\n",
        "    keywords_sorted = sorted(keywords, key=len, reverse=True)\n",
        "    pattern = '|'.join(r'(?<![\\w])(?:' + re.escape(kw) + r')(?![\\w])' for kw in keywords_sorted)\n",
        "    def replacer(match):\n",
        "        return f'<strong class=\"keyword\">{match.group(0)}</strong>'\n",
        "    return re.sub(pattern, replacer, text, flags=re.IGNORECASE)\n",
        "\n",
        "# Palabras clave a resaltar\n",
        "keywords = [\n",
        "    \"prompt\", \"tokenización\", \"token\", \"embedding\", \"espacio latente\",\n",
        "    \"procesamiento contextual\", \"Transformer\", \"auto-atención\", \"self-attention\",\n",
        "    \"generación\", \"decodificación\", \"modelo de lenguaje\", \"ID de token\",\n",
        "    \"vector\", \"probabilidad\", \"contexto\", \"parámetros\", \"texto inicial\", \"red neuronal\"\n",
        "]\n",
        "\n",
        "# Contenido estructurado\n",
        "title = \"El Viaje de un Prompt: De la Idea a la Respuesta del LLM\"\n",
        "\n",
        "intro_general = \"\"\"\n",
        "<p>Los <b>modelos de lenguaje</b> grandes (LLMs) han revolucionado la forma en que interactuamos con la inteligencia artificial, capaces de generar texto, traducir idiomas, responder preguntas y mucho más. Pero, ¿qué sucede realmente cuando ingresamos un <b>prompt</b>? Este documento desglosa el fascinante flujo de procesamiento interno.</p>\n",
        "\"\"\"\n",
        "\n",
        "prompt_section = \"\"\"\n",
        "<h2>¿Qué es un Prompt? El Punto de Partida</h2>\n",
        "El término <b>prompt</b> se refiere al <b>texto inicial, instrucción o pregunta</b> que se le proporciona a un <b>modelo de lenguaje</b> para guiar su comportamiento y solicitar una respuesta. Es el estímulo que desencadena la <b>generación</b> de texto, funcionando como el punto de partida que <b>define el contexto</b>, la intención, el formato deseado y el estilo esperado del resultado.<br>\n",
        "Un <b>prompt</b> puede adoptar distintas formas:\n",
        "<ul>\n",
        "    <li>Una pregunta directa: <code>¿Cuáles son las aplicaciones principales de la <b>auto-atención</b> en los <b>Transformers</b>?</code></li>\n",
        "    <li>Una frase incompleta para continuar: <code>El futuro de la inteligencia artificial es prometedor porque...</code></li>\n",
        "    <li>Una orden o instrucción: <code>Resume el siguiente artículo sobre <b>embeddings</b> en tres frases:</code></li>\n",
        "    <li>Ejemplos que demuestran el formato o tarea deseada (aprendizaje por pocos disparos o <i>few-shot learning</i>): <br><code>Texto: ¡Qué película tan emocionante! → Sentimiento: positivo.<br>Texto: No me gustó nada el servicio. → Sentimiento: negativo.<br>Texto: El día estuvo bastante normal. → Sentimiento:</code></li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "prompt_importance = \"\"\"\n",
        "<h3>La Importancia Crítica del Prompt</h3>\n",
        "La <b>calidad, especificidad y claridad del prompt</b> son fundamentales para obtener salidas coherentes, relevantes y útiles de un <b>modelo de lenguaje</b>. Un <b>prompt</b> bien diseñado:\n",
        "<ul>\n",
        "    <li>Reduce la ambigüedad y enfoca la tarea.</li>\n",
        "    <li>Establece el <b>tono, estilo, formato y contenido</b> esperado de la respuesta.</li>\n",
        "    <li>Aumenta significativamente la <b>probabilidad</b> de obtener una respuesta precisa y alineada con la intención del usuario.</li>\n",
        "    <li>Activa los <b>conocimientos y patrones relevantes</b> aprendidos por la <strong class=\"keyword\">red neuronal</strong> durante su entrenamiento, guiándola hacia la información pertinente dentro de sus vastos <b>parámetros</b>.</li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "flujo_intro = \"\"\"\n",
        "<h2>El Flujo Interno: ¿Qué Ocurre con un Prompt Dentro del Modelo?</h2>\n",
        "Una vez que el usuario introduce un <b>prompt</b>, el <b>modelo de lenguaje</b> inicia un sofisticado proceso interno que se puede resumir en <b>cinco etapas clave</b>:\n",
        "<ol>\n",
        "    <li><b>Tokenización</b> del <b>texto inicial</b>.</li>\n",
        "    <li><b>Conversión a Embeddings</b> (representación en el <b>espacio latente</b>).</li>\n",
        "    <li><b>Procesamiento Contextual</b> (usualmente mediante la arquitectura <b>Transformer</b> y su mecanismo de <b>auto-atención</b>).</li>\n",
        "    <li><b>Generación del Siguiente Token</b> (predicción basada en <b>probabilidad</b>).</li>\n",
        "    <li><b>Decodificación</b> a texto legible.</li>\n",
        "</ol>\n",
        "Este ciclo se repite para generar la respuesta completa, <b>token</b> por <b>token</b>.\n",
        "\"\"\"\n",
        "\n",
        "# Etapas del flujo\n",
        "tokenizacion = \"\"\"\n",
        "<h3>1. Tokenización: Descomponiendo el Lenguaje</h3>\n",
        "El primer paso es la <b>tokenización</b>. El <b>modelo de lenguaje</b> convierte el <b>texto inicial</b> del <b>prompt</b> en una secuencia de unidades más pequeñas llamadas <b>tokens</b>. Estos <b>tokens</b> pueden ser palabras completas, subpalabras (ej., \"inteligentemente\" podría dividirse en \"inteligente\" y \"mente\"), o incluso caracteres individuales, dependiendo del tokenizador específico utilizado por el modelo.<br>\n",
        "A cada <b>token</b> se le asigna un <b>ID de token</b> único, que es un número entero. Estos números son la forma en que la <strong class=\"keyword\">red neuronal</strong> puede procesar y entender el texto computacionalmente.\n",
        "<br>\n",
        "Ejemplo:\n",
        "<pre>\n",
        "Prompt: \"La inteligencia artificial cambiará el mundo.\"\n",
        "Tokenización: [\"La\", \" inteligencia\", \" artificial\", \" cambiará\", \" el\", \" mundo\", \".\"]\n",
        "IDs de tokens: [203, 15421, 3456, 8763, 132, 9231, 25] (Estos IDs son ilustrativos)\n",
        "</pre>\n",
        "La elección del vocabulario de <b>tokens</b> y el algoritmo de <b>tokenización</b> son cruciales para el rendimiento del modelo.\n",
        "\"\"\"\n",
        "\n",
        "espacio_latente = \"\"\"\n",
        "<h3>2. Conversión a Embeddings: Del Token al Espacio Latente</h3>\n",
        "Una vez que el <b>prompt</b> está tokenizado, cada <b>ID de token</b> se convierte en un <b>vector numérico denso de alta dimensión</b>, conocido como <b>embedding</b>. Estos <b>vectores</b> residen en un complejo <b>espacio latente</b> aprendido por el <b>modelo de lenguaje</b> durante su fase de pre-entrenamiento con cantidades masivas de texto. <br>\n",
        "Las dimensiones de estos <b>vectores</b> pueden variar (ej., 768, 1024, 4096 o más, dependiendo del modelo).\n",
        "<ul>\n",
        "    <li>En este <b>espacio latente</b>, <b>tokens</b> con significados o usos contextuales similares tienden a tener <b>vectores</b> cercanos entre sí.</li>\n",
        "    <li>Este mapeo captura relaciones semánticas y sintácticas profundas entre los <b>tokens</b>.</li>\n",
        "</ul>\n",
        "Ejemplo (conceptual):\n",
        "<pre>\n",
        "ID de token 15421 (\"inteligencia\") → <b>Embedding</b>: [0.12, -0.45, 0.33, ..., -0.09, 0.07]  (un <b>vector</b>, por ejemplo, de 768 dimensiones)\n",
        "</pre>\n",
        "Estos <b>embeddings</b> son la entrada real para las capas de procesamiento de la <strong class=\"keyword\">red neuronal</strong>.\n",
        "\"\"\"\n",
        "\n",
        "procesamiento_contextual = \"\"\"\n",
        "<h3>3. Procesamiento Contextual: Entendiendo las Relaciones con Transformers</h3>\n",
        "Los <b>embeddings</b> de los <b>tokens</b> del <b>prompt</b> se procesan a través de las capas de la arquitectura <b>Transformer</b>, el corazón de la mayoría de los LLMs modernos. La característica clave aquí es el mecanismo de <b>auto-atención</b> (<i>self-attention</i>).\n",
        "<ul>\n",
        "    <li>La <b>auto-atención</b> permite al modelo sopesar la importancia de cada <b>token</b> en relación con todos los demás <b>tokens</b> del <b>prompt</b>. De esta forma, la representación de cada <b>token</b> se enriquece con información de su <b>contexto</b> completo.</li>\n",
        "    <li>El modelo evalúa cómo cada palabra (o <b>token</b>) se relaciona con las demás, sin importar su distancia en la secuencia.</li>\n",
        "    <li>Estos <b>vectores</b> contextualizados pasan a través de múltiples capas de la <strong class=\"keyword\">red neuronal</strong> (apiladas en bloques <b>Transformer</b>), refinando progresivamente la comprensión del <b>texto inicial</b>. Cada capa combina la información de la capa anterior con los pesos aprendidos (<b>parámetros</b> del modelo).</li>\n",
        "</ul>\n",
        "Resultado: El modelo obtiene una comprensión profunda no solo del significado individual de cada <b>token</b>, sino de <b>su función y relevancia dentro del <strong class=\"keyword\">contexto</strong> global</b> del <b>prompt</b>. Se crea una representación rica y contextualizada de la entrada.\n",
        "\"\"\"\n",
        "\n",
        "generacion = \"\"\"\n",
        "<h3>4. Generación del Siguiente Token: La Predicción Creativa</h3>\n",
        "Con la representación contextualizada del <b>prompt</b> (y de los <b>tokens</b> ya generados en pasos anteriores, si los hay), el <b>modelo de lenguaje</b> está listo para la <b>generación</b>.\n",
        "<ul>\n",
        "    <li>El modelo utiliza su estado interno para predecir el siguiente <b>token</b> más probable que debería seguir en la secuencia.</li>\n",
        "    <li>Esto se hace calculando una distribución de <b>probabilidad</b> sobre todo su vocabulario de <b>tokens</b>. Cada <b>token</b> en el vocabulario recibe una puntuación de <b>probabilidad</b>.</li>\n",
        "    <li>Generalmente, el <b>token</b> con la mayor <b>probabilidad</b> se selecciona (esto se conoce como decodificación voraz o <i>greedy decoding</i>), aunque existen otras estrategias de muestreo (top-k, nucleus sampling) para introducir variabilidad y creatividad.</li>\n",
        "    <li>Este nuevo <b>token</b> generado se añade a la secuencia de salida.</li>\n",
        "</ul>\n",
        "Este proceso es inherentemente auto-regresivo: el <b>token</b> recién generado se convierte en parte del <b>contexto</b> para la predicción del siguiente <b>token</b>.\n",
        "\"\"\"\n",
        "\n",
        "decodificacion = \"\"\"\n",
        "<h3>5. Decodificación: De IDs de Token a Texto Humano</h3>\n",
        "El proceso de <b>generación</b> produce una secuencia de <b>IDs de token</b>. La etapa final es la <b>decodificación</b>, que es el proceso inverso a la <b>tokenización</b>.\n",
        "<ul>\n",
        "    <li>Cada <b>ID de token</b> en la secuencia generada se convierte de nuevo en su representación textual (palabra, subpalabra o carácter).</li>\n",
        "    <li>Estos <b>tokens</b> se concatenan para formar la respuesta completa en lenguaje natural, legible por el usuario.</li>\n",
        "</ul>\n",
        "Ejemplo de salida tras la <b>decodificación</b>:\n",
        "<blockquote>\n",
        "<b>La inteligencia artificial cambiará el mundo</b>, especialmente en áreas como la medicina, la educación y la industria automotriz, impulsando innovaciones sin precedentes.\n",
        "</blockquote>\n",
        "El proceso de <b>generación</b> (paso 4) y <b>decodificación</b> (paso 5, para el <b>token</b> actual) se repite iterativamente hasta que el modelo genera un <b>token</b> especial de finalización (ej., `[EOS]`) o alcanza una longitud máxima predefinida.\n",
        "\"\"\"\n",
        "\n",
        "conclusion = \"\"\"\n",
        "<h2>Conclusión: Un Ciclo Sofisticado de Transformación</h2>\n",
        "El <b>prompt</b> es mucho más que una simple entrada; es la semilla que, mediante un sofisticado proceso de <b>tokenización</b>, mapeo a un <b>espacio latente</b> mediante <b>embeddings</b>, <b>procesamiento contextual</b> profundo con arquitecturas <b>Transformer</b> y su poderosa <b>auto-atención</b>, y una <b>generación</b> probabilística de <b>tokens</b> seguida de <b>decodificación</b>, florece en una <b>respuesta coherente y contextualmente relevante</b>.\n",
        "<br><br>\n",
        "Comprender este flujo, desde el <b>texto inicial</b> hasta la salida final, es clave no solo para apreciar la complejidad de estas <strong class=\"keyword\">redes neuronales</strong>, sino también para interactuar más eficazmente con cualquier <b>modelo de lenguaje</b> y diseñar <b>prompts</b> que maximicen su potencial.\n",
        "\"\"\"\n",
        "\n",
        "# Resumen visual con tabla\n",
        "tabla = \"\"\"\n",
        "<h3>Flujo Resumido en Etapas Clave</h3>\n",
        "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
        "<thead>\n",
        "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Etapa</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción Breve</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Entrada Principal</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Salida Principal</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Prompt</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Texto inicial</b> proporcionado por el usuario.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">N/A (Inicio del proceso)</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (el <b>prompt</b>)</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Tokenización</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Fragmentación del texto en unidades básicas (<b>tokens</b>) y conversión a <b>IDs de token</b> numéricos.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (<b>prompt</b>)</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de token</b></td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Embeddings</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cada <b>ID de token</b> se transforma en un <b>vector</b> numérico denso en el <b>espacio latente</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de token</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>vectores</b> (<b>embeddings</b>)</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Procesamiento Contextual</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b>embeddings</b> son procesados por la <strong class=\"keyword\">red neuronal</strong> (ej. <b>Transformer</b> con <b>auto-atención</b>) para entender el <b>contexto</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>embeddings</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>vectores</b> contextualizados</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Generación</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">El modelo predice el siguiente <b>ID de token</b> más probable basado en el <b>contexto</b> actual.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Representación contextualizada</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Un nuevo <b>ID de token</b> (y su <b>probabilidad</b>)</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Decodificación</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b>IDs de token</b> generados se convierten de nuevo en texto legible.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Secuencia de <b>IDs de token</b> generados</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cadena de texto (respuesta del modelo)</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "# CSS y JS para modo claro/oscuro\n",
        "css = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #1e88e5; /* Azul más vibrante */\n",
        "  --secondary-color: #00acc1; /* Cian */\n",
        "  --text-color: #37474f; /* Gris oscuro azulado */\n",
        "  --bg-color: #eceff1; /* Gris muy claro */\n",
        "  --container-bg: #ffffff;\n",
        "  --keyword-bg: #e0f7fa; /* Cian muy pálido */\n",
        "  --keyword-text: #00796b; /* Teal oscuro */\n",
        "  --shadow-color: rgba(0,0,0,0.1);\n",
        "  --pre-bg: #f5f5f5;\n",
        "  --pre-text: #212121;\n",
        "  --blockquote-bg: #e8f5e9; /* Verde muy pálido */\n",
        "  --blockquote-border: var(--secondary-color);\n",
        "  --table-border-color: #cfd8dc;\n",
        "  --row-bg-odd: #f9f9f9;\n",
        "  --row-bg-even: #ffffff;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #42a5f5; /* Azul claro */\n",
        "  --secondary-color: #26c6da; /* Cian claro */\n",
        "  --text-color: #e0e0e0; /* Gris claro */\n",
        "  --bg-color: #212121; /* Gris muy oscuro */\n",
        "  --container-bg: #303030; /* Gris oscuro */\n",
        "  --keyword-bg: #455a64; /* Gris azulado oscuro */\n",
        "  --keyword-text: #80deea; /* Cian pálido */\n",
        "  --shadow-color: rgba(0,0,0,0.4);\n",
        "  --pre-bg: #263238; /* Azul grisáceo oscuro */\n",
        "  --pre-text: #eceff1;\n",
        "  --blockquote-bg: #37474f; /* Gris azulado oscuro */\n",
        "  --blockquote-border: var(--secondary-color);\n",
        "  --table-border-color: #455a64;\n",
        "  --row-bg-odd: #3a3a3a;\n",
        "  --row-bg-even: #303030;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Roboto', 'Arial', sans-serif;\n",
        "  line-height: 1.75;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 20px;\n",
        "  margin: 0;\n",
        "}\n",
        ".container {\n",
        "  max-width: 950px;\n",
        "  margin: 30px auto;\n",
        "  padding: 25px 35px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 12px;\n",
        "  box-shadow: 0 5px 20px var(--shadow-color);\n",
        "  border-top: 7px solid var(--primary-color);\n",
        "  transition: background-color .3s, box-shadow .3s;\n",
        "}\n",
        "h1 {\n",
        "    color: var(--primary-color);\n",
        "    font-size: 2.4em;\n",
        "    margin-bottom: 0.6em;\n",
        "    border-bottom: 2px solid var(--secondary-color);\n",
        "    padding-bottom: 0.3em;\n",
        "}\n",
        "h2 {\n",
        "    color: var(--secondary-color);\n",
        "    margin-top: 2.2em;\n",
        "    margin-bottom: 0.8em;\n",
        "    font-size: 1.8em;\n",
        "    border-bottom: 1px solid #eee;\n",
        "    padding-bottom: 0.2em;\n",
        "}\n",
        "body.dark-mode h2 {\n",
        "    border-bottom: 1px solid #444;\n",
        "}\n",
        "h3 {\n",
        "    color: var(--primary-color);\n",
        "    margin-top: 1.8em;\n",
        "    margin-bottom: 0.6em;\n",
        "    font-size: 1.4em;\n",
        "}\n",
        "ul, ol {\n",
        "    margin-bottom:1.3em;\n",
        "    padding-left: 25px;\n",
        "}\n",
        "li {\n",
        "    margin-bottom:0.6em;\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.18em 0.4em;\n",
        "  border-radius: 5px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        "pre {\n",
        "    background: var(--pre-bg);\n",
        "    color: var(--pre-text);\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 0.95em;\n",
        "    line-height: 1.5;\n",
        "    overflow-x: auto;\n",
        "    margin: 1em 0;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);\n",
        "}\n",
        "blockquote {\n",
        "    background: var(--blockquote-bg);\n",
        "    border-left: 6px solid var(--blockquote-border);\n",
        "    margin: 1.5em 0;\n",
        "    padding: 1em 1.5em;\n",
        "    font-style: italic;\n",
        "    border-radius: 0 8px 8px 0;\n",
        "}\n",
        "table th, table td {\n",
        "    text-align: left;\n",
        "    vertical-align: top;\n",
        "}\n",
        "table th { font-weight: 600; }\n",
        "\n",
        ".theme-toggle {\n",
        "  background-color: var(--primary-color);\n",
        "  color: white;\n",
        "  border: none;\n",
        "  padding: 10px 18px;\n",
        "  border-radius: 6px;\n",
        "  cursor: pointer;\n",
        "  position: fixed; /* Fijado en la pantalla */\n",
        "  top: 20px;\n",
        "  right: 25px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, transform .2s;\n",
        "  z-index: 1000;\n",
        "  box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--secondary-color);\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 3px solid var(--secondary-color);\n",
        "    outline-offset: 2px;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "    }\n",
        "}\n",
        "\n",
        "function initializeTheme(buttonElement) {\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "\n",
        "    if (savedTheme === \"dark\" || (!savedTheme && prefersDark)) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        if (buttonElement) buttonElement.textContent = \"Modo Claro\";\n",
        "    } else {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        if (buttonElement) buttonElement.textContent = \"Modo Oscuro\";\n",
        "    }\n",
        "}\n",
        "\n",
        "window.onload = function() {\n",
        "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    if (!themeToggleButton) {\n",
        "        // Si el botón no está en el HTML inicial (puede pasar en algunos entornos como Colab a veces)\n",
        "        // crearlo y añadirlo al body.\n",
        "        const button = document.createElement('button');\n",
        "        button.id = \"theme-toggle-btn\";\n",
        "        button.className = \"theme-toggle\";\n",
        "        button.title = \"Cambiar tema de color\";\n",
        "        button.onclick = toggleTheme;\n",
        "        document.body.appendChild(button);\n",
        "        themeToggleButton = button; // Asignar el botón recién creado\n",
        "    }\n",
        "    initializeTheme(themeToggleButton);\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Ensamblar el HTML\n",
        "html_content = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{title}</title>\n",
        "    {css}\n",
        "</head>\n",
        "<body>\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">Modo Oscuro</button>\n",
        "<div class=\"container\">\n",
        "  <h1>{highlight_keywords(title, keywords)}</h1>\n",
        "  {highlight_keywords(intro_general, keywords)}\n",
        "  {highlight_keywords(prompt_section, keywords)}\n",
        "  {highlight_keywords(prompt_importance, keywords)}\n",
        "  {highlight_keywords(flujo_intro, keywords)}\n",
        "  {highlight_keywords(tokenizacion, keywords)}\n",
        "  {highlight_keywords(espacio_latente, keywords)}\n",
        "  {highlight_keywords(procesamiento_contextual, keywords)}\n",
        "  {highlight_keywords(generacion, keywords)}\n",
        "  {highlight_keywords(decodificacion, keywords)}\n",
        "  {highlight_keywords(conclusion, keywords)}\n",
        "  {highlight_keywords(tabla, keywords)}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fvV7QWn17Kb7",
        "outputId": "68491151-f7ad-41b8-8663-b2f06c57f3bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>Tokens en NLP: La Piedra Angular del Procesamiento del Lenguaje Moderno</title>\n",
              "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #1e88e5;\n",
              "  --secondary-color: #00acc1;\n",
              "  --text-color: #37474f;\n",
              "  --bg-color: #f4f6f8;\n",
              "  --container-bg: #ffffff;\n",
              "  --keyword-bg: #e0f7fa;\n",
              "  --keyword-text: #00796b;\n",
              "  --button-bg: #e9ecef;\n",
              "  --button-hover-bg: #ced4da;\n",
              "  --button-text-color: #212529;\n",
              "  --shadow-color: rgba(0,0,0,0.08);\n",
              "  --table-border-color: #dee2e6;\n",
              "  --row-bg-odd: #f8f9fa;\n",
              "  --row-bg-even: #ffffff;\n",
              "  --pre-bg: #e9ecef;\n",
              "  --pre-text: #212529;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #42a5f5;\n",
              "  --secondary-color: #26c6da;\n",
              "  --text-color: #e0e0e0;\n",
              "  --bg-color: #121212;\n",
              "  --container-bg: #1e1e1e;\n",
              "  --keyword-bg: #37474f;\n",
              "  --keyword-text: #80deea;\n",
              "  --button-bg: #343a40;\n",
              "  --button-hover-bg: #495057;\n",
              "  --button-text-color: #f8f9fa;\n",
              "  --shadow-color: rgba(0,0,0,0.5);\n",
              "  --table-border-color: #495057;\n",
              "  --row-bg-odd: #2c3034;\n",
              "  --row-bg-even: #212529;\n",
              "  --pre-bg: #2c3034;\n",
              "  --pre-text: #f8f9fa;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Roboto', 'Arial', sans-serif;\n",
              "  line-height: 1.75;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 20px;\n",
              "  margin: 0;\n",
              "}\n",
              ".container {\n",
              "  max-width: 960px;\n",
              "  margin: 30px auto;\n",
              "  padding: 30px 40px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 12px;\n",
              "  box-shadow: 0 6px 18px var(--shadow-color);\n",
              "  position: relative;\n",
              "  transition: background-color .3s, box-shadow .3s;\n",
              "  border-top: 7px solid var(--primary-color);\n",
              "}\n",
              "h1 {\n",
              "  color: var(--primary-color);\n",
              "  font-size: 2.3em;\n",
              "  margin-bottom: .1em;\n",
              "  line-height: 1.25;\n",
              "  text-align: center;\n",
              "  border-bottom: 2px solid var(--secondary-color);\n",
              "  padding-bottom: 0.3em;\n",
              "}\n",
              "h2 {\n",
              "  color: var(--secondary-color);\n",
              "  text-align: left;\n",
              "  margin-top: 2.3em;\n",
              "  margin-bottom: .8em;\n",
              "  font-size: 1.7em;\n",
              "  border-bottom: 1px solid #ddd;\n",
              "  padding-bottom: 0.2em;\n",
              "}\n",
              "body.dark-mode h2 {\n",
              "    border-bottom: 1px solid #444;\n",
              "}\n",
              "h3 {\n",
              "  color: var(--primary-color);\n",
              "  margin-top: 1.8em;\n",
              "  margin-bottom: 0.6em;\n",
              "  font-size: 1.4em;\n",
              "}\n",
              ".subtitle-style {\n",
              "  font-style:italic;\n",
              "  font-weight:400;\n",
              "  color: var(--text-color);\n",
              "  opacity: 0.85;\n",
              "  text-align:center;\n",
              "  margin-top:0.2em;\n",
              "  margin-bottom: 1.5em;\n",
              "  font-size: 1.1em;\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.2em 0.4em;\n",
              "  border-radius: 5px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--button-bg);\n",
              "  color: var(--button-text-color);\n",
              "  border: 1.5px solid var(--secondary-color);\n",
              "  padding: 9px 14px;\n",
              "  border-radius: 6px;\n",
              "  cursor: pointer;\n",
              "  position: fixed;\n",
              "  top: 20px;\n",
              "  right: 25px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
              "  z-index: 1000;\n",
              "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--button-hover-bg);\n",
              "    transform: translateY(-1px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 3px solid var(--primary-color);\n",
              "    outline-offset: 2px;\n",
              "    border-color: var(--primary-color);\n",
              "}\n",
              "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
              "li { margin-bottom:0.6em; }\n",
              "b { color: var(--primary-color); font-weight: 600;}\n",
              "table {\n",
              "    font-size:0.95em;\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    width: 100%; /* Asegurar que la tabla ocupe el ancho */\n",
              "    border-collapse: collapse; /* Para que los bordes se fusionen bien */\n",
              "}\n",
              "table th, table td {\n",
              "    padding:10px 12px !important;\n",
              "    border:1px solid var(--table-border-color) !important;\n",
              "    text-align: left;\n",
              "    vertical-align: top;\n",
              "}\n",
              "table th { font-weight: 600; background-color: var(--row-bg-odd); } /* Fondo para headers */\n",
              "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
              "\n",
              "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "\n",
              "\n",
              "pre {\n",
              "    background: var(--pre-bg);\n",
              "    color: var(--pre-text);\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    border-radius: 8px;\n",
              "    padding: 12px 16px;\n",
              "    font-size: 0.9em;\n",
              "    line-height: 1.6;\n",
              "    overflow-x: auto;\n",
              "    margin: 1.2em 0;\n",
              "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
              "}\n",
              "code.language-python, code.nohighlight {\n",
              "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
              "<div class=\"container\">\n",
              "    <h1><strong class=\"keyword\">Tokens</strong> en <strong class=\"keyword\">NLP</strong>: La Piedra Angular del Procesamiento del Lenguaje Moderno</h1><p class='subtitle-style'>Definición, Tipos, Algoritmos de <strong class=\"keyword\">Tokenización</strong>, Relevancia y Desafíos en Modelos como <strong class=\"keyword\">GPT</strong> y <strong class=\"keyword\">BERT</strong></p><div style='margin-top: 1.3em;'>\n",
              "En el corazón del <b>Procesamiento de Lenguaje Natural (<strong class=\"keyword\">NLP</strong>)</b> moderno, el concepto de <b><strong class=\"keyword\">token</strong></b> es fundamental. Un <b><strong class=\"keyword\">token</strong></b> es una secuencia de <b><strong class=\"keyword\">caracteres</strong></b> agrupada como una unidad semántica útil para el procesamiento. Es la unidad mínima de texto que un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> como <b><strong class=\"keyword\">GPT</strong></b>, <b><strong class=\"keyword\">BERT</strong></b> o <b><strong class=\"keyword\">T5</strong></b> ingiere y procesa. Estos modelos no entienden el lenguaje humano directamente como palabras o frases completas; en su lugar, dependen de un proceso crucial llamado <b><strong class=\"keyword\">tokenización</strong></b>.<br><br>\n",
              "La <b><strong class=\"keyword\">tokenización</strong></b> es el primer paso para convertir el texto crudo en un formato que una <b><strong class=\"keyword\">red neuronal</strong></b> pueda entender: una secuencia de <b><strong class=\"keyword\">tokens</strong></b>. Posteriormente, cada uno de estos <b><strong class=\"keyword\">tokens</strong></b> es transformado en <b><strong class=\"keyword\">representaciones numéricas</strong></b> (conocidas como <b>embeddings</b> o <b>vectores</b>), que son la verdadera <b><strong class=\"keyword\">entrada</strong></b> para los complejos cálculos dentro de la arquitectura <b><strong class=\"keyword\">Transformer</strong></b>.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>¿Qué Puede Ser un <strong class=\"keyword\">Token</strong> Exactamente?</h2>\n",
              "La naturaleza de un <b><strong class=\"keyword\">token</strong></b> no es fija; depende intrínsecamente del algoritmo de <b><strong class=\"keyword\">tokenización</strong></b> (el <b><strong class=\"keyword\">tokenizador</strong></b>) específico que utilice un <b><strong class=\"keyword\">modelo de lenguaje</strong></b>. Un <b><strong class=\"keyword\">token</strong></b> puede representar:\n",
              "<ul>\n",
              "    <li>Una <b><strong class=\"keyword\">palabra</strong> completa</b>: Por ejemplo, en un <strong class=\"keyword\">tokenizador</strong> simple, \"aprendizaje\" podría ser un único <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "    <li>Una <b><strong class=\"keyword\">subpalabra</strong></b> (o parte de una <strong class=\"keyword\">palabra</strong>): Es muy común en modelos avanzados. Por ejemplo, \"<strong class=\"keyword\">tokenización</strong>\" podría dividirse en <b><strong class=\"keyword\">tokens</strong></b> como \"<strong class=\"keyword\">token</strong>\", \"ización\". Esto ayuda a manejar palabras raras o nuevas.</li>\n",
              "    <li>Un solo <b>carácter</b>: En algunos enfoques, cada letra o <b><strong class=\"keyword\">símbolo</strong></b> (e.g., 'a', '$', '.') puede ser un <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "    <li>Puntuación y <b>símbolos especiales</b>: <strong class=\"keyword\">Caracteres</strong> como '.', ',', '?', '@' suelen ser <b><strong class=\"keyword\">tokens</strong></b> individuales.</li>\n",
              "    <li><b>Espacios en blanco</b>: Algunos <b>tokenizadores</b>, como los usados por <b><strong class=\"keyword\">OpenAI</strong></b> (ej. <b><strong class=\"keyword\">tiktoken</strong></b>), pueden incluir el <b><strong class=\"keyword\">espacio</strong></b> precedente como parte del <b><strong class=\"keyword\">token</strong></b> (ej. \" <strong class=\"keyword\">palabra</strong>\" en lugar de \"<strong class=\"keyword\">palabra</strong>\").</li>\n",
              "</ul>\n",
              "La elección del tipo de <b><strong class=\"keyword\">token</strong></b> es un compromiso entre el tamaño del <b><strong class=\"keyword\">vocabulario</strong></b> del modelo y la longitud de las secuencias de <b><strong class=\"keyword\">tokens</strong></b> resultantes.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>¿Por Qué <strong class=\"keyword\">Tokenizar</strong>? ¿Por Qué no Usar Palabras o <strong class=\"keyword\">Caracteres</strong> Directamente?</h2>\n",
              "Los <b>modelos de lenguaje</b> necesitan procesar el texto de manera eficiente y manejar la vasta diversidad del lenguaje humano.\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong> basada en palabras:</b>\n",
              "        <ul>\n",
              "            <li><b>Problema:</b> Genera vocabularios gigantescos (cientos de miles o millones de palabras únicas). Muchas palabras serían raras (Out-of-Vocabulary u <b><strong class=\"keyword\">OOV</strong></b>), dificultando que el modelo aprenda buenas <b><strong class=\"keyword\">representaciones numéricas</strong></b> para ellas. ¿Cómo manejar \"supercalifragilisticoespialidoso\" o neologismos como \"GPTizar\"?</li>\n",
              "            <li><b>Solución con subpalabras:</b> Las palabras raras pueden formarse a partir de <b>subpalabras</b> comunes.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong> basada en <strong class=\"keyword\">caracteres</strong>:</b>\n",
              "        <ul>\n",
              "            <li><b>Problema:</b> Aunque el <b><strong class=\"keyword\">vocabulario</strong></b> es muy pequeño (solo el alfabeto, números y símbolos), las secuencias de <b><strong class=\"keyword\">tokens</strong></b> resultantes serían extremadamente largas (ej., una frase de 10 palabras podría tener 50-70 <b><strong class=\"keyword\">caracteres</strong></b>/<b><strong class=\"keyword\">tokens</strong></b>). Esto aumenta drásticamente la carga computacional y dificulta que los modelos capturen dependencias a larga distancia.</li>\n",
              "            <li><b>Solución con subpalabras:</b> Logra un equilibrio, manteniendo secuencias más cortas que los <b><strong class=\"keyword\">caracteres</strong></b> y un <b><strong class=\"keyword\">vocabulario</strong></b> más manejable que las palabras.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "</ul>\n",
              "La <b><strong class=\"keyword\">tokenización</strong></b> basada en <b>subpalabras</b> ofrece un equilibrio óptimo, permitiendo a los modelos manejar un <b><strong class=\"keyword\">vocabulario</strong></b> finito y representar cualquier <strong class=\"keyword\">palabra</strong>, incluso las no vistas durante el <b><strong class=\"keyword\">preentrenamiento</strong></b>.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>Principales Tipos de Algoritmos de <strong class=\"keyword\">Tokenización</strong></h2>\n",
              "Existen varios enfoques para la <b><strong class=\"keyword\">tokenización</strong></b>, cada uno con sus ventajas y desventajas:\n",
              "<ol>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong> Basada en Palabras (Word-based):</b>\n",
              "        <ul>\n",
              "            <li><b>Descripción:</b> Divide el texto utilizando delimitadores como <b>espacios</b> y signos de puntuación.</li>\n",
              "            <li><b>Ejemplo:</b> <code>\"El <b><strong class=\"keyword\">modelo de lenguaje</strong></b> es potente.\" → [\"El\", \"<b><strong class=\"keyword\">modelo de lenguaje</strong></b>\", \"es\", \"potente\", \".\"]</code></li>\n",
              "            <li><b>Ventajas:</b> Simple e intuitivo.</li>\n",
              "            <li><b>Desventajas:</b> Vocabularios enormes, problemas con palabras <b><strong class=\"keyword\">OOV</strong></b>, dificultades con idiomas aglutinantes (ej. alemán, turco) o sin segmentación clara de palabras (ej. chino, japonés). Sensible a errores tipográficos.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong> Basada en <strong class=\"keyword\">Caracteres</strong> (Character-based):</b>\n",
              "        <ul>\n",
              "            <li><b>Descripción:</b> Cada <b>carácter</b> individual se considera un <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "            <li><b>Ejemplo:</b> <code>\"<b><strong class=\"keyword\">GPT</strong></b>\" → [\"G\", \"P\", \"T\"]</code></li>\n",
              "            <li><b>Ventajas:</b> <b><strong class=\"keyword\">Vocabulario</strong></b> muy pequeño y fijo, sin problemas de <b><strong class=\"keyword\">OOV</strong></b>.</li>\n",
              "            <li><b>Desventajas:</b> Secuencias de <b><strong class=\"keyword\">tokens</strong></b> muy largas, lo que incrementa la complejidad computacional para el <b><strong class=\"keyword\">modelo de lenguaje</strong></b>. Un <b><strong class=\"keyword\">token</strong></b> individual (un carácter) tiene poco significado semántico por sí solo.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b><strong class=\"keyword\">Tokenización</strong> Basada en Subpalabras (Subword-based):</b>\n",
              "        <ul>\n",
              "            <li><b>Descripción:</b> Es el enfoque dominante en los <b>modelos de lenguaje</b> modernos como <b><strong class=\"keyword\">GPT</strong></b>, <b><strong class=\"keyword\">BERT</strong></b> y <b><strong class=\"keyword\">T5</strong></b>. Busca un equilibrio dividiendo palabras en unidades de <b>subpalabras</b> más pequeñas y significativas, aprendidas estadísticamente a partir de un gran <b><strong class=\"keyword\">corpus</strong></b>. Las palabras comunes pueden ser <b><strong class=\"keyword\">tokens</strong></b> únicos, mientras que las palabras raras se descomponen en múltiples <b>subpalabras</b>.</li>\n",
              "            <li><b>Algoritmos Comunes:</b>\n",
              "                <ul>\n",
              "                    <li><b><strong class=\"keyword\">Byte Pair Encoding</strong> (<strong class=\"keyword\">BPE</strong>):</b> Comienza con un <b><strong class=\"keyword\">vocabulario</strong></b> de <b><strong class=\"keyword\">caracteres</strong></b> individuales y fusiona iterativamente los pares de <b><strong class=\"keyword\">tokens</strong></b> más frecuentes para formar nuevas <b>subpalabras</b> hasta alcanzar un tamaño de <b><strong class=\"keyword\">vocabulario</strong></b> deseado. Usado por <b><strong class=\"keyword\">GPT</strong></b>.</li>\n",
              "                    <li><b><strong class=\"keyword\">WordPiece</strong>:</b> Similar a <b><strong class=\"keyword\">BPE</strong></b>, pero utiliza un criterio de probabilidad (likelihood) para decidir las fusiones. Usado por <b><strong class=\"keyword\">BERT</strong></b>.</li>\n",
              "                    <li><b><strong class=\"keyword\">SentencePiece</strong>:</b> Trata el texto de <b><strong class=\"keyword\">entrada</strong></b> como una secuencia cruda (incluyendo <b>espacios</b>) y <b>tokeniza</b> directamente a partir de ella, a menudo usando <strong class=\"keyword\">BPE</strong> o unigram language model. Es útil para idiomas sin delimitadores de palabras claros.</li>\n",
              "                </ul>\n",
              "            </li>\n",
              "            <li><b>Ejemplo (conceptual):</b> <code>\"<b><strong class=\"keyword\">tokenización</strong></b> increíble\" → [\"<strong class=\"keyword\">token</strong>\", \"ización\", \" increí\", \"ble\"]</code></li>\n",
              "            <li><b>Ventajas:</b> Maneja palabras <b><strong class=\"keyword\">OOV</strong></b> eficazmente, controla el tamaño del <b><strong class=\"keyword\">vocabulario</strong></b>, produce secuencias de longitud razonable, y las <b>subpalabras</b> pueden retener cierto significado semántico.</li>\n",
              "            <li><b>Desventajas:</b> La <b><strong class=\"keyword\">tokenización</strong></b> puede no ser siempre intuitiva para los humanos. La segmentación puede variar entre diferentes <b>tokenizadores</b>.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "</ol>\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>El <strong class=\"keyword\">Vocabulario</strong> del <strong class=\"keyword\">Tokenizador</strong></h2>\n",
              "Cada <b><strong class=\"keyword\">tokenizador</strong></b> tiene un <b><strong class=\"keyword\">vocabulario</strong></b> predefinido: un conjunto finito de todos los posibles <b><strong class=\"keyword\">tokens</strong></b> que puede generar.\n",
              "<ul>\n",
              "    <li>Este <b><strong class=\"keyword\">vocabulario</strong></b> se construye durante el <b><strong class=\"keyword\">preentrenamiento</strong></b> del <b><strong class=\"keyword\">tokenizador</strong></b> sobre un gran <b><strong class=\"keyword\">corpus</strong></b> de texto.</li>\n",
              "    <li>El tamaño del <b><strong class=\"keyword\">vocabulario</strong></b> es un hiperparámetro importante. Por ejemplo, el <b><strong class=\"keyword\">tokenizador</strong></b> \"cl100k_base\" de <b><strong class=\"keyword\">OpenAI</strong></b> (usado para <b><strong class=\"keyword\">GPT</strong></b>-3.5-turbo y <b><strong class=\"keyword\">GPT</strong></b>-4) tiene un <b><strong class=\"keyword\">vocabulario</strong></b> de aproximadamente 100,000 <b><strong class=\"keyword\">tokens</strong></b>.</li>\n",
              "    <li>Cada <b><strong class=\"keyword\">token</strong></b> en el <b><strong class=\"keyword\">vocabulario</strong></b> tiene asociado un ID numérico único. Es esta secuencia de IDs la que finalmente se pasa al <b><strong class=\"keyword\">modelo de lenguaje</strong></b>.</li>\n",
              "</ul>\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2><strong class=\"keyword\">Tokens Especiales</strong></h2>\n",
              "Muchos <b>tokenizadores</b> incluyen <b><strong class=\"keyword\">tokens especiales</strong></b> que tienen un significado particular para el <b><strong class=\"keyword\">modelo de lenguaje</strong></b>:\n",
              "<ul>\n",
              "    <li><code><b>[CLS]</b></code> (Classification): A menudo se añade al inicio de una secuencia de <b><strong class=\"keyword\">entrada</strong></b> en modelos como <b><strong class=\"keyword\">BERT</strong></b>. El <b><strong class=\"keyword\">embedding</strong></b> correspondiente a este <b><strong class=\"keyword\">token</strong></b> se usa como una representación agregada de toda la secuencia para tareas de clasificación.</li>\n",
              "    <li><code><b>[SEP]</b></code> (Separator): Se utiliza para separar diferentes segmentos de texto en la <b><strong class=\"keyword\">entrada</strong></b>, como dos oraciones en tareas de inferencia de lenguaje natural o pregunta y <b><strong class=\"keyword\">contexto</strong></b> en tareas de respuesta a preguntas (ej., en <b><strong class=\"keyword\">BERT</strong></b>).</li>\n",
              "    <li><code><b>[PAD]</b></code> (Padding): Si las secuencias de <b><strong class=\"keyword\">entrada</strong></b> a un modelo deben tener una longitud fija (común en el procesamiento por lotes), las secuencias más cortas se rellenan con <b><strong class=\"keyword\">tokens</strong></b> <b>[PAD]</b> hasta alcanzar la longitud deseada. El modelo suele estar entrenado para ignorar estos <b><strong class=\"keyword\">tokens</strong></b>.</li>\n",
              "    <li><code><b>[UNK]</b></code> (Unknown): Representa <b><strong class=\"keyword\">tokens</strong></b> que no están en el <b><strong class=\"keyword\">vocabulario</strong></b> del <b><strong class=\"keyword\">tokenizador</strong></b>. Aunque los tokenizadores de <b>subpalabras</b> reducen drásticamente la necesidad de <b>[UNK]</b>, aún pueden ocurrir con <b><strong class=\"keyword\">caracteres</strong></b> o secuencias muy inusuales.</li>\n",
              "    <li><code><b>[MASK]</b></code>: Usado en tareas de Modelado de Lenguaje Enmascarado (MLM), como en <b><strong class=\"keyword\">BERT</strong></b>, donde el modelo debe predecir el <b><strong class=\"keyword\">token</strong></b> original que fue reemplazado por <b>[MASK]</b>.</li>\n",
              "</ul>\n",
              "Estos <b><strong class=\"keyword\">tokens especiales</strong></b> son cruciales para dar formato a la <b><strong class=\"keyword\">entrada</strong></b> de manera que el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> pueda realizar tareas específicas.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>Ejemplo Práctico: <strong class=\"keyword\">Tokenización</strong> con `<strong class=\"keyword\">tiktoken</strong>` de <strong class=\"keyword\">OpenAI</strong></h2>\n",
              "Los modelos <b><strong class=\"keyword\">GPT</strong></b> de <b><strong class=\"keyword\">OpenAI</strong></b> utilizan un <b><strong class=\"keyword\">tokenizador</strong></b> basado en <b><strong class=\"keyword\">BPE</strong></b>. La librería <b><strong class=\"keyword\">tiktoken</strong></b> permite replicar esta <b><strong class=\"keyword\">tokenización</strong></b>.\n",
              "Consideremos la frase: <code>\"¡La <b><strong class=\"keyword\">tokenización</strong></b> en <b><strong class=\"keyword\">NLP</strong></b> es fascinante!\"</code>\n",
              "Usando el <b><strong class=\"keyword\">tokenizador</strong></b> \"cl100k_base\" (compatible con <strong class=\"keyword\">gpt</strong>-4, <strong class=\"keyword\">gpt</strong>-3.5-turbo):\n",
              "<pre><code class=\"language-python\">\n",
              "import <strong class=\"keyword\">tiktoken</strong>\n",
              "\n",
              "# Cargar el <strong class=\"keyword\">tokenizador</strong> para modelos como <strong class=\"keyword\">GPT</strong>-4\n",
              "tokenizer = <strong class=\"keyword\">tiktoken</strong>.get_encoding(\"cl100k_base\")\n",
              "\n",
              "texto = \"¡La <strong class=\"keyword\">tokenización</strong> en <strong class=\"keyword\">NLP</strong> es fascinante!\"\n",
              "encoded_tokens_ids = tokenizer.encode(texto)\n",
              "decoded_tokens = [tokenizer.decode_single_token_bytes(token_id).decode('utf-8', errors='replace') for token_id in encoded_tokens_ids]\n",
              "\n",
              "print(f\"Texto original: {texto}\")\n",
              "print(f\"IDs de <strong class=\"keyword\">Tokens</strong>: {encoded_tokens_ids}\")\n",
              "print(f\"<strong class=\"keyword\">Tokens</strong> decodificados: {decoded_tokens}\")\n",
              "print(f\"Número de <strong class=\"keyword\">tokens</strong>: {len(encoded_tokens_ids)}\")\n",
              "</code></pre>\n",
              "<strong class=\"keyword\">Salida</strong> (ejemplo ilustrativo, puede variar ligeramente):\n",
              "<pre><code class=\"nohighlight\">\n",
              "Texto original: ¡La <strong class=\"keyword\">tokenización</strong> en <strong class=\"keyword\">NLP</strong> es fascinante!\n",
              "IDs de <strong class=\"keyword\">Tokens</strong>: [89118, 284, 2000, 7900, 495, 19193, 669, 44758, 29991, 0] # IDs ilustrativos, variarán\n",
              "<strong class=\"keyword\">Tokens</strong> decodificados: ['¡', 'La', ' <strong class=\"keyword\">token</strong>', 'ización', ' en', ' <strong class=\"keyword\">NLP</strong>', ' es', ' fascinante', '!', ''] # La decodificación puede variar\n",
              "Número de <strong class=\"keyword\">tokens</strong>: 10\n",
              "</code></pre>\n",
              "Observaciones:\n",
              "<ul>\n",
              "    <li>\"<strong class=\"keyword\">tokenización</strong>\" se divide en \" <strong class=\"keyword\">token</strong>\" e \"ización\". El <b><strong class=\"keyword\">espacio</strong></b> antes de \"<strong class=\"keyword\">token</strong>\" es parte del primer <b><strong class=\"keyword\">token</strong></b> de <b><strong class=\"keyword\">subpalabra</strong></b>.</li>\n",
              "    <li>\"<strong class=\"keyword\">NLP</strong>\" es un solo <b><strong class=\"keyword\">token</strong></b>, probablemente porque es una sigla común en el <b><strong class=\"keyword\">corpus</strong></b> de <b><strong class=\"keyword\">preentrenamiento</strong></b>.</li>\n",
              "    <li>Los signos de puntuación como '¡' y '!' son <b><strong class=\"keyword\">tokens</strong></b> separados.</li>\n",
              "    <li>La <b><strong class=\"keyword\">tokenización</strong></b> es determinista para un <b><strong class=\"keyword\">tokenizador</strong></b> y texto dados.</li>\n",
              "</ul>\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>¿Por Qué es Crucial Contar los <strong class=\"keyword\">Tokens</strong>? La <strong class=\"keyword\">Ventana de Contexto</strong></h2>\n",
              "La cantidad de <b><strong class=\"keyword\">tokens</strong></b> en una <b><strong class=\"keyword\">entrada</strong></b> y/o <b><strong class=\"keyword\">salida</strong></b> es una consideración crítica al trabajar con <b>modelos de lenguaje</b>:\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Límite de Tokens</strong> (<strong class=\"keyword\">Ventana de Contexto</strong>):</b> Cada <b><strong class=\"keyword\">modelo de lenguaje</strong></b> tiene un <b><strong class=\"keyword\">límite de tokens</strong></b> máximo que puede procesar en una sola vez (<b><strong class=\"keyword\">entrada</strong></b> + <b><strong class=\"keyword\">salida</strong></b> generada). Esto se conoce como su \"<b><strong class=\"keyword\">ventana de contexto</strong></b>\". Por ejemplo:\n",
              "        <ul>\n",
              "            <li><b><strong class=\"keyword\">GPT</strong></b>-3 (modelos más antiguos como `davinci`): hasta 2048 o 4096 <b><strong class=\"keyword\">tokens</strong></b>.</li>\n",
              "            <li><b><strong class=\"keyword\">GPT</strong></b>-3.5-turbo: típicamente 4096 <b><strong class=\"keyword\">tokens</strong></b>, con versiones de 16k <b><strong class=\"keyword\">tokens</strong></b>.</li>\n",
              "            <li><b><strong class=\"keyword\">GPT</strong></b>-4: versiones con 8192 <b><strong class=\"keyword\">tokens</strong></b> (8k) y 32768 <b><strong class=\"keyword\">tokens</strong></b> (32k).</li>\n",
              "        </ul>\n",
              "        Exceder este límite resultará en errores o truncamiento del texto.\n",
              "    </li>\n",
              "    <li><b>Costo de <strong class=\"keyword\">API</strong>:</b> Al usar <b>modelos de lenguaje</b> a través de una <b><strong class=\"keyword\">API</strong></b> (como la de <b><strong class=\"keyword\">OpenAI</strong></b>), el costo se calcula generalmente por el número de <b><strong class=\"keyword\">tokens</strong></b> procesados (tanto de <b><strong class=\"keyword\">entrada</strong></b> como de <b><strong class=\"keyword\">salida</strong></b>).</li>\n",
              "    <li><b>Rendimiento Computacional:</b> Secuencias más largas de <b><strong class=\"keyword\">tokens</strong></b> requieren más memoria y tiempo de cómputo para ser procesadas por el <b><strong class=\"keyword\">modelo de lenguaje</strong></b>, especialmente en los mecanismos de <b>auto-atención</b> del <b><strong class=\"keyword\">Transformer</strong></b> cuya complejidad puede crecer cuadráticamente con la longitud de la secuencia.</li>\n",
              "    <li><b>Calidad de la <strong class=\"keyword\">Salida</strong>:</b> La cantidad de <b><strong class=\"keyword\">contexto</strong></b> (en <b><strong class=\"keyword\">tokens</strong></b>) que se proporciona al modelo puede influir significativamente en la relevancia y coherencia de su <b><strong class=\"keyword\">salida</strong></b>.</li>\n",
              "</ul>\n",
              "Entender cómo se cuentan los <b><strong class=\"keyword\">tokens</strong></b> y gestionar la longitud de la secuencia es vital para el uso efectivo y eficiente de los LLMs.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>Del <strong class=\"keyword\">Token</strong> al <strong class=\"keyword\">Vector</strong>: El Rol del <strong class=\"keyword\">Embedding</strong></h2>\n",
              "Una vez que el texto de <b><strong class=\"keyword\">entrada</strong></b> ha sido descompuesto en una secuencia de <b><strong class=\"keyword\">tokens</strong></b> (o más bien, sus IDs numéricos), el siguiente paso es convertir cada <b>ID de <strong class=\"keyword\">token</strong></b> en un <b><strong class=\"keyword\">embedding</strong></b>.\n",
              "<ul>\n",
              "    <li>Un <b><strong class=\"keyword\">embedding</strong></b> es un <b><strong class=\"keyword\">vector</strong></b> denso de números de punto flotante de alta dimensión (ej., 768, 1024, o más dimensiones, dependiendo del <b><strong class=\"keyword\">modelo de lenguaje</strong></b>).</li>\n",
              "    <li>Estos <b>vectores</b> son aprendidos durante el <b><strong class=\"keyword\">preentrenamiento</strong></b> del modelo y están diseñados para capturar el significado semántico del <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "    <li><b><strong class=\"keyword\">Tokens</strong></b> con significados similares tienden a tener <b>vectores</b> de <b><strong class=\"keyword\">embedding</strong></b> cercanos en el <strong class=\"keyword\">espacio</strong> vectorial.</li>\n",
              "    <li>La capa de <b><strong class=\"keyword\">embedding</strong></b> del <b><strong class=\"keyword\">modelo de lenguaje</strong></b> actúa como una tabla de búsqueda: mapea cada ID de <b><strong class=\"keyword\">token</strong></b> a su correspondiente <b><strong class=\"keyword\">vector</strong></b> de <b><strong class=\"keyword\">embedding</strong></b>.</li>\n",
              "    <li>Estos <b>embeddings</b> (a menudo combinados con embeddings posicionales que indican el lugar del <b><strong class=\"keyword\">token</strong></b> en la secuencia) son la verdadera <b><strong class=\"keyword\">entrada</strong></b> que se alimenta a las capas subsiguientes de la <b><strong class=\"keyword\">red neuronal</strong></b> (generalmente una arquitectura <b><strong class=\"keyword\">Transformer</strong></b>).</li>\n",
              "</ul>\n",
              "Este proceso transforma el lenguaje simbólico (<b><strong class=\"keyword\">tokens</strong></b>) en un <strong class=\"keyword\">espacio</strong> numérico donde los modelos de <b>aprendizaje profundo</b> pueden operar y aprender patrones complejos.\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>Consideraciones Prácticas y Desafíos de la <strong class=\"keyword\">Tokenización</strong></h2>\n",
              "Si bien la <b><strong class=\"keyword\">tokenización</strong></b> es un paso fundamental, presenta ciertas consideraciones y desafíos:\n",
              "<ul>\n",
              "    <li><b>Multilingüismo:</b> Diseñar <b>tokenizadores</b> que funcionen bien en múltiples idiomas, con diferentes escrituras y estructuras morfológicas, es complejo. Un <b><strong class=\"keyword\">tokenizador</strong></b> entrenado principalmente en inglés puede no ser óptimo para otros idiomas.</li>\n",
              "    <li><b>Sensibilidad a Pequeñas Variaciones:</b> Los <b>tokenizadores</b> pueden ser sensibles a cambios menores como mayúsculas/minúsculas, espacios adicionales o errores tipográficos, resultando en diferentes secuencias de <b><strong class=\"keyword\">tokens</strong></b> para textos semánticamente idénticos. Ejemplo: \"<strong class=\"keyword\">Token</strong>\" vs \"<strong class=\"keyword\">token</strong>\" vs \" <strong class=\"keyword\">token</strong>\".</li>\n",
              "    <li><b>Manejo de <strong class=\"keyword\">OOV</strong> (Out-of-Vocabulary):</b> Aunque los <b>tokenizadores</b> de <b>subpalabras</b> minimizan los <b><strong class=\"keyword\">tokens</strong></b> <b><strong class=\"keyword\">OOV</strong></b>, secuencias de <b><strong class=\"keyword\">caracteres</strong></b> extremadamente raras o emojis nuevos podrían aún no tener una representación directa y descomponerse en <b><strong class=\"keyword\">tokens</strong></b> de <b><strong class=\"keyword\">caracteres</strong></b> individuales o un <b><strong class=\"keyword\">token</strong></b> <b>[UNK]</b>.</li>\n",
              "    <li><b>Interpretabilidad:</b> La segmentación en <b>subpalabras</b> a veces no es intuitiva para los humanos, lo que puede dificultar la depuración o el análisis de por qué un modelo se comporta de cierta manera.</li>\n",
              "    <li><b>Diferencias entre Tokenizadores:</b> Diferentes modelos (<b><strong class=\"keyword\">GPT</strong></b>, <b><strong class=\"keyword\">BERT</strong></b>, <b><strong class=\"keyword\">T5</strong></b>) usan diferentes <b>tokenizadores</b> con distintos <b>vocabularios</b> y algoritmos. Esto significa que el mismo texto se <b>tokenizará</b> de manera diferente, resultando en un número distinto de <b><strong class=\"keyword\">tokens</strong></b> y diferentes IDs de <b><strong class=\"keyword\">tokens</strong></b>. No se pueden mezclar directamente <b>tokenizadores</b> y modelos no compatibles.</li>\n",
              "    <li><b>Impacto en el Rendimiento y Costo:</b> Una <b><strong class=\"keyword\">tokenización</strong></b> subóptima (ej., generando demasiados <b><strong class=\"keyword\">tokens</strong></b> para un texto dado) puede llevar a un mayor costo de <b><strong class=\"keyword\">API</strong></b> y a alcanzar más rápidamente el <b><strong class=\"keyword\">límite de tokens</strong></b> del modelo.</li>\n",
              "</ul>\n",
              "</div>\n",
              "<h2>En Resumen: Claves sobre los <strong class=\"keyword\">Tokens</strong></h2>\n",
              "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
              "<thead>\n",
              "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Concepto Clave</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Explicación Esencial</th>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Token</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Unidad fundamental de texto (<b><strong class=\"keyword\">palabra</strong></b>, <b><strong class=\"keyword\">subpalabra</strong></b>, <b>carácter</b>, <b><strong class=\"keyword\">símbolo</strong></b>) que un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> procesa.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Tokenización</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Proceso de convertir texto crudo en una secuencia de <b><strong class=\"keyword\">tokens</strong></b>. Es el primer paso para la comprensión del modelo.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Tokenizador</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Algoritmo (ej. <b><strong class=\"keyword\">BPE</strong></b>, <b><strong class=\"keyword\">WordPiece</strong></b>, <b><strong class=\"keyword\">SentencePiece</strong></b>) y <b><strong class=\"keyword\">vocabulario</strong></b> asociado que realiza la <b><strong class=\"keyword\">tokenización</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Subpalabras</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Enfoque dominante en LLMs modernos, equilibra tamaño de <b><strong class=\"keyword\">vocabulario</strong></b> y longitud de secuencia, manejando bien palabras raras/<b><strong class=\"keyword\">OOV</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">ID de <strong class=\"keyword\">Token</strong></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cada <b><strong class=\"keyword\">token</strong></b> único en el <b><strong class=\"keyword\">vocabulario</strong></b> del <b><strong class=\"keyword\">tokenizador</strong></b> tiene un identificador numérico.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Embedding</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Transformación de un ID de <b><strong class=\"keyword\">token</strong></b> en un <b><strong class=\"keyword\">vector</strong></b> numérico denso que captura su significado para la <b><strong class=\"keyword\">red neuronal</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Ventana de Contexto</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">El <b><strong class=\"keyword\">límite de tokens</strong></b> (<b><strong class=\"keyword\">entrada</strong></b> + <b><strong class=\"keyword\">salida</strong></b>) que un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> puede procesar a la vez.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Tokens Especiales</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Marcadores como <b>[CLS]</b>, <b>[SEP]</b>, <b>[PAD]</b>, <b>[UNK]</b>, <b>[MASK]</b> que ayudan a estructurar la <b><strong class=\"keyword\">entrada</strong></b> para tareas específicas.</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "<div style='margin-top: 1.3em;'>\n",
              "<h2>¿Cómo ver el número de <strong class=\"keyword\">tokens</strong> en un texto?</h2>\n",
              "Con <b><strong class=\"keyword\">tiktoken</strong></b> (el <b><strong class=\"keyword\">tokenizador</strong></b> de <b><strong class=\"keyword\">OpenAI</strong></b>), podés calcularlo así en Colab:\n",
              "<pre><code class=\"language-python\">!pip install -q <strong class=\"keyword\">tiktoken</strong>\n",
              "\n",
              "import <strong class=\"keyword\">tiktoken</strong>\n",
              "\n",
              "tokenizer = <strong class=\"keyword\">tiktoken</strong>.get_encoding(\"cl100k_base\")  # Compatible con <strong class=\"keyword\">GPT</strong>-4, <strong class=\"keyword\">GPT</strong>-3.5-turbo\n",
              "texto = \"ChatGPT es genial y la <strong class=\"keyword\">tokenización</strong> también.\"\n",
              "tokens_ids = tokenizer.encode(texto)\n",
              "decoded_tokens = [tokenizer.decode_single_token_bytes(token_id).decode('utf-8', errors='replace') for token_id in tokens_ids]\n",
              "\n",
              "\n",
              "print(f\"Texto: '{texto}'\")\n",
              "print(f\"IDs de <strong class=\"keyword\">Tokens</strong>: {tokens_ids}\")\n",
              "print(f\"<strong class=\"keyword\">Tokens</strong> decodificados: {decoded_tokens}\")\n",
              "print(f\"Cantidad de <strong class=\"keyword\">tokens</strong>: {len(tokens_ids)}\")\n",
              "</code></pre>\n",
              "</div><div style='margin-top: 1.3em;'>\n",
              "<h2>Conclusión: La Indispensable Labor de los <strong class=\"keyword\">Tokens</strong></h2>\n",
              "La <b><strong class=\"keyword\">tokenización</strong></b> y el concepto de <b><strong class=\"keyword\">token</strong></b> son mucho más que un simple preprocesamiento técnico; son la interfaz crítica entre el lenguaje humano, rico y ambiguo, y el mundo estructurado y numérico de los <b>modelos de lenguaje</b>. La elección del método de <b><strong class=\"keyword\">tokenización</strong></b> (predominantemente algoritmos de <b>subpalabras</b> como <b><strong class=\"keyword\">BPE</strong></b> o <b><strong class=\"keyword\">WordPiece</strong></b> en modelos como <b><strong class=\"keyword\">GPT</strong></b> y <b><strong class=\"keyword\">BERT</strong></b>) impacta directamente en el <b><strong class=\"keyword\">vocabulario</strong></b> del modelo, su capacidad para manejar palabras nuevas o raras (<b><strong class=\"keyword\">OOV</strong></b>), la eficiencia computacional, y en última instancia, su habilidad para comprender y generar lenguaje natural.<br><br>\n",
              "Desde la gestión de la <b><strong class=\"keyword\">ventana de contexto</strong></b> y los costos de <b><strong class=\"keyword\">API</strong></b>, hasta la transformación de <b><strong class=\"keyword\">tokens</strong></b> en <b>embeddings</b> significativos que alimentan la arquitectura <b><strong class=\"keyword\">Transformer</strong></b>, una sólida comprensión de los <b><strong class=\"keyword\">tokens</strong></b> es esencial para cualquier persona que trabaje o interactúe con <b><strong class=\"keyword\">NLP</strong></b> y los <b>modelos de lenguaje</b> de vanguardia. Son, en efecto, los ladrillos con los que se construye la inteligencia artificial lingüística.\n",
              "</div>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = function() {\n",
              "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    if (!themeToggleButton) {\n",
              "        const button = document.createElement('button');\n",
              "        button.id = \"theme-toggle-btn\";\n",
              "        button.className = \"theme-toggle\";\n",
              "        button.title = \"Cambiar tema de color\";\n",
              "        button.onclick = toggleTheme;\n",
              "        document.body.appendChild(button);\n",
              "        themeToggleButton = button;\n",
              "    }\n",
              "\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let currentThemeIsDark = false;\n",
              "\n",
              "    if (savedTheme === \"dark\") {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    } else if (savedTheme === \"light\") {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        currentThemeIsDark = false;\n",
              "    } else if (prefersDark) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    }\n",
              "\n",
              "    if (themeToggleButton) {\n",
              "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
              "    }\n",
              "};\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# 1. Función para resaltar palabras clave (versión simple y robusta)\n",
        "def simple_highlight_keywords(text, keywords):\n",
        "    keywords_sorted = sorted(keywords, key=len, reverse=True)\n",
        "    if not keywords_sorted: return text\n",
        "\n",
        "    # Crear un patrón que solo coincida con palabras clave completas (word boundaries)\n",
        "    # y sea insensible a mayúsculas/minúsculas.\n",
        "    pattern = '|'.join(r'\\b(?:' + re.escape(kw) + r')\\b' for kw in keywords_sorted)\n",
        "\n",
        "    # Si no hay palabras clave válidas para el patrón, devolver el texto original\n",
        "    if not pattern:\n",
        "        return text\n",
        "\n",
        "    def replacer(match):\n",
        "        # Heurística simple para no resaltar dentro de etiquetas HTML o atributos.\n",
        "        # Esto verifica si el match está inmediatamente precedido por '<' o '=\"' (inicio de atributo)\n",
        "        # o si está dentro de una etiqueta que no se ha cerrado.\n",
        "        # Es una heurística y puede no cubrir todos los casos, pero es mejor que nada.\n",
        "\n",
        "        # Verificar si el match está dentro de una etiqueta (ej: <strong class=\"keyword\">)\n",
        "        # Buscamos '<' antes del match sin un '>' intermedio.\n",
        "        pre_match_text = text[:match.start()]\n",
        "        last_open_bracket = pre_match_text.rfind('<')\n",
        "        last_close_bracket = pre_match_text.rfind('>')\n",
        "\n",
        "        if last_open_bracket > last_close_bracket: # Estamos dentro de una etiqueta\n",
        "            return match.group(0) # No resaltar\n",
        "\n",
        "        # Verificar si el match está dentro de un valor de atributo entre comillas\n",
        "        # (ej: title=\"keyword\")\n",
        "        # Esto es más complejo y puede necesitar un análisis más profundo.\n",
        "        # Por ahora, esta heurística simple debería ayudar.\n",
        "        # Si el match está precedido por =\" o =', es probable que sea un valor de atributo.\n",
        "        if match.start() > 1: # Asegurar que hay al menos dos caracteres antes\n",
        "            char_before1 = text[match.start()-1]\n",
        "            char_before2 = text[match.start()-2]\n",
        "            if (char_before1 == '\"' and char_before2 == '=') or \\\n",
        "               (char_before1 == \"'\" and char_before2 == '='):\n",
        "               # Podríamos verificar si también hay una comilla de cierre después del match\n",
        "               # pero se vuelve más complejo.\n",
        "               return match.group(0) # No resaltar\n",
        "\n",
        "        return f'<strong class=\"keyword\">{match.group(0)}</strong>'\n",
        "\n",
        "    try:\n",
        "        # Usar re.sub con la función replacer\n",
        "        return re.sub(pattern, replacer, text, flags=re.IGNORECASE)\n",
        "    except re.error as e:\n",
        "        print(f\"Advertencia: Error en el patrón regex: {e}\")\n",
        "        return text # Devolver el texto original si hay error de regex\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en simple_highlight_keywords: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return text\n",
        "\n",
        "\n",
        "# 2. Palabras clave para resaltar\n",
        "keywords_token = [\n",
        "    \"token\", \"tokens\", \"tokenización\", \"tokenizar\", \"NLP\", \"modelo de lenguaje\",\n",
        "    \"GPT\", \"BERT\", \"T5\", \"transformer\", \"representaciones numéricas\", \"embedding\",\n",
        "    \"Byte Pair Encoding\", \"BPE\", \"WordPiece\", \"SentencePiece\", \"parámetros\", \"límite de tokens\",\n",
        "    \"API\", \"OpenAI\", \"entrada\", \"salida\", \"contexto\", \"tokenizador\", \"preentrenamiento\",\n",
        "    \"fine-tune\", \"red neuronal\", \"vector\", \"corpus\", \"caracteres\", \"palabra\", \"subpalabra\",\n",
        "    \"símbolo\", \"espacio\", \"tiktoken\", \"ventana de contexto\", \"vocabulario\", \"OOV\",\n",
        "    \"tokens especiales\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\", \"[MASK]\"\n",
        "]\n",
        "\n",
        "# 3. Secciones didácticas (expandidas y mejoradas)\n",
        "sections_token = {\n",
        "    \"title\": \"Tokens en NLP: La Piedra Angular del Procesamiento del Lenguaje Moderno\",\n",
        "    \"subtitle\": \"Definición, Tipos, Algoritmos de Tokenización, Relevancia y Desafíos en Modelos como GPT y BERT\",\n",
        "    \"intro\": \"\"\"\n",
        "En el corazón del <b>Procesamiento de Lenguaje Natural (NLP)</b> moderno, el concepto de <b>token</b> es fundamental. Un <b>token</b> es una secuencia de <b>caracteres</b> agrupada como una unidad semántica útil para el procesamiento. Es la unidad mínima de texto que un <b>modelo de lenguaje</b> como <b>GPT</b>, <b>BERT</b> o <b>T5</b> ingiere y procesa. Estos modelos no entienden el lenguaje humano directamente como palabras o frases completas; en su lugar, dependen de un proceso crucial llamado <b>tokenización</b>.<br><br>\n",
        "La <b>tokenización</b> es el primer paso para convertir el texto crudo en un formato que una <b>red neuronal</b> pueda entender: una secuencia de <b>tokens</b>. Posteriormente, cada uno de estos <b>tokens</b> es transformado en <b>representaciones numéricas</b> (conocidas como <b>embeddings</b> o <b>vectores</b>), que son la verdadera <b>entrada</b> para los complejos cálculos dentro de la arquitectura <b>Transformer</b>.\n",
        "\"\"\",\n",
        "    \"que_puede_ser\": \"\"\"\n",
        "<h2>¿Qué Puede Ser un Token Exactamente?</h2>\n",
        "La naturaleza de un <b>token</b> no es fija; depende intrínsecamente del algoritmo de <b>tokenización</b> (el <b>tokenizador</b>) específico que utilice un <b>modelo de lenguaje</b>. Un <b>token</b> puede representar:\n",
        "<ul>\n",
        "    <li>Una <b>palabra completa</b>: Por ejemplo, en un tokenizador simple, \"aprendizaje\" podría ser un único <b>token</b>.</li>\n",
        "    <li>Una <b>subpalabra</b> (o parte de una palabra): Es muy común en modelos avanzados. Por ejemplo, \"tokenización\" podría dividirse en <b>tokens</b> como \"token\", \"ización\". Esto ayuda a manejar palabras raras o nuevas.</li>\n",
        "    <li>Un solo <b>carácter</b>: En algunos enfoques, cada letra o <b>símbolo</b> (e.g., 'a', '$', '.') puede ser un <b>token</b>.</li>\n",
        "    <li>Puntuación y <b>símbolos especiales</b>: Caracteres como '.', ',', '?', '@' suelen ser <b>tokens</b> individuales.</li>\n",
        "    <li><b>Espacios en blanco</b>: Algunos <b>tokenizadores</b>, como los usados por <b>OpenAI</b> (ej. <b>tiktoken</b>), pueden incluir el <b>espacio</b> precedente como parte del <b>token</b> (ej. \" palabra\" en lugar de \"palabra\").</li>\n",
        "</ul>\n",
        "La elección del tipo de <b>token</b> es un compromiso entre el tamaño del <b>vocabulario</b> del modelo y la longitud de las secuencias de <b>tokens</b> resultantes.\n",
        "\"\"\",\n",
        "    \"porque_tokenizar\": \"\"\"\n",
        "<h2>¿Por Qué Tokenizar? ¿Por Qué no Usar Palabras o Caracteres Directamente?</h2>\n",
        "Los <b>modelos de lenguaje</b> necesitan procesar el texto de manera eficiente y manejar la vasta diversidad del lenguaje humano.\n",
        "<ul>\n",
        "    <li><b>Tokenización basada en palabras:</b>\n",
        "        <ul>\n",
        "            <li><b>Problema:</b> Genera vocabularios gigantescos (cientos de miles o millones de palabras únicas). Muchas palabras serían raras (Out-of-Vocabulary u <b>OOV</b>), dificultando que el modelo aprenda buenas <b>representaciones numéricas</b> para ellas. ¿Cómo manejar \"supercalifragilisticoespialidoso\" o neologismos como \"GPTizar\"?</li>\n",
        "            <li><b>Solución con subpalabras:</b> Las palabras raras pueden formarse a partir de <b>subpalabras</b> comunes.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Tokenización basada en caracteres:</b>\n",
        "        <ul>\n",
        "            <li><b>Problema:</b> Aunque el <b>vocabulario</b> es muy pequeño (solo el alfabeto, números y símbolos), las secuencias de <b>tokens</b> resultantes serían extremadamente largas (ej., una frase de 10 palabras podría tener 50-70 <b>caracteres</b>/<b>tokens</b>). Esto aumenta drásticamente la carga computacional y dificulta que los modelos capturen dependencias a larga distancia.</li>\n",
        "            <li><b>Solución con subpalabras:</b> Logra un equilibrio, manteniendo secuencias más cortas que los <b>caracteres</b> y un <b>vocabulario</b> más manejable que las palabras.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "La <b>tokenización</b> basada en <b>subpalabras</b> ofrece un equilibrio óptimo, permitiendo a los modelos manejar un <b>vocabulario</b> finito y representar cualquier palabra, incluso las no vistas durante el <b>preentrenamiento</b>.\n",
        "\"\"\",\n",
        "    \"tipos\": \"\"\"\n",
        "<h2>Principales Tipos de Algoritmos de Tokenización</h2>\n",
        "Existen varios enfoques para la <b>tokenización</b>, cada uno con sus ventajas y desventajas:\n",
        "<ol>\n",
        "    <li><b>Tokenización Basada en Palabras (Word-based):</b>\n",
        "        <ul>\n",
        "            <li><b>Descripción:</b> Divide el texto utilizando delimitadores como <b>espacios</b> y signos de puntuación.</li>\n",
        "            <li><b>Ejemplo:</b> <code>\"El <b>modelo de lenguaje</b> es potente.\" → [\"El\", \"<b>modelo de lenguaje</b>\", \"es\", \"potente\", \".\"]</code></li>\n",
        "            <li><b>Ventajas:</b> Simple e intuitivo.</li>\n",
        "            <li><b>Desventajas:</b> Vocabularios enormes, problemas con palabras <b>OOV</b>, dificultades con idiomas aglutinantes (ej. alemán, turco) o sin segmentación clara de palabras (ej. chino, japonés). Sensible a errores tipográficos.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Tokenización Basada en Caracteres (Character-based):</b>\n",
        "        <ul>\n",
        "            <li><b>Descripción:</b> Cada <b>carácter</b> individual se considera un <b>token</b>.</li>\n",
        "            <li><b>Ejemplo:</b> <code>\"<b>GPT</b>\" → [\"G\", \"P\", \"T\"]</code></li>\n",
        "            <li><b>Ventajas:</b> <b>Vocabulario</b> muy pequeño y fijo, sin problemas de <b>OOV</b>.</li>\n",
        "            <li><b>Desventajas:</b> Secuencias de <b>tokens</b> muy largas, lo que incrementa la complejidad computacional para el <b>modelo de lenguaje</b>. Un <b>token</b> individual (un carácter) tiene poco significado semántico por sí solo.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Tokenización Basada en Subpalabras (Subword-based):</b>\n",
        "        <ul>\n",
        "            <li><b>Descripción:</b> Es el enfoque dominante en los <b>modelos de lenguaje</b> modernos como <b>GPT</b>, <b>BERT</b> y <b>T5</b>. Busca un equilibrio dividiendo palabras en unidades de <b>subpalabras</b> más pequeñas y significativas, aprendidas estadísticamente a partir de un gran <b>corpus</b>. Las palabras comunes pueden ser <b>tokens</b> únicos, mientras que las palabras raras se descomponen en múltiples <b>subpalabras</b>.</li>\n",
        "            <li><b>Algoritmos Comunes:</b>\n",
        "                <ul>\n",
        "                    <li><b>Byte Pair Encoding (BPE):</b> Comienza con un <b>vocabulario</b> de <b>caracteres</b> individuales y fusiona iterativamente los pares de <b>tokens</b> más frecuentes para formar nuevas <b>subpalabras</b> hasta alcanzar un tamaño de <b>vocabulario</b> deseado. Usado por <b>GPT</b>.</li>\n",
        "                    <li><b>WordPiece:</b> Similar a <b>BPE</b>, pero utiliza un criterio de probabilidad (likelihood) para decidir las fusiones. Usado por <b>BERT</b>.</li>\n",
        "                    <li><b>SentencePiece:</b> Trata el texto de <b>entrada</b> como una secuencia cruda (incluyendo <b>espacios</b>) y <b>tokeniza</b> directamente a partir de ella, a menudo usando BPE o unigram language model. Es útil para idiomas sin delimitadores de palabras claros.</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            <li><b>Ejemplo (conceptual):</b> <code>\"<b>tokenización</b> increíble\" → [\"token\", \"ización\", \" increí\", \"ble\"]</code></li>\n",
        "            <li><b>Ventajas:</b> Maneja palabras <b>OOV</b> eficazmente, controla el tamaño del <b>vocabulario</b>, produce secuencias de longitud razonable, y las <b>subpalabras</b> pueden retener cierto significado semántico.</li>\n",
        "            <li><b>Desventajas:</b> La <b>tokenización</b> puede no ser siempre intuitiva para los humanos. La segmentación puede variar entre diferentes <b>tokenizadores</b>.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ol>\n",
        "\"\"\",\n",
        "    \"vocabulario_tokenizador\": \"\"\"\n",
        "<h2>El Vocabulario del Tokenizador</h2>\n",
        "Cada <b>tokenizador</b> tiene un <b>vocabulario</b> predefinido: un conjunto finito de todos los posibles <b>tokens</b> que puede generar.\n",
        "<ul>\n",
        "    <li>Este <b>vocabulario</b> se construye durante el <b>preentrenamiento</b> del <b>tokenizador</b> sobre un gran <b>corpus</b> de texto.</li>\n",
        "    <li>El tamaño del <b>vocabulario</b> es un hiperparámetro importante. Por ejemplo, el <b>tokenizador</b> \"cl100k_base\" de <b>OpenAI</b> (usado para <b>GPT</b>-3.5-turbo y <b>GPT</b>-4) tiene un <b>vocabulario</b> de aproximadamente 100,000 <b>tokens</b>.</li>\n",
        "    <li>Cada <b>token</b> en el <b>vocabulario</b> tiene asociado un ID numérico único. Es esta secuencia de IDs la que finalmente se pasa al <b>modelo de lenguaje</b>.</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"tokens_especiales\": \"\"\"\n",
        "<h2>Tokens Especiales</h2>\n",
        "Muchos <b>tokenizadores</b> incluyen <b>tokens especiales</b> que tienen un significado particular para el <b>modelo de lenguaje</b>:\n",
        "<ul>\n",
        "    <li><code><b>[CLS]</b></code> (Classification): A menudo se añade al inicio de una secuencia de <b>entrada</b> en modelos como <b>BERT</b>. El <b>embedding</b> correspondiente a este <b>token</b> se usa como una representación agregada de toda la secuencia para tareas de clasificación.</li>\n",
        "    <li><code><b>[SEP]</b></code> (Separator): Se utiliza para separar diferentes segmentos de texto en la <b>entrada</b>, como dos oraciones en tareas de inferencia de lenguaje natural o pregunta y <b>contexto</b> en tareas de respuesta a preguntas (ej., en <b>BERT</b>).</li>\n",
        "    <li><code><b>[PAD]</b></code> (Padding): Si las secuencias de <b>entrada</b> a un modelo deben tener una longitud fija (común en el procesamiento por lotes), las secuencias más cortas se rellenan con <b>tokens</b> <b>[PAD]</b> hasta alcanzar la longitud deseada. El modelo suele estar entrenado para ignorar estos <b>tokens</b>.</li>\n",
        "    <li><code><b>[UNK]</b></code> (Unknown): Representa <b>tokens</b> que no están en el <b>vocabulario</b> del <b>tokenizador</b>. Aunque los tokenizadores de <b>subpalabras</b> reducen drásticamente la necesidad de <b>[UNK]</b>, aún pueden ocurrir con <b>caracteres</b> o secuencias muy inusuales.</li>\n",
        "    <li><code><b>[MASK]</b></code>: Usado en tareas de Modelado de Lenguaje Enmascarado (MLM), como en <b>BERT</b>, donde el modelo debe predecir el <b>token</b> original que fue reemplazado por <b>[MASK]</b>.</li>\n",
        "</ul>\n",
        "Estos <b>tokens especiales</b> son cruciales para dar formato a la <b>entrada</b> de manera que el <b>modelo de lenguaje</b> pueda realizar tareas específicas.\n",
        "\"\"\",\n",
        "    \"ejemplo_real\": \"\"\"\n",
        "<h2>Ejemplo Práctico: Tokenización con `tiktoken` de OpenAI</h2>\n",
        "Los modelos <b>GPT</b> de <b>OpenAI</b> utilizan un <b>tokenizador</b> basado en <b>BPE</b>. La librería <b>tiktoken</b> permite replicar esta <b>tokenización</b>.\n",
        "Consideremos la frase: <code>\"¡La <b>tokenización</b> en <b>NLP</b> es fascinante!\"</code>\n",
        "Usando el <b>tokenizador</b> \"cl100k_base\" (compatible con gpt-4, gpt-3.5-turbo):\n",
        "<pre><code class=\"language-python\">\n",
        "import tiktoken\n",
        "\n",
        "# Cargar el tokenizador para modelos como GPT-4\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "texto = \"¡La tokenización en NLP es fascinante!\"\n",
        "encoded_tokens_ids = tokenizer.encode(texto)\n",
        "decoded_tokens = [tokenizer.decode_single_token_bytes(token_id).decode('utf-8', errors='replace') for token_id in encoded_tokens_ids]\n",
        "\n",
        "print(f\"Texto original: {texto}\")\n",
        "print(f\"IDs de Tokens: {encoded_tokens_ids}\")\n",
        "print(f\"Tokens decodificados: {decoded_tokens}\")\n",
        "print(f\"Número de tokens: {len(encoded_tokens_ids)}\")\n",
        "</code></pre>\n",
        "Salida (ejemplo ilustrativo, puede variar ligeramente):\n",
        "<pre><code class=\"nohighlight\">\n",
        "Texto original: ¡La tokenización en NLP es fascinante!\n",
        "IDs de Tokens: [89118, 284, 2000, 7900, 495, 19193, 669, 44758, 29991, 0] # IDs ilustrativos, variarán\n",
        "Tokens decodificados: ['¡', 'La', ' token', 'ización', ' en', ' NLP', ' es', ' fascinante', '!', ''] # La decodificación puede variar\n",
        "Número de tokens: 10\n",
        "</code></pre>\n",
        "Observaciones:\n",
        "<ul>\n",
        "    <li>\"tokenización\" se divide en \" token\" e \"ización\". El <b>espacio</b> antes de \"token\" es parte del primer <b>token</b> de <b>subpalabra</b>.</li>\n",
        "    <li>\"NLP\" es un solo <b>token</b>, probablemente porque es una sigla común en el <b>corpus</b> de <b>preentrenamiento</b>.</li>\n",
        "    <li>Los signos de puntuación como '¡' y '!' son <b>tokens</b> separados.</li>\n",
        "    <li>La <b>tokenización</b> es determinista para un <b>tokenizador</b> y texto dados.</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"importancia_limite\": \"\"\"\n",
        "<h2>¿Por Qué es Crucial Contar los Tokens? La Ventana de Contexto</h2>\n",
        "La cantidad de <b>tokens</b> en una <b>entrada</b> y/o <b>salida</b> es una consideración crítica al trabajar con <b>modelos de lenguaje</b>:\n",
        "<ul>\n",
        "    <li><b>Límite de Tokens (Ventana de Contexto):</b> Cada <b>modelo de lenguaje</b> tiene un <b>límite de tokens</b> máximo que puede procesar en una sola vez (<b>entrada</b> + <b>salida</b> generada). Esto se conoce como su \"<b>ventana de contexto</b>\". Por ejemplo:\n",
        "        <ul>\n",
        "            <li><b>GPT</b>-3 (modelos más antiguos como `davinci`): hasta 2048 o 4096 <b>tokens</b>.</li>\n",
        "            <li><b>GPT</b>-3.5-turbo: típicamente 4096 <b>tokens</b>, con versiones de 16k <b>tokens</b>.</li>\n",
        "            <li><b>GPT</b>-4: versiones con 8192 <b>tokens</b> (8k) y 32768 <b>tokens</b> (32k).</li>\n",
        "        </ul>\n",
        "        Exceder este límite resultará en errores o truncamiento del texto.\n",
        "    </li>\n",
        "    <li><b>Costo de API:</b> Al usar <b>modelos de lenguaje</b> a través de una <b>API</b> (como la de <b>OpenAI</b>), el costo se calcula generalmente por el número de <b>tokens</b> procesados (tanto de <b>entrada</b> como de <b>salida</b>).</li>\n",
        "    <li><b>Rendimiento Computacional:</b> Secuencias más largas de <b>tokens</b> requieren más memoria y tiempo de cómputo para ser procesadas por el <b>modelo de lenguaje</b>, especialmente en los mecanismos de <b>auto-atención</b> del <b>Transformer</b> cuya complejidad puede crecer cuadráticamente con la longitud de la secuencia.</li>\n",
        "    <li><b>Calidad de la Salida:</b> La cantidad de <b>contexto</b> (en <b>tokens</b>) que se proporciona al modelo puede influir significativamente en la relevancia y coherencia de su <b>salida</b>.</li>\n",
        "</ul>\n",
        "Entender cómo se cuentan los <b>tokens</b> y gestionar la longitud de la secuencia es vital para el uso efectivo y eficiente de los LLMs.\n",
        "\"\"\",\n",
        "    \"embedding_uso\": \"\"\"\n",
        "<h2>Del Token al Vector: El Rol del Embedding</h2>\n",
        "Una vez que el texto de <b>entrada</b> ha sido descompuesto en una secuencia de <b>tokens</b> (o más bien, sus IDs numéricos), el siguiente paso es convertir cada <b>ID de token</b> en un <b>embedding</b>.\n",
        "<ul>\n",
        "    <li>Un <b>embedding</b> es un <b>vector</b> denso de números de punto flotante de alta dimensión (ej., 768, 1024, o más dimensiones, dependiendo del <b>modelo de lenguaje</b>).</li>\n",
        "    <li>Estos <b>vectores</b> son aprendidos durante el <b>preentrenamiento</b> del modelo y están diseñados para capturar el significado semántico del <b>token</b>.</li>\n",
        "    <li><b>Tokens</b> con significados similares tienden a tener <b>vectores</b> de <b>embedding</b> cercanos en el espacio vectorial.</li>\n",
        "    <li>La capa de <b>embedding</b> del <b>modelo de lenguaje</b> actúa como una tabla de búsqueda: mapea cada ID de <b>token</b> a su correspondiente <b>vector</b> de <b>embedding</b>.</li>\n",
        "    <li>Estos <b>embeddings</b> (a menudo combinados con embeddings posicionales que indican el lugar del <b>token</b> en la secuencia) son la verdadera <b>entrada</b> que se alimenta a las capas subsiguientes de la <b>red neuronal</b> (generalmente una arquitectura <b>Transformer</b>).</li>\n",
        "</ul>\n",
        "Este proceso transforma el lenguaje simbólico (<b>tokens</b>) en un espacio numérico donde los modelos de <b>aprendizaje profundo</b> pueden operar y aprender patrones complejos.\n",
        "\"\"\",\n",
        "    \"consideraciones_desafios\": \"\"\"\n",
        "<h2>Consideraciones Prácticas y Desafíos de la Tokenización</h2>\n",
        "Si bien la <b>tokenización</b> es un paso fundamental, presenta ciertas consideraciones y desafíos:\n",
        "<ul>\n",
        "    <li><b>Multilingüismo:</b> Diseñar <b>tokenizadores</b> que funcionen bien en múltiples idiomas, con diferentes escrituras y estructuras morfológicas, es complejo. Un <b>tokenizador</b> entrenado principalmente en inglés puede no ser óptimo para otros idiomas.</li>\n",
        "    <li><b>Sensibilidad a Pequeñas Variaciones:</b> Los <b>tokenizadores</b> pueden ser sensibles a cambios menores como mayúsculas/minúsculas, espacios adicionales o errores tipográficos, resultando en diferentes secuencias de <b>tokens</b> para textos semánticamente idénticos. Ejemplo: \"Token\" vs \"token\" vs \" token\".</li>\n",
        "    <li><b>Manejo de OOV (Out-of-Vocabulary):</b> Aunque los <b>tokenizadores</b> de <b>subpalabras</b> minimizan los <b>tokens</b> <b>OOV</b>, secuencias de <b>caracteres</b> extremadamente raras o emojis nuevos podrían aún no tener una representación directa y descomponerse en <b>tokens</b> de <b>caracteres</b> individuales o un <b>token</b> <b>[UNK]</b>.</li>\n",
        "    <li><b>Interpretabilidad:</b> La segmentación en <b>subpalabras</b> a veces no es intuitiva para los humanos, lo que puede dificultar la depuración o el análisis de por qué un modelo se comporta de cierta manera.</li>\n",
        "    <li><b>Diferencias entre Tokenizadores:</b> Diferentes modelos (<b>GPT</b>, <b>BERT</b>, <b>T5</b>) usan diferentes <b>tokenizadores</b> con distintos <b>vocabularios</b> y algoritmos. Esto significa que el mismo texto se <b>tokenizará</b> de manera diferente, resultando en un número distinto de <b>tokens</b> y diferentes IDs de <b>tokens</b>. No se pueden mezclar directamente <b>tokenizadores</b> y modelos no compatibles.</li>\n",
        "    <li><b>Impacto en el Rendimiento y Costo:</b> Una <b>tokenización</b> subóptima (ej., generando demasiados <b>tokens</b> para un texto dado) puede llevar a un mayor costo de <b>API</b> y a alcanzar más rápidamente el <b>límite de tokens</b> del modelo.</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"tabla_resumen\": \"\"\"\n",
        "<h2>En Resumen: Claves sobre los Tokens</h2>\n",
        "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
        "<thead>\n",
        "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Concepto Clave</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Explicación Esencial</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Token</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Unidad fundamental de texto (<b>palabra</b>, <b>subpalabra</b>, <b>carácter</b>, <b>símbolo</b>) que un <b>modelo de lenguaje</b> procesa.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Tokenización</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Proceso de convertir texto crudo en una secuencia de <b>tokens</b>. Es el primer paso para la comprensión del modelo.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Tokenizador</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Algoritmo (ej. <b>BPE</b>, <b>WordPiece</b>, <b>SentencePiece</b>) y <b>vocabulario</b> asociado que realiza la <b>tokenización</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Subpalabras</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Enfoque dominante en LLMs modernos, equilibra tamaño de <b>vocabulario</b> y longitud de secuencia, manejando bien palabras raras/<b>OOV</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">ID de Token</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Cada <b>token</b> único en el <b>vocabulario</b> del <b>tokenizador</b> tiene un identificador numérico.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Embedding</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Transformación de un ID de <b>token</b> en un <b>vector</b> numérico denso que captura su significado para la <b>red neuronal</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Ventana de Contexto</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">El <b>límite de tokens</b> (<b>entrada</b> + <b>salida</b>) que un <b>modelo de lenguaje</b> puede procesar a la vez.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Tokens Especiales</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Marcadores como <b>[CLS]</b>, <b>[SEP]</b>, <b>[PAD]</b>, <b>[UNK]</b>, <b>[MASK]</b> que ayudan a estructurar la <b>entrada</b> para tareas específicas.</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\"\"\",\n",
        "    \"demo_tiktoken\": \"\"\"\n",
        "<h2>¿Cómo ver el número de tokens en un texto?</h2>\n",
        "Con <b>tiktoken</b> (el <b>tokenizador</b> de <b>OpenAI</b>), podés calcularlo así en Colab:\n",
        "<pre><code class=\"language-python\">!pip install -q tiktoken\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Compatible con GPT-4, GPT-3.5-turbo\n",
        "texto = \"ChatGPT es genial y la tokenización también.\"\n",
        "tokens_ids = tokenizer.encode(texto)\n",
        "decoded_tokens = [tokenizer.decode_single_token_bytes(token_id).decode('utf-8', errors='replace') for token_id in tokens_ids]\n",
        "\n",
        "\n",
        "print(f\"Texto: '{texto}'\")\n",
        "print(f\"IDs de Tokens: {tokens_ids}\")\n",
        "print(f\"Tokens decodificados: {decoded_tokens}\")\n",
        "print(f\"Cantidad de tokens: {len(tokens_ids)}\")\n",
        "</code></pre>\n",
        "\"\"\",\n",
        "    \"conclusion_final\": \"\"\"\n",
        "<h2>Conclusión: La Indispensable Labor de los Tokens</h2>\n",
        "La <b>tokenización</b> y el concepto de <b>token</b> son mucho más que un simple preprocesamiento técnico; son la interfaz crítica entre el lenguaje humano, rico y ambiguo, y el mundo estructurado y numérico de los <b>modelos de lenguaje</b>. La elección del método de <b>tokenización</b> (predominantemente algoritmos de <b>subpalabras</b> como <b>BPE</b> o <b>WordPiece</b> en modelos como <b>GPT</b> y <b>BERT</b>) impacta directamente en el <b>vocabulario</b> del modelo, su capacidad para manejar palabras nuevas o raras (<b>OOV</b>), la eficiencia computacional, y en última instancia, su habilidad para comprender y generar lenguaje natural.<br><br>\n",
        "Desde la gestión de la <b>ventana de contexto</b> y los costos de <b>API</b>, hasta la transformación de <b>tokens</b> en <b>embeddings</b> significativos que alimentan la arquitectura <b>Transformer</b>, una sólida comprensión de los <b>tokens</b> es esencial para cualquier persona que trabaje o interactúe con <b>NLP</b> y los <b>modelos de lenguaje</b> de vanguardia. Son, en efecto, los ladrillos con los que se construye la inteligencia artificial lingüística.\n",
        "\"\"\"\n",
        "}\n",
        "# Reordenar secciones para un flujo lógico\n",
        "ordered_sections_keys = [\n",
        "    \"title\", \"subtitle\", \"intro\", \"que_puede_ser\", \"porque_tokenizar\", \"tipos\",\n",
        "    \"vocabulario_tokenizador\", \"tokens_especiales\", \"ejemplo_real\", \"importancia_limite\",\n",
        "    \"embedding_uso\", \"consideraciones_desafios\", \"tabla_resumen\", \"demo_tiktoken\", \"conclusion_final\"\n",
        "]\n",
        "\n",
        "# 4. Aplicar el resaltado a las secciones\n",
        "highlighted_sections = {\n",
        "    k: simple_highlight_keywords(sections_token[k], keywords_token)\n",
        "    for k in ordered_sections_keys if k in sections_token\n",
        "}\n",
        "\n",
        "\n",
        "# 5. CSS + JS para modo claro/oscuro\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #1e88e5;\n",
        "  --secondary-color: #00acc1;\n",
        "  --text-color: #37474f;\n",
        "  --bg-color: #f4f6f8;\n",
        "  --container-bg: #ffffff;\n",
        "  --keyword-bg: #e0f7fa;\n",
        "  --keyword-text: #00796b;\n",
        "  --button-bg: #e9ecef;\n",
        "  --button-hover-bg: #ced4da;\n",
        "  --button-text-color: #212529;\n",
        "  --shadow-color: rgba(0,0,0,0.08);\n",
        "  --table-border-color: #dee2e6;\n",
        "  --row-bg-odd: #f8f9fa;\n",
        "  --row-bg-even: #ffffff;\n",
        "  --pre-bg: #e9ecef;\n",
        "  --pre-text: #212529;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #42a5f5;\n",
        "  --secondary-color: #26c6da;\n",
        "  --text-color: #e0e0e0;\n",
        "  --bg-color: #121212;\n",
        "  --container-bg: #1e1e1e;\n",
        "  --keyword-bg: #37474f;\n",
        "  --keyword-text: #80deea;\n",
        "  --button-bg: #343a40;\n",
        "  --button-hover-bg: #495057;\n",
        "  --button-text-color: #f8f9fa;\n",
        "  --shadow-color: rgba(0,0,0,0.5);\n",
        "  --table-border-color: #495057;\n",
        "  --row-bg-odd: #2c3034;\n",
        "  --row-bg-even: #212529;\n",
        "  --pre-bg: #2c3034;\n",
        "  --pre-text: #f8f9fa;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Roboto', 'Arial', sans-serif;\n",
        "  line-height: 1.75;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 20px;\n",
        "  margin: 0;\n",
        "}\n",
        ".container {\n",
        "  max-width: 960px;\n",
        "  margin: 30px auto;\n",
        "  padding: 30px 40px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 12px;\n",
        "  box-shadow: 0 6px 18px var(--shadow-color);\n",
        "  position: relative;\n",
        "  transition: background-color .3s, box-shadow .3s;\n",
        "  border-top: 7px solid var(--primary-color);\n",
        "}\n",
        "h1 {\n",
        "  color: var(--primary-color);\n",
        "  font-size: 2.3em;\n",
        "  margin-bottom: .1em;\n",
        "  line-height: 1.25;\n",
        "  text-align: center;\n",
        "  border-bottom: 2px solid var(--secondary-color);\n",
        "  padding-bottom: 0.3em;\n",
        "}\n",
        "h2 {\n",
        "  color: var(--secondary-color);\n",
        "  text-align: left;\n",
        "  margin-top: 2.3em;\n",
        "  margin-bottom: .8em;\n",
        "  font-size: 1.7em;\n",
        "  border-bottom: 1px solid #ddd;\n",
        "  padding-bottom: 0.2em;\n",
        "}\n",
        "body.dark-mode h2 {\n",
        "    border-bottom: 1px solid #444;\n",
        "}\n",
        "h3 {\n",
        "  color: var(--primary-color);\n",
        "  margin-top: 1.8em;\n",
        "  margin-bottom: 0.6em;\n",
        "  font-size: 1.4em;\n",
        "}\n",
        ".subtitle-style {\n",
        "  font-style:italic;\n",
        "  font-weight:400;\n",
        "  color: var(--text-color);\n",
        "  opacity: 0.85;\n",
        "  text-align:center;\n",
        "  margin-top:0.2em;\n",
        "  margin-bottom: 1.5em;\n",
        "  font-size: 1.1em;\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.2em 0.4em;\n",
        "  border-radius: 5px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--button-bg);\n",
        "  color: var(--button-text-color);\n",
        "  border: 1.5px solid var(--secondary-color);\n",
        "  padding: 9px 14px;\n",
        "  border-radius: 6px;\n",
        "  cursor: pointer;\n",
        "  position: fixed;\n",
        "  top: 20px;\n",
        "  right: 25px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
        "  z-index: 1000;\n",
        "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--button-hover-bg);\n",
        "    transform: translateY(-1px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 3px solid var(--primary-color);\n",
        "    outline-offset: 2px;\n",
        "    border-color: var(--primary-color);\n",
        "}\n",
        "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
        "li { margin-bottom:0.6em; }\n",
        "b { color: var(--primary-color); font-weight: 600;}\n",
        "table {\n",
        "    font-size:0.95em;\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    width: 100%; /* Asegurar que la tabla ocupe el ancho */\n",
        "    border-collapse: collapse; /* Para que los bordes se fusionen bien */\n",
        "}\n",
        "table th, table td {\n",
        "    padding:10px 12px !important;\n",
        "    border:1px solid var(--table-border-color) !important;\n",
        "    text-align: left;\n",
        "    vertical-align: top;\n",
        "}\n",
        "table th { font-weight: 600; background-color: var(--row-bg-odd); } /* Fondo para headers */\n",
        "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
        "\n",
        "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "\n",
        "\n",
        "pre {\n",
        "    background: var(--pre-bg);\n",
        "    color: var(--pre-text);\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 0.9em;\n",
        "    line-height: 1.6;\n",
        "    overflow-x: auto;\n",
        "    margin: 1.2em 0;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
        "}\n",
        "code.language-python, code.nohighlight {\n",
        "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = function() {\n",
        "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    if (!themeToggleButton) {\n",
        "        const button = document.createElement('button');\n",
        "        button.id = \"theme-toggle-btn\";\n",
        "        button.className = \"theme-toggle\";\n",
        "        button.title = \"Cambiar tema de color\";\n",
        "        button.onclick = toggleTheme;\n",
        "        document.body.appendChild(button);\n",
        "        themeToggleButton = button;\n",
        "    }\n",
        "\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let currentThemeIsDark = false;\n",
        "\n",
        "    if (savedTheme === \"dark\") {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    } else if (savedTheme === \"light\") {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        currentThemeIsDark = false;\n",
        "    } else if (prefersDark) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    }\n",
        "\n",
        "    if (themeToggleButton) {\n",
        "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
        "    }\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# 6. Ensamblar el HTML\n",
        "html_body_content = f\"<h1>{highlighted_sections.get('title', '')}</h1>\"\n",
        "html_body_content += f\"<p class='subtitle-style'>{highlighted_sections.get('subtitle', '')}</p>\"\n",
        "\n",
        "for key in ordered_sections_keys:\n",
        "    if key not in [\"title\", \"subtitle\"] and key in highlighted_sections:\n",
        "        # Para la tabla, no añadir el div extra para que no tenga margen superior innecesario\n",
        "        if key == \"tabla_resumen\":\n",
        "            html_body_content += highlighted_sections[key]\n",
        "        else:\n",
        "            html_body_content += f\"<div style='margin-top: 1.3em;'>{highlighted_sections[key]}</div>\"\n",
        "\n",
        "\n",
        "html_structure = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{sections_token.get('title', 'Tokens en NLP')}</title>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
        "    {css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
        "<div class=\"container\">\n",
        "    {html_body_content}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_structure))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nLMFS7zW9pBy",
        "outputId": "60e6eeb1-7c53-4d76-cdb1-080d19084c57"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>De Tokens a Embeddings: El Viaje al Espacio Latente Semántico</title>\n",
              "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #1e88e5;\n",
              "  --secondary-color: #00acc1;\n",
              "  --text-color: #37474f;\n",
              "  --bg-color: #f4f6f8;\n",
              "  --container-bg: #ffffff;\n",
              "  --keyword-bg: #e0f7fa;\n",
              "  --keyword-text: #00796b;\n",
              "  --button-bg: #e9ecef;\n",
              "  --button-hover-bg: #ced4da;\n",
              "  --button-text-color: #212529;\n",
              "  --shadow-color: rgba(0,0,0,0.08);\n",
              "  --table-border-color: #dee2e6;\n",
              "  --row-bg-odd: #f8f9fa;\n",
              "  --row-bg-even: #ffffff;\n",
              "  --pre-bg: #e9ecef;\n",
              "  --pre-text: #212529;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #42a5f5;\n",
              "  --secondary-color: #26c6da;\n",
              "  --text-color: #e0e0e0;\n",
              "  --bg-color: #121212;\n",
              "  --container-bg: #1e1e1e;\n",
              "  --keyword-bg: #37474f;\n",
              "  --keyword-text: #80deea;\n",
              "  --button-bg: #343a40;\n",
              "  --button-hover-bg: #495057;\n",
              "  --button-text-color: #f8f9fa;\n",
              "  --shadow-color: rgba(0,0,0,0.5);\n",
              "  --table-border-color: #495057;\n",
              "  --row-bg-odd: #2c3034;\n",
              "  --row-bg-even: #212529;\n",
              "  --pre-bg: #2c3034;\n",
              "  --pre-text: #f8f9fa;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Roboto', 'Arial', sans-serif;\n",
              "  line-height: 1.75;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 20px;\n",
              "  margin: 0;\n",
              "}\n",
              ".container {\n",
              "  max-width: 980px; /* Un poco más ancho para contenido denso */\n",
              "  margin: 30px auto;\n",
              "  padding: 30px 40px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 12px;\n",
              "  box-shadow: 0 6px 18px var(--shadow-color);\n",
              "  position: relative;\n",
              "  transition: background-color .3s, box-shadow .3s;\n",
              "  border-top: 7px solid var(--primary-color);\n",
              "}\n",
              "h1 {\n",
              "  color: var(--primary-color);\n",
              "  font-size: 2.4em; /* Ligeramente más grande para el título principal */\n",
              "  margin-bottom: .1em;\n",
              "  line-height: 1.25;\n",
              "  text-align: center;\n",
              "  border-bottom: 2px solid var(--secondary-color);\n",
              "  padding-bottom: 0.3em;\n",
              "}\n",
              "h2 {\n",
              "  color: var(--secondary-color);\n",
              "  text-align: left;\n",
              "  margin-top: 2.3em;\n",
              "  margin-bottom: .8em;\n",
              "  font-size: 1.8em; /* Consistente para subtítulos de sección */\n",
              "  border-bottom: 1px solid #ddd;\n",
              "  padding-bottom: 0.2em;\n",
              "}\n",
              "body.dark-mode h2 {\n",
              "    border-bottom: 1px solid #444;\n",
              "}\n",
              ".subtitle-style {\n",
              "  font-style:italic;\n",
              "  font-weight:400;\n",
              "  color: var(--text-color);\n",
              "  opacity: 0.85;\n",
              "  text-align:center;\n",
              "  margin-top:0.2em;\n",
              "  margin-bottom: 1.8em; /* Más espacio después del subtítulo */\n",
              "  font-size: 1.15em; /* Ligeramente más grande */\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.2em 0.4em;\n",
              "  border-radius: 5px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--button-bg);\n",
              "  color: var(--button-text-color);\n",
              "  border: 1.5px solid var(--secondary-color);\n",
              "  padding: 9px 14px;\n",
              "  border-radius: 6px;\n",
              "  cursor: pointer;\n",
              "  position: fixed;\n",
              "  top: 20px;\n",
              "  right: 25px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
              "  z-index: 1000;\n",
              "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--button-hover-bg);\n",
              "    transform: translateY(-1px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 3px solid var(--primary-color);\n",
              "    outline-offset: 2px;\n",
              "    border-color: var(--primary-color);\n",
              "}\n",
              "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
              "ol li, ul li { margin-bottom:0.7em; } /* Más espacio entre ítems de lista */\n",
              "p { margin-bottom: 1.3em; } /* Espacio consistente para párrafos */\n",
              "b { color: var(--primary-color); font-weight: 600;}\n",
              "table {\n",
              "    font-size:0.95em;\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    width: 100%; \n",
              "    border-collapse: collapse; \n",
              "}\n",
              "table th, table td {\n",
              "    padding:10px 12px !important; \n",
              "    border:1px solid var(--table-border-color) !important;\n",
              "    text-align: left;\n",
              "    vertical-align: top;\n",
              "}\n",
              "table th { font-weight: 600; background-color: var(--row-bg-odd); }\n",
              "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
              "\n",
              "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "\n",
              "pre {\n",
              "    background: var(--pre-bg);\n",
              "    color: var(--pre-text);\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    border-radius: 8px;\n",
              "    padding: 12px 16px;\n",
              "    font-size: 0.9em;\n",
              "    line-height: 1.6;\n",
              "    overflow-x: auto;\n",
              "    margin: 1.2em 0;\n",
              "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
              "}\n",
              "code.language-python, code.nohighlight { /* Para tiktoken u otros ejemplos */\n",
              "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
              "<div class=\"container\">\n",
              "    <h1>De <strong class=\"keyword\">Tokens</strong> a <strong class=\"keyword\">Embeddings</strong>: El Viaje al <strong class=\"keyword\">Espacio Latente</strong> Semántico</h1><p class='subtitle-style'>Comprendiendo cómo los Modelos de Lenguaje representan el <strong class=\"keyword\">significado</strong> del texto</p><div style='margin-top: 1.5em;'>\n",
              "<h2>El Desafío: De Símbolos Discretos a Comprensión Numérica</h2>\n",
              "Una vez que un texto ha sido procesado mediante la <b>tokenización</b>, obtenemos una secuencia de <b><strong class=\"keyword\">tokens</strong></b> (o más precisamente, sus <b>IDs de <strong class=\"keyword\">token</strong></b> numéricos). Por ejemplo, la frase \"El gato duerme\" podría convertirse en <code>[ID_El, ID_gato, ID_duerme]</code> como <code>[10, 254, 700]</code>.<br><br>\n",
              "Sin embargo, estos <b>IDs de <strong class=\"keyword\">token</strong></b> son simplemente identificadores discretos y arbitrarios. No capturan ninguna información sobre el <b><strong class=\"keyword\">significado</strong></b> de los <b><strong class=\"keyword\">tokens</strong></b> ni las relaciones entre ellos. Un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> no puede operar directamente con estos IDs para tareas complejas como entender el <b><strong class=\"keyword\">contexto</strong></b> o generar texto coherente. Necesitamos una forma de transformar estos <b><strong class=\"keyword\">tokens</strong></b> en <b>representaciones numéricas</b> ricas y densas que la <b><strong class=\"keyword\">red neuronal</strong></b> pueda procesar: aquí es donde entran en juego los <b><strong class=\"keyword\">embeddings</strong></b>.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>¿Qué son los <strong class=\"keyword\">Embeddings</strong>? Traduciendo <strong class=\"keyword\">Tokens</strong> a <strong class=\"keyword\">Vectores</strong></h2>\n",
              "Un <b><strong class=\"keyword\">embedding</strong></b> (o incrustación) es una <b><strong class=\"keyword\">representación numérica</strong></b> de un <b><strong class=\"keyword\">token</strong></b> (o a veces de palabras, frases o incluso documentos) en forma de un <b><strong class=\"keyword\">vector</strong></b> denso de números de punto flotante. Estos <b><strong class=\"keyword\">vectores</strong></b> suelen tener una <b><strong class=\"keyword\">alta dimensión</strong></b> (por ejemplo, 768, 1024, 4096 o más dimensiones para modelos como <b><strong class=\"keyword\">BERT</strong></b> o <b><strong class=\"keyword\">GPT</strong></b>).\n",
              "<ul>\n",
              "    <li><b>Denso vs. Disperso:</b> A diferencia de las representaciones \"one-hot\" (donde un <b><strong class=\"keyword\">vector</strong></b> es mayormente ceros con un solo '1'), los <b><strong class=\"keyword\">embeddings</strong></b> son densos, lo que significa que la mayoría de sus valores son distintos de cero.</li>\n",
              "    <li><b><strong class=\"keyword\">Coordenadas</strong> Semánticas:</b> Se puede pensar en un <b><strong class=\"keyword\">embedding</strong></b> como un conjunto de <b><strong class=\"keyword\">coordenadas</strong></b> que ubican un <b><strong class=\"keyword\">token</strong></b> en un vasto mapa multidimensional. La posición en este mapa (el <b><strong class=\"keyword\">espacio latente</strong></b>) refleja el <b><strong class=\"keyword\">significado</strong></b> y uso del <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "    <li><b>Aprendidos, no Fijos:</b> Crucialmente, estos <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> no son asignados al azar; son <b><strong class=\"keyword\">parámetros</strong></b> del <b><strong class=\"keyword\">modelo de lenguaje</strong></b> que se aprenden y ajustan durante el proceso de <b><strong class=\"keyword\">preentrenamiento</strong></b>.</li>\n",
              "</ul>\n",
              "Ejemplo conceptual:\n",
              "<pre>\n",
              "ID_token para \"rey\" (ej. 5021) → <b><strong class=\"keyword\">Embedding</strong></b>: [0.23, -0.51, 0.08, ..., 0.74]  (un <b><strong class=\"keyword\">vector</strong></b> de, digamos, 768 números)\n",
              "ID_token para \"reina\" (ej. 6034) → <b><strong class=\"keyword\">Embedding</strong></b>: [0.28, -0.45, 0.12, ..., 0.69] (otro <b><strong class=\"keyword\">vector</strong></b> de 768 números)\n",
              "</pre>\n",
              "La idea es que los <b><strong class=\"keyword\">vectores</strong></b> para \"rey\" y \"reina\" sean relativamente cercanos en este espacio debido a su similar <b><strong class=\"keyword\">significado</strong></b>.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>El <strong class=\"keyword\">Espacio Latente</strong>: Un Universo de <strong class=\"keyword\">Significado</strong></h2>\n",
              "Los <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> \"viven\" en un <b><strong class=\"keyword\">espacio latente</strong></b> (o espacio de <strong class=\"keyword\">embedding</strong>). Este es un espacio vectorial multidimensional donde cada dimensión contribuye a capturar algún aspecto (latente o oculto) del <b><strong class=\"keyword\">significado</strong></b> o uso de los <b><strong class=\"keyword\">tokens</strong></b>.\n",
              "<ul>\n",
              "    <li><b>Estructura <strong class=\"keyword\">Semántica</strong>:</b> La magia del <b><strong class=\"keyword\">espacio latente</strong></b> reside en que su estructura geométrica refleja las <b><strong class=\"keyword\">relaciones semánticas</strong></b> entre los <b><strong class=\"keyword\">tokens</strong></b>. Los <b><strong class=\"keyword\">tokens</strong></b> con significados similares o que se usan en <b>contextos</b> parecidos tienden a agruparse, mientras que los <b><strong class=\"keyword\">tokens</strong></b> con significados dispares se encuentran más alejados.</li>\n",
              "    <li><b>Continuidad:</b> El espacio es continuo, lo que permite al modelo generalizar. Un nuevo <b><strong class=\"keyword\">token</strong></b> (o una combinación de ellos) puede ser proyectado a una región del espacio, heredando propiedades de sus vecinos.</li>\n",
              "    <li><b>Descubierto por el Modelo:</b> El <b><strong class=\"keyword\">modelo de lenguaje</strong></b>, durante su <b><strong class=\"keyword\">preentrenamiento</strong></b>, aprende a organizar este <b><strong class=\"keyword\">espacio latente</strong></b> de manera que sea útil para la tarea de predicción de lenguaje (ej., predecir el siguiente <b><strong class=\"keyword\">token</strong></b> o un <b><strong class=\"keyword\">token</strong></b> enmascarado).</li>\n",
              "</ul>\n",
              "Este espacio no es algo que diseñemos explícitamente; emerge como resultado del <b><strong class=\"keyword\">aprendizaje profundo</strong></b> sobre grandes cantidades de texto.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>¿Cómo se Aprenden los <strong class=\"keyword\">Embeddings</strong> y se Construye el <strong class=\"keyword\">Espacio Latente</strong>?</h2>\n",
              "La creación de <b><strong class=\"keyword\">embeddings</strong></b> significativos es uno de los logros clave del <b><strong class=\"keyword\">preentrenamiento</strong></b> de los <b>modelos de lenguaje</b>.\n",
              "<ol>\n",
              "    <li><b><strong class=\"keyword\">Capa de Embedding</strong> (<strong class=\"keyword\">Embedding</strong> Layer):</b>\n",
              "        <ul>\n",
              "            <li>En la arquitectura de una <b><strong class=\"keyword\">red neuronal</strong></b> para <b><strong class=\"keyword\">NLP</strong></b>, la primera capa suele ser una <b><strong class=\"keyword\">capa de embedding</strong></b>. Esta capa funciona esencialmente como una gran <b><strong class=\"keyword\">tabla de búsqueda</strong></b> (o matriz de pesos).</li>\n",
              "            <li>Las filas de esta tabla corresponden a todos los <b>IDs de <strong class=\"keyword\">token</strong></b> posibles en el <b>vocabulario</b> del modelo, y cada fila es el <b><strong class=\"keyword\">vector</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> para ese <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "            <li>Cuando un <b><strong class=\"keyword\">ID de token</strong></b> entra en el modelo, la <b><strong class=\"keyword\">capa de embedding</strong></b> simplemente \"busca\" y devuelve el <b><strong class=\"keyword\">vector</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> correspondiente.</li>\n",
              "            <li>Inicialmente, estos <b><strong class=\"keyword\">vectores</strong></b> pueden ser aleatorios, pero sus valores son <b><strong class=\"keyword\">parámetros</strong></b> que se actualizan durante el entrenamiento.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Aprendizaje a Través de Tareas de Predicción Lingüística:</b>\n",
              "        <ul>\n",
              "            <li>Los <b>modelos de lenguaje</b> se preentrenan en tareas como predecir el siguiente <b><strong class=\"keyword\">token</strong></b> en una secuencia (enfoque <b>causal</b> como <b><strong class=\"keyword\">GPT</strong></b>) o predecir <b><strong class=\"keyword\">tokens</strong></b> enmascarados (enfoque bidireccional como <b><strong class=\"keyword\">BERT</strong></b>).</li>\n",
              "            <li>Para realizar bien estas tareas, el modelo necesita aprender qué <b><strong class=\"keyword\">tokens</strong></b> tienden a aparecer juntos y en qué <b>contextos</b>. Para ello, ajusta los <b><strong class=\"keyword\">parámetros</strong></b> de sus <b><strong class=\"keyword\">embeddings</strong></b> (y del resto de la <b><strong class=\"keyword\">red neuronal</strong></b>) para minimizar una <b><strong class=\"keyword\">función de pérdida</strong></b> (un indicador de cuán incorrectas son sus predicciones).</li>\n",
              "            <li>Si el modelo predice incorrectamente, la señal de error se retropropaga a través de la red, y los <b><strong class=\"keyword\">embeddings</strong></b> de los <b><strong class=\"keyword\">tokens</strong></b> involucrados se ajustan ligeramente para que, en el futuro, la predicción sea mejor.</li>\n",
              "            <li>Por ejemplo, si el modelo ve frecuentemente \"El gato persigue al _____\" seguido de \"ratón\", los <b><strong class=\"keyword\">embeddings</strong></b> de \"gato\", \"persigue\", \"al\" y \"ratón\" se ajustarán de tal manera que la presencia de los primeros haga más probable la predicción del último. Esto implica que sus <b><strong class=\"keyword\">vectores</strong></b> se organizarán en el <b><strong class=\"keyword\">espacio latente</strong></b> de una forma que capture esta relación.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Influencias Históricas (<strong class=\"keyword\">Word2Vec</strong>, <strong class=\"keyword\">GloVe</strong>):</b>\n",
              "        <ul>\n",
              "            <li>Antes de los <b>Transformers</b>, algoritmos como <b><strong class=\"keyword\">Word2Vec</strong></b> (Skip-gram, CBOW) y <b><strong class=\"keyword\">GloVe</strong></b> fueron pioneros en aprender <b><strong class=\"keyword\">embeddings</strong></b> de palabras de alta calidad a partir de grandes corpus, basándose en la hipótesis distribucional (\"una palabra se conoce por la compañía que mantiene\"). Estos producían <b><strong class=\"keyword\">embeddings</strong> estáticos</b> (un solo <b><strong class=\"keyword\">vector</strong></b> por palabra, independientemente del <b><strong class=\"keyword\">contexto</strong></b>).</li>\n",
              "            <li>Los <b>modelos de lenguaje</b> modernos como <b><strong class=\"keyword\">BERT</strong></b> y <b><strong class=\"keyword\">GPT</strong></b> aprenden <b><strong class=\"keyword\">embeddings</strong> contextuales</b>. Aunque hay un <b><strong class=\"keyword\">embedding</strong></b> base para cada <b><strong class=\"keyword\">token</strong></b> en la <b><strong class=\"keyword\">capa de embedding</strong></b> inicial, estos <b><strong class=\"keyword\">vectores</strong></b> son luego procesados y transformados por las capas <b><strong class=\"keyword\">Transformer</strong></b> (especialmente por los mecanismos de <b><strong class=\"keyword\">auto-atención</strong></b>) para generar representaciones que dependen del <b><strong class=\"keyword\">contexto</strong></b> específico en el que aparece el <b><strong class=\"keyword\">token</strong></b>.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "</ol>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Propiedades Fascinantes de los <strong class=\"keyword\">Embeddings</strong> y el <strong class=\"keyword\">Espacio Latente</strong></h2>\n",
              "El <b><strong class=\"keyword\">espacio latente</strong></b> aprendido exhibe propiedades notables:\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Proximidad</strong> <strong class=\"keyword\">Semántica</strong>:</b> <b><strong class=\"keyword\">Tokens</strong></b> con significados similares o que se usan en roles gramaticales parecidos tienden a tener <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> cercanos en el <b><strong class=\"keyword\">espacio latente</strong></b> (medido por distancias como la euclidiana o la similitud del coseno). Ej: \"feliz\", \"alegre\", \"contento\" estarían agrupados.</li>\n",
              "    <li><b><strong class=\"keyword\">Analogías Vectoriales</strong>:</b> Una de las propiedades más famosas es la capacidad de realizar aritmética vectorial que refleja analogías semánticas. El ejemplo clásico es: <code><b><strong class=\"keyword\">vector</strong></b>(\"rey\") - <b><strong class=\"keyword\">vector</strong></b>(\"hombre\") + <b><strong class=\"keyword\">vector</strong></b>(\"mujer\") ≈ <b><strong class=\"keyword\">vector</strong></b>(\"reina\")</code>. Esto sugiere que el <b><strong class=\"keyword\">espacio latente</strong></b> captura relaciones complejas de manera estructurada.</li>\n",
              "    <li><b>Composición y Generalización:</b> El modelo puede componer <b><strong class=\"keyword\">embeddings</strong></b> de <b><strong class=\"keyword\">tokens</strong></b> para representar el <b><strong class=\"keyword\">significado</strong></b> de frases o secuencias más largas, y puede generalizar a combinaciones de <b><strong class=\"keyword\">tokens</strong></b> no vistas explícitamente.</li>\n",
              "    <li><b><strong class=\"keyword\">Embeddings</strong> Contextuales (en Transformers):</b> En modelos como <b><strong class=\"keyword\">BERT</strong></b> o <b><strong class=\"keyword\">GPT</strong></b>, el <b><strong class=\"keyword\">embedding</strong></b> inicial de un <b><strong class=\"keyword\">token</strong></b> se transforma a través de las múltiples capas del <b><strong class=\"keyword\">Transformer</strong></b>. La representación final de un <b><strong class=\"keyword\">token</strong></b> (su <b><strong class=\"keyword\">vector</strong></b> contextualizado) depende de todos los demás <b><strong class=\"keyword\">tokens</strong></b> en la <b>ventana de <strong class=\"keyword\">contexto</strong></b> gracias a la <b><strong class=\"keyword\">auto-atención</strong></b>. Esto significa que la palabra \"banco\" tendrá diferentes <b><strong class=\"keyword\">vectores</strong></b> de representación final en \"fui al banco a sacar dinero\" vs. \"me senté en el banco del parque\".</li>\n",
              "</ul>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Visualizando lo Invisible: El <strong class=\"keyword\">Espacio Latente</strong></h2>\n",
              "Visualizar directamente un <b><strong class=\"keyword\">espacio latente</strong></b> de cientos o miles de dimensiones es imposible para los humanos. Sin embargo, podemos obtener una intuición de su estructura utilizando técnicas de reducción de <b><strong class=\"keyword\">dimensionalidad</strong></b> como:\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">t-SNE</strong> (t-distributed Stochastic Neighbor <strong class=\"keyword\">Embedding</strong>):</b> Popular para visualizar agrupaciones de datos de <b><strong class=\"keyword\">alta dimensión</strong></b> en 2D o 3D.</li>\n",
              "    <li><b><strong class=\"keyword\">PCA</strong> (Principal Component Analysis):</b> Otra técnica para reducir la <b><strong class=\"keyword\">dimensionalidad</strong></b> preservando la mayor varianza posible.</li>\n",
              "</ul>\n",
              "Si aplicáramos estas técnicas a los <b><strong class=\"keyword\">embeddings</strong></b> de un <b>vocabulario</b>, veríamos puntos en un gráfico 2D/3D donde palabras semánticamente similares (\"perro\", \"gato\", \"mascota\") aparecerían cerca unas de otras, mientras que palabras dispares (\"coche\", \"justicia\", \"manzana\") estarían más alejadas. También podríamos observar cómo ciertas direcciones en el espacio corresponden a conceptos (ej., una dirección para el género, otra para la pluralidad, etc.).\n",
              "<br><br>\n",
              "<i>(Imagine aquí una representación gráfica 2D donde grupos de palabras relacionadas como \"frutas\", \"animales\", \"verbos de acción\" forman clusters visualmente distinguibles.)</i>\n",
              "<div style=\"text-align:center; margin: 20px 0; padding: 15px; border: 1px dashed var(--secondary-color); border-radius: 8px; background-color: var(--pre-bg);\">\n",
              "  <p style=\"font-style:italic; color: var(--text-color);\"><b>[Placeholder Visual Conceptual]</b><br>\n",
              "  Un gráfico 2D mostraría puntos, cada uno representando un <b><strong class=\"keyword\">token</strong></b>. Palabras como \"manzana\", \"banana\", \"naranja\" estarían agrupadas. Verbos como \"correr\", \"saltar\", \"caminar\" formarían otro cluster. Adjetivos como \"grande\", \"pequeño\", \"enorme\" también se agruparían. Se podrían observar ejes conceptuales, por ejemplo, un eje que va de \"frío\" a \"caliente\".</p>\n",
              "</div>\n",
              "Estas visualizaciones son aproximaciones, pero ayudan a confirmar que el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> está aprendiendo una estructura <strong class=\"keyword\">semántica</strong> coherente.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>La Importancia Crucial de los <strong class=\"keyword\">Embeddings</strong> para los Modelos de Lenguaje</h2>\n",
              "Los <b><strong class=\"keyword\">embeddings</strong></b> son la base sobre la cual operan las capas subsiguientes de un <b><strong class=\"keyword\">modelo de lenguaje</strong></b>, especialmente las capas <b><strong class=\"keyword\">Transformer</strong></b>:\n",
              "<ul>\n",
              "    <li><b>Entrada Significativa:</b> Proporcionan a la <b><strong class=\"keyword\">red neuronal</strong></b> una <b>entrada</b> que ya contiene información <strong class=\"keyword\">semántica</strong> y relacional, en lugar de simples IDs arbitrarios.</li>\n",
              "    <li><b>Base para la <strong class=\"keyword\">Auto-atención</strong>:</b> Los mecanismos de <b><strong class=\"keyword\">auto-atención</strong></b> en los <b>Transformers</b> operan sobre estos <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> (y sus transformaciones contextualizadas) para determinar cómo cada <b><strong class=\"keyword\">token</strong></b> se relaciona con los demás en la secuencia.</li>\n",
              "    <li><b>Eficiencia de <strong class=\"keyword\">Parámetros</strong>:</b> Aprender <b><strong class=\"keyword\">embeddings</strong></b> permite al modelo compartir conocimiento estadístico entre <b><strong class=\"keyword\">tokens</strong></b> similares, lo que es mucho más eficiente en términos de <b><strong class=\"keyword\">parámetros</strong></b> que si cada <b><strong class=\"keyword\">token</strong></b> tuviera que aprender sus relaciones desde cero de forma aislada.</li>\n",
              "    <li><b>Generación de Texto:</b> En la generación, cuando el modelo predice el siguiente <b><strong class=\"keyword\">token</strong></b>, en realidad está prediciendo una distribución de probabilidad sobre el <b>vocabulario</b>. El <b><strong class=\"keyword\">embedding</strong></b> del <b><strong class=\"keyword\">token</strong></b> predicho se utiliza para continuar el proceso.</li>\n",
              "</ul>\n",
              "Sin <b><strong class=\"keyword\">embeddings</strong></b> de alta calidad, la capacidad de los <b>modelos de lenguaje</b> para entender matices, generar texto coherente y realizar tareas complejas de <b><strong class=\"keyword\">NLP</strong></b> se vería severamente limitada.\n",
              "</div>\n",
              "<h2>Conceptos Clave: <strong class=\"keyword\">Tokens</strong>, <strong class=\"keyword\">Embeddings</strong> y <strong class=\"keyword\">Espacio Latente</strong></h2>\n",
              "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
              "<thead>\n",
              "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Concepto</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción Esencial</th>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">ID de Token</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Identificador numérico discreto para un <b><strong class=\"keyword\">token</strong></b> después de la <b>tokenización</b>. Carece de <b><strong class=\"keyword\">significado</strong></b> intrínseco.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Embedding</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Vector</strong></b> denso de <b><strong class=\"keyword\">alta dimensión</strong></b> que representa el <b><strong class=\"keyword\">significado</strong></b> y uso de un <b><strong class=\"keyword\">token</strong></b>. Es una <b><strong class=\"keyword\">representación numérica</strong></b> aprendida.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Espacio Latente</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Espacio vectorial multidimensional donde residen los <b><strong class=\"keyword\">embeddings</strong></b>. Su estructura geométrica (<b><strong class=\"keyword\">proximidad</strong></b>, direcciones) captura <b><strong class=\"keyword\">relaciones semánticas</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><strong class=\"keyword\">Capa de Embedding</strong></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Capa de la <b><strong class=\"keyword\">red neuronal</strong></b> que mapea <b>IDs de <strong class=\"keyword\">token</strong></b> a sus <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b> (una <b><strong class=\"keyword\">tabla de búsqueda</strong></b> aprendible).</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Aprendizaje</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b><strong class=\"keyword\">embeddings</strong></b> se aprenden durante el <b><strong class=\"keyword\">preentrenamiento</strong></b> del <b><strong class=\"keyword\">modelo de lenguaje</strong></b> al optimizar una <b><strong class=\"keyword\">función de pérdida</strong></b> en tareas de predicción textual.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Contextualización</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">En <b>Transformers</b>, los <b><strong class=\"keyword\">embeddings</strong></b> iniciales se refinan capa por capa para producir representaciones <b>contextuales</b> sensibles a la secuencia completa.</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "<div style='margin-top: 1.5em;'>\n",
              "<h2>Conclusión: <strong class=\"keyword\">Embeddings</strong> como Puente Hacia la Comprensión del Lenguaje</h2>\n",
              "La transformación de <b><strong class=\"keyword\">tokens</strong></b> discretos en ricos <b><strong class=\"keyword\">vectores</strong></b> de <b><strong class=\"keyword\">embedding</strong></b>, y su proyección en un <b><strong class=\"keyword\">espacio latente</strong></b> estructurado semánticamente, es un paso absolutamente fundamental en el funcionamiento de los <b>modelos de lenguaje</b> modernos. Es el mecanismo por el cual estos modelos comienzan a \"entender\" el <b><strong class=\"keyword\">significado</strong></b>, el <b><strong class=\"keyword\">contexto</strong></b> y las sutiles relaciones del lenguaje humano.<br><br>\n",
              "Estos <b><strong class=\"keyword\">embeddings</strong></b>, aprendidos a través de un extenso <b><strong class=\"keyword\">preentrenamiento</strong></b> y refinados contextualmente por arquitecturas como el <b><strong class=\"keyword\">Transformer</strong></b>, no son solo representaciones pasivas; son <b><strong class=\"keyword\">parámetros</strong></b> activos que permiten a los modelos realizar inferencias, generar texto coherente y llevar a cabo una asombrosa variedad de tareas de <b><strong class=\"keyword\">NLP</strong></b>. Comprender los <b><strong class=\"keyword\">embeddings</strong></b> y el <b><strong class=\"keyword\">espacio latente</strong></b> es, por lo tanto, esencial para apreciar la profundidad y la capacidad de la inteligencia artificial lingüística actual.\n",
              "</div>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = function() {\n",
              "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    if (!themeToggleButton) {\n",
              "        const button = document.createElement('button');\n",
              "        button.id = \"theme-toggle-btn\";\n",
              "        button.className = \"theme-toggle\";\n",
              "        button.title = \"Cambiar tema de color\";\n",
              "        button.onclick = toggleTheme;\n",
              "        document.body.appendChild(button);\n",
              "        themeToggleButton = button;\n",
              "    }\n",
              "\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let currentThemeIsDark = false;\n",
              "\n",
              "    if (savedTheme === \"dark\") {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    } else if (savedTheme === \"light\") {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        currentThemeIsDark = false;\n",
              "    } else if (prefersDark) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    }\n",
              "\n",
              "    if (themeToggleButton) {\n",
              "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
              "    }\n",
              "};\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# 1. Función para resaltar palabras clave (versión simple y robusta)\n",
        "def simple_highlight_keywords(text, keywords):\n",
        "    keywords_sorted = sorted(keywords, key=len, reverse=True)\n",
        "    if not keywords_sorted: return text\n",
        "\n",
        "    pattern = '|'.join(r'\\b(?:' + re.escape(kw) + r')\\b' for kw in keywords_sorted)\n",
        "    if not pattern: return text\n",
        "\n",
        "    def replacer(match):\n",
        "        pre_match_text = text[:match.start()]\n",
        "        last_open_bracket = pre_match_text.rfind('<')\n",
        "        last_close_bracket = pre_match_text.rfind('>')\n",
        "        if last_open_bracket > last_close_bracket:\n",
        "            return match.group(0)\n",
        "\n",
        "        if match.start() > 1:\n",
        "            char_before1 = text[match.start()-1]\n",
        "            char_before2 = text[match.start()-2]\n",
        "            if (char_before1 == '\"' and char_before2 == '=') or \\\n",
        "               (char_before1 == \"'\" and char_before2 == '='):\n",
        "               return match.group(0)\n",
        "        return f'<strong class=\"keyword\">{match.group(0)}</strong>'\n",
        "    try:\n",
        "        return re.sub(pattern, replacer, text, flags=re.IGNORECASE)\n",
        "    except re.error as e:\n",
        "        print(f\"Advertencia: Error en el patrón regex: {e}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en simple_highlight_keywords: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return text\n",
        "\n",
        "# 2. Palabras clave para resaltar\n",
        "keywords_embedding = [\n",
        "    \"embedding\", \"embeddings\", \"espacio latente\", \"vector\", \"vectores\", \"token\", \"tokens\",\n",
        "    \"modelo de lenguaje\", \"NLP\", \"Transformer\", \"red neuronal\", \"semántica\", \"contexto\",\n",
        "    \"dimensionalidad\", \"alta dimensión\", \"capa de embedding\", \"tabla de búsqueda\",\n",
        "    \"preentrenamiento\", \"Word2Vec\", \"GloVe\", \"BERT\", \"GPT\", \"auto-atención\",\n",
        "    \"aprendizaje profundo\", \"parámetros\", \"función de pérdida\", \"proximidad\",\n",
        "    \"analogías vectoriales\", \"relaciones semánticas\", \"t-SNE\", \"PCA\", \"ID de token\",\n",
        "    \"representación numérica\", \"significado\", \"contextual\", \"estático\", \"coordenadas\"\n",
        "]\n",
        "\n",
        "# 3. Secciones didácticas\n",
        "sections_embedding = {\n",
        "    \"title\": \"De Tokens a Embeddings: El Viaje al Espacio Latente Semántico\",\n",
        "    \"subtitle\": \"Comprendiendo cómo los Modelos de Lenguaje representan el significado del texto\",\n",
        "    \"intro_problema\": \"\"\"\n",
        "<h2>El Desafío: De Símbolos Discretos a Comprensión Numérica</h2>\n",
        "Una vez que un texto ha sido procesado mediante la <b>tokenización</b>, obtenemos una secuencia de <b>tokens</b> (o más precisamente, sus <b>IDs de token</b> numéricos). Por ejemplo, la frase \"El gato duerme\" podría convertirse en <code>[ID_El, ID_gato, ID_duerme]</code> como <code>[10, 254, 700]</code>.<br><br>\n",
        "Sin embargo, estos <b>IDs de token</b> son simplemente identificadores discretos y arbitrarios. No capturan ninguna información sobre el <b>significado</b> de los <b>tokens</b> ni las relaciones entre ellos. Un <b>modelo de lenguaje</b> no puede operar directamente con estos IDs para tareas complejas como entender el <b>contexto</b> o generar texto coherente. Necesitamos una forma de transformar estos <b>tokens</b> en <b>representaciones numéricas</b> ricas y densas que la <b>red neuronal</b> pueda procesar: aquí es donde entran en juego los <b>embeddings</b>.\n",
        "\"\"\",\n",
        "    \"que_son_embeddings\": \"\"\"\n",
        "<h2>¿Qué son los Embeddings? Traduciendo Tokens a Vectores</h2>\n",
        "Un <b>embedding</b> (o incrustación) es una <b>representación numérica</b> de un <b>token</b> (o a veces de palabras, frases o incluso documentos) en forma de un <b>vector</b> denso de números de punto flotante. Estos <b>vectores</b> suelen tener una <b>alta dimensión</b> (por ejemplo, 768, 1024, 4096 o más dimensiones para modelos como <b>BERT</b> o <b>GPT</b>).\n",
        "<ul>\n",
        "    <li><b>Denso vs. Disperso:</b> A diferencia de las representaciones \"one-hot\" (donde un <b>vector</b> es mayormente ceros con un solo '1'), los <b>embeddings</b> son densos, lo que significa que la mayoría de sus valores son distintos de cero.</li>\n",
        "    <li><b>Coordenadas Semánticas:</b> Se puede pensar en un <b>embedding</b> como un conjunto de <b>coordenadas</b> que ubican un <b>token</b> en un vasto mapa multidimensional. La posición en este mapa (el <b>espacio latente</b>) refleja el <b>significado</b> y uso del <b>token</b>.</li>\n",
        "    <li><b>Aprendidos, no Fijos:</b> Crucialmente, estos <b>vectores</b> de <b>embedding</b> no son asignados al azar; son <b>parámetros</b> del <b>modelo de lenguaje</b> que se aprenden y ajustan durante el proceso de <b>preentrenamiento</b>.</li>\n",
        "</ul>\n",
        "Ejemplo conceptual:\n",
        "<pre>\n",
        "ID_token para \"rey\" (ej. 5021) → <b>Embedding</b>: [0.23, -0.51, 0.08, ..., 0.74]  (un <b>vector</b> de, digamos, 768 números)\n",
        "ID_token para \"reina\" (ej. 6034) → <b>Embedding</b>: [0.28, -0.45, 0.12, ..., 0.69] (otro <b>vector</b> de 768 números)\n",
        "</pre>\n",
        "La idea es que los <b>vectores</b> para \"rey\" y \"reina\" sean relativamente cercanos en este espacio debido a su similar <b>significado</b>.\n",
        "\"\"\",\n",
        "    \"espacio_latente\": \"\"\"\n",
        "<h2>El Espacio Latente: Un Universo de Significado</h2>\n",
        "Los <b>vectores</b> de <b>embedding</b> \"viven\" en un <b>espacio latente</b> (o espacio de embedding). Este es un espacio vectorial multidimensional donde cada dimensión contribuye a capturar algún aspecto (latente o oculto) del <b>significado</b> o uso de los <b>tokens</b>.\n",
        "<ul>\n",
        "    <li><b>Estructura Semántica:</b> La magia del <b>espacio latente</b> reside en que su estructura geométrica refleja las <b>relaciones semánticas</b> entre los <b>tokens</b>. Los <b>tokens</b> con significados similares o que se usan en <b>contextos</b> parecidos tienden a agruparse, mientras que los <b>tokens</b> con significados dispares se encuentran más alejados.</li>\n",
        "    <li><b>Continuidad:</b> El espacio es continuo, lo que permite al modelo generalizar. Un nuevo <b>token</b> (o una combinación de ellos) puede ser proyectado a una región del espacio, heredando propiedades de sus vecinos.</li>\n",
        "    <li><b>Descubierto por el Modelo:</b> El <b>modelo de lenguaje</b>, durante su <b>preentrenamiento</b>, aprende a organizar este <b>espacio latente</b> de manera que sea útil para la tarea de predicción de lenguaje (ej., predecir el siguiente <b>token</b> o un <b>token</b> enmascarado).</li>\n",
        "</ul>\n",
        "Este espacio no es algo que diseñemos explícitamente; emerge como resultado del <b>aprendizaje profundo</b> sobre grandes cantidades de texto.\n",
        "\"\"\",\n",
        "    \"como_se_aprenden\": \"\"\"\n",
        "<h2>¿Cómo se Aprenden los Embeddings y se Construye el Espacio Latente?</h2>\n",
        "La creación de <b>embeddings</b> significativos es uno de los logros clave del <b>preentrenamiento</b> de los <b>modelos de lenguaje</b>.\n",
        "<ol>\n",
        "    <li><b>Capa de Embedding (Embedding Layer):</b>\n",
        "        <ul>\n",
        "            <li>En la arquitectura de una <b>red neuronal</b> para <b>NLP</b>, la primera capa suele ser una <b>capa de embedding</b>. Esta capa funciona esencialmente como una gran <b>tabla de búsqueda</b> (o matriz de pesos).</li>\n",
        "            <li>Las filas de esta tabla corresponden a todos los <b>IDs de token</b> posibles en el <b>vocabulario</b> del modelo, y cada fila es el <b>vector</b> de <b>embedding</b> para ese <b>token</b>.</li>\n",
        "            <li>Cuando un <b>ID de token</b> entra en el modelo, la <b>capa de embedding</b> simplemente \"busca\" y devuelve el <b>vector</b> de <b>embedding</b> correspondiente.</li>\n",
        "            <li>Inicialmente, estos <b>vectores</b> pueden ser aleatorios, pero sus valores son <b>parámetros</b> que se actualizan durante el entrenamiento.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Aprendizaje a Través de Tareas de Predicción Lingüística:</b>\n",
        "        <ul>\n",
        "            <li>Los <b>modelos de lenguaje</b> se preentrenan en tareas como predecir el siguiente <b>token</b> en una secuencia (enfoque <b>causal</b> como <b>GPT</b>) o predecir <b>tokens</b> enmascarados (enfoque bidireccional como <b>BERT</b>).</li>\n",
        "            <li>Para realizar bien estas tareas, el modelo necesita aprender qué <b>tokens</b> tienden a aparecer juntos y en qué <b>contextos</b>. Para ello, ajusta los <b>parámetros</b> de sus <b>embeddings</b> (y del resto de la <b>red neuronal</b>) para minimizar una <b>función de pérdida</b> (un indicador de cuán incorrectas son sus predicciones).</li>\n",
        "            <li>Si el modelo predice incorrectamente, la señal de error se retropropaga a través de la red, y los <b>embeddings</b> de los <b>tokens</b> involucrados se ajustan ligeramente para que, en el futuro, la predicción sea mejor.</li>\n",
        "            <li>Por ejemplo, si el modelo ve frecuentemente \"El gato persigue al _____\" seguido de \"ratón\", los <b>embeddings</b> de \"gato\", \"persigue\", \"al\" y \"ratón\" se ajustarán de tal manera que la presencia de los primeros haga más probable la predicción del último. Esto implica que sus <b>vectores</b> se organizarán en el <b>espacio latente</b> de una forma que capture esta relación.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Influencias Históricas (Word2Vec, GloVe):</b>\n",
        "        <ul>\n",
        "            <li>Antes de los <b>Transformers</b>, algoritmos como <b>Word2Vec</b> (Skip-gram, CBOW) y <b>GloVe</b> fueron pioneros en aprender <b>embeddings</b> de palabras de alta calidad a partir de grandes corpus, basándose en la hipótesis distribucional (\"una palabra se conoce por la compañía que mantiene\"). Estos producían <b>embeddings estáticos</b> (un solo <b>vector</b> por palabra, independientemente del <b>contexto</b>).</li>\n",
        "            <li>Los <b>modelos de lenguaje</b> modernos como <b>BERT</b> y <b>GPT</b> aprenden <b>embeddings contextuales</b>. Aunque hay un <b>embedding</b> base para cada <b>token</b> en la <b>capa de embedding</b> inicial, estos <b>vectores</b> son luego procesados y transformados por las capas <b>Transformer</b> (especialmente por los mecanismos de <b>auto-atención</b>) para generar representaciones que dependen del <b>contexto</b> específico en el que aparece el <b>token</b>.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ol>\n",
        "\"\"\",\n",
        "    \"caracteristicas_espacio_latente\": \"\"\"\n",
        "<h2>Propiedades Fascinantes de los Embeddings y el Espacio Latente</h2>\n",
        "El <b>espacio latente</b> aprendido exhibe propiedades notables:\n",
        "<ul>\n",
        "    <li><b>Proximidad Semántica:</b> <b>Tokens</b> con significados similares o que se usan en roles gramaticales parecidos tienden a tener <b>vectores</b> de <b>embedding</b> cercanos en el <b>espacio latente</b> (medido por distancias como la euclidiana o la similitud del coseno). Ej: \"feliz\", \"alegre\", \"contento\" estarían agrupados.</li>\n",
        "    <li><b>Analogías Vectoriales:</b> Una de las propiedades más famosas es la capacidad de realizar aritmética vectorial que refleja analogías semánticas. El ejemplo clásico es: <code><b>vector</b>(\"rey\") - <b>vector</b>(\"hombre\") + <b>vector</b>(\"mujer\") ≈ <b>vector</b>(\"reina\")</code>. Esto sugiere que el <b>espacio latente</b> captura relaciones complejas de manera estructurada.</li>\n",
        "    <li><b>Composición y Generalización:</b> El modelo puede componer <b>embeddings</b> de <b>tokens</b> para representar el <b>significado</b> de frases o secuencias más largas, y puede generalizar a combinaciones de <b>tokens</b> no vistas explícitamente.</li>\n",
        "    <li><b>Embeddings Contextuales (en Transformers):</b> En modelos como <b>BERT</b> o <b>GPT</b>, el <b>embedding</b> inicial de un <b>token</b> se transforma a través de las múltiples capas del <b>Transformer</b>. La representación final de un <b>token</b> (su <b>vector</b> contextualizado) depende de todos los demás <b>tokens</b> en la <b>ventana de contexto</b> gracias a la <b>auto-atención</b>. Esto significa que la palabra \"banco\" tendrá diferentes <b>vectores</b> de representación final en \"fui al banco a sacar dinero\" vs. \"me senté en el banco del parque\".</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"visualizacion_conceptual\": \"\"\"\n",
        "<h2>Visualizando lo Invisible: El Espacio Latente</h2>\n",
        "Visualizar directamente un <b>espacio latente</b> de cientos o miles de dimensiones es imposible para los humanos. Sin embargo, podemos obtener una intuición de su estructura utilizando técnicas de reducción de <b>dimensionalidad</b> como:\n",
        "<ul>\n",
        "    <li><b>t-SNE (t-distributed Stochastic Neighbor Embedding):</b> Popular para visualizar agrupaciones de datos de <b>alta dimensión</b> en 2D o 3D.</li>\n",
        "    <li><b>PCA (Principal Component Analysis):</b> Otra técnica para reducir la <b>dimensionalidad</b> preservando la mayor varianza posible.</li>\n",
        "</ul>\n",
        "Si aplicáramos estas técnicas a los <b>embeddings</b> de un <b>vocabulario</b>, veríamos puntos en un gráfico 2D/3D donde palabras semánticamente similares (\"perro\", \"gato\", \"mascota\") aparecerían cerca unas de otras, mientras que palabras dispares (\"coche\", \"justicia\", \"manzana\") estarían más alejadas. También podríamos observar cómo ciertas direcciones en el espacio corresponden a conceptos (ej., una dirección para el género, otra para la pluralidad, etc.).\n",
        "<br><br>\n",
        "<i>(Imagine aquí una representación gráfica 2D donde grupos de palabras relacionadas como \"frutas\", \"animales\", \"verbos de acción\" forman clusters visualmente distinguibles.)</i>\n",
        "<div style=\"text-align:center; margin: 20px 0; padding: 15px; border: 1px dashed var(--secondary-color); border-radius: 8px; background-color: var(--pre-bg);\">\n",
        "  <p style=\"font-style:italic; color: var(--text-color);\"><b>[Placeholder Visual Conceptual]</b><br>\n",
        "  Un gráfico 2D mostraría puntos, cada uno representando un <b>token</b>. Palabras como \"manzana\", \"banana\", \"naranja\" estarían agrupadas. Verbos como \"correr\", \"saltar\", \"caminar\" formarían otro cluster. Adjetivos como \"grande\", \"pequeño\", \"enorme\" también se agruparían. Se podrían observar ejes conceptuales, por ejemplo, un eje que va de \"frío\" a \"caliente\".</p>\n",
        "</div>\n",
        "Estas visualizaciones son aproximaciones, pero ayudan a confirmar que el <b>modelo de lenguaje</b> está aprendiendo una estructura semántica coherente.\n",
        "\"\"\",\n",
        "    \"importancia_para_llm\": \"\"\"\n",
        "<h2>La Importancia Crucial de los Embeddings para los Modelos de Lenguaje</h2>\n",
        "Los <b>embeddings</b> son la base sobre la cual operan las capas subsiguientes de un <b>modelo de lenguaje</b>, especialmente las capas <b>Transformer</b>:\n",
        "<ul>\n",
        "    <li><b>Entrada Significativa:</b> Proporcionan a la <b>red neuronal</b> una <b>entrada</b> que ya contiene información semántica y relacional, en lugar de simples IDs arbitrarios.</li>\n",
        "    <li><b>Base para la Auto-atención:</b> Los mecanismos de <b>auto-atención</b> en los <b>Transformers</b> operan sobre estos <b>vectores</b> de <b>embedding</b> (y sus transformaciones contextualizadas) para determinar cómo cada <b>token</b> se relaciona con los demás en la secuencia.</li>\n",
        "    <li><b>Eficiencia de Parámetros:</b> Aprender <b>embeddings</b> permite al modelo compartir conocimiento estadístico entre <b>tokens</b> similares, lo que es mucho más eficiente en términos de <b>parámetros</b> que si cada <b>token</b> tuviera que aprender sus relaciones desde cero de forma aislada.</li>\n",
        "    <li><b>Generación de Texto:</b> En la generación, cuando el modelo predice el siguiente <b>token</b>, en realidad está prediciendo una distribución de probabilidad sobre el <b>vocabulario</b>. El <b>embedding</b> del <b>token</b> predicho se utiliza para continuar el proceso.</li>\n",
        "</ul>\n",
        "Sin <b>embeddings</b> de alta calidad, la capacidad de los <b>modelos de lenguaje</b> para entender matices, generar texto coherente y realizar tareas complejas de <b>NLP</b> se vería severamente limitada.\n",
        "\"\"\",\n",
        "    \"tabla_resumen_embedding\": \"\"\"\n",
        "<h2>Conceptos Clave: Tokens, Embeddings y Espacio Latente</h2>\n",
        "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
        "<thead>\n",
        "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Concepto</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción Esencial</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>ID de Token</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Identificador numérico discreto para un <b>token</b> después de la <b>tokenización</b>. Carece de <b>significado</b> intrínseco.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Embedding</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Vector</b> denso de <b>alta dimensión</b> que representa el <b>significado</b> y uso de un <b>token</b>. Es una <b>representación numérica</b> aprendida.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Espacio Latente</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Espacio vectorial multidimensional donde residen los <b>embeddings</b>. Su estructura geométrica (<b>proximidad</b>, direcciones) captura <b>relaciones semánticas</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Capa de Embedding</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Capa de la <b>red neuronal</b> que mapea <b>IDs de token</b> a sus <b>vectores</b> de <b>embedding</b> (una <b>tabla de búsqueda</b> aprendible).</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Aprendizaje</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Los <b>embeddings</b> se aprenden durante el <b>preentrenamiento</b> del <b>modelo de lenguaje</b> al optimizar una <b>función de pérdida</b> en tareas de predicción textual.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Contextualización</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">En <b>Transformers</b>, los <b>embeddings</b> iniciales se refinan capa por capa para producir representaciones <b>contextuales</b> sensibles a la secuencia completa.</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\"\"\",\n",
        "    \"conclusion_embedding\": \"\"\"\n",
        "<h2>Conclusión: Embeddings como Puente Hacia la Comprensión del Lenguaje</h2>\n",
        "La transformación de <b>tokens</b> discretos en ricos <b>vectores</b> de <b>embedding</b>, y su proyección en un <b>espacio latente</b> estructurado semánticamente, es un paso absolutamente fundamental en el funcionamiento de los <b>modelos de lenguaje</b> modernos. Es el mecanismo por el cual estos modelos comienzan a \"entender\" el <b>significado</b>, el <b>contexto</b> y las sutiles relaciones del lenguaje humano.<br><br>\n",
        "Estos <b>embeddings</b>, aprendidos a través de un extenso <b>preentrenamiento</b> y refinados contextualmente por arquitecturas como el <b>Transformer</b>, no son solo representaciones pasivas; son <b>parámetros</b> activos que permiten a los modelos realizar inferencias, generar texto coherente y llevar a cabo una asombrosa variedad de tareas de <b>NLP</b>. Comprender los <b>embeddings</b> y el <b>espacio latente</b> es, por lo tanto, esencial para apreciar la profundidad y la capacidad de la inteligencia artificial lingüística actual.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "ordered_sections_keys_emb = [\n",
        "    \"title\", \"subtitle\", \"intro_problema\", \"que_son_embeddings\", \"espacio_latente\",\n",
        "    \"como_se_aprenden\", \"caracteristicas_espacio_latente\", \"visualizacion_conceptual\",\n",
        "    \"importancia_para_llm\", \"tabla_resumen_embedding\", \"conclusion_embedding\"\n",
        "]\n",
        "\n",
        "# 4. Aplicar el resaltado\n",
        "highlighted_sections_emb = {\n",
        "    k: simple_highlight_keywords(sections_embedding[k], keywords_embedding)\n",
        "    for k in ordered_sections_keys_emb if k in sections_embedding\n",
        "}\n",
        "\n",
        "# 5. CSS + JS (reutilizando los estilos mejorados)\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #1e88e5;\n",
        "  --secondary-color: #00acc1;\n",
        "  --text-color: #37474f;\n",
        "  --bg-color: #f4f6f8;\n",
        "  --container-bg: #ffffff;\n",
        "  --keyword-bg: #e0f7fa;\n",
        "  --keyword-text: #00796b;\n",
        "  --button-bg: #e9ecef;\n",
        "  --button-hover-bg: #ced4da;\n",
        "  --button-text-color: #212529;\n",
        "  --shadow-color: rgba(0,0,0,0.08);\n",
        "  --table-border-color: #dee2e6;\n",
        "  --row-bg-odd: #f8f9fa;\n",
        "  --row-bg-even: #ffffff;\n",
        "  --pre-bg: #e9ecef;\n",
        "  --pre-text: #212529;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #42a5f5;\n",
        "  --secondary-color: #26c6da;\n",
        "  --text-color: #e0e0e0;\n",
        "  --bg-color: #121212;\n",
        "  --container-bg: #1e1e1e;\n",
        "  --keyword-bg: #37474f;\n",
        "  --keyword-text: #80deea;\n",
        "  --button-bg: #343a40;\n",
        "  --button-hover-bg: #495057;\n",
        "  --button-text-color: #f8f9fa;\n",
        "  --shadow-color: rgba(0,0,0,0.5);\n",
        "  --table-border-color: #495057;\n",
        "  --row-bg-odd: #2c3034;\n",
        "  --row-bg-even: #212529;\n",
        "  --pre-bg: #2c3034;\n",
        "  --pre-text: #f8f9fa;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Roboto', 'Arial', sans-serif;\n",
        "  line-height: 1.75;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 20px;\n",
        "  margin: 0;\n",
        "}\n",
        ".container {\n",
        "  max-width: 980px; /* Un poco más ancho para contenido denso */\n",
        "  margin: 30px auto;\n",
        "  padding: 30px 40px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 12px;\n",
        "  box-shadow: 0 6px 18px var(--shadow-color);\n",
        "  position: relative;\n",
        "  transition: background-color .3s, box-shadow .3s;\n",
        "  border-top: 7px solid var(--primary-color);\n",
        "}\n",
        "h1 {\n",
        "  color: var(--primary-color);\n",
        "  font-size: 2.4em; /* Ligeramente más grande para el título principal */\n",
        "  margin-bottom: .1em;\n",
        "  line-height: 1.25;\n",
        "  text-align: center;\n",
        "  border-bottom: 2px solid var(--secondary-color);\n",
        "  padding-bottom: 0.3em;\n",
        "}\n",
        "h2 {\n",
        "  color: var(--secondary-color);\n",
        "  text-align: left;\n",
        "  margin-top: 2.3em;\n",
        "  margin-bottom: .8em;\n",
        "  font-size: 1.8em; /* Consistente para subtítulos de sección */\n",
        "  border-bottom: 1px solid #ddd;\n",
        "  padding-bottom: 0.2em;\n",
        "}\n",
        "body.dark-mode h2 {\n",
        "    border-bottom: 1px solid #444;\n",
        "}\n",
        ".subtitle-style {\n",
        "  font-style:italic;\n",
        "  font-weight:400;\n",
        "  color: var(--text-color);\n",
        "  opacity: 0.85;\n",
        "  text-align:center;\n",
        "  margin-top:0.2em;\n",
        "  margin-bottom: 1.8em; /* Más espacio después del subtítulo */\n",
        "  font-size: 1.15em; /* Ligeramente más grande */\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.2em 0.4em;\n",
        "  border-radius: 5px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--button-bg);\n",
        "  color: var(--button-text-color);\n",
        "  border: 1.5px solid var(--secondary-color);\n",
        "  padding: 9px 14px;\n",
        "  border-radius: 6px;\n",
        "  cursor: pointer;\n",
        "  position: fixed;\n",
        "  top: 20px;\n",
        "  right: 25px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
        "  z-index: 1000;\n",
        "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--button-hover-bg);\n",
        "    transform: translateY(-1px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 3px solid var(--primary-color);\n",
        "    outline-offset: 2px;\n",
        "    border-color: var(--primary-color);\n",
        "}\n",
        "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
        "ol li, ul li { margin-bottom:0.7em; } /* Más espacio entre ítems de lista */\n",
        "p { margin-bottom: 1.3em; } /* Espacio consistente para párrafos */\n",
        "b { color: var(--primary-color); font-weight: 600;}\n",
        "table {\n",
        "    font-size:0.95em;\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "}\n",
        "table th, table td {\n",
        "    padding:10px 12px !important;\n",
        "    border:1px solid var(--table-border-color) !important;\n",
        "    text-align: left;\n",
        "    vertical-align: top;\n",
        "}\n",
        "table th { font-weight: 600; background-color: var(--row-bg-odd); }\n",
        "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
        "\n",
        "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "\n",
        "pre {\n",
        "    background: var(--pre-bg);\n",
        "    color: var(--pre-text);\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 0.9em;\n",
        "    line-height: 1.6;\n",
        "    overflow-x: auto;\n",
        "    margin: 1.2em 0;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
        "}\n",
        "code.language-python, code.nohighlight { /* Para tiktoken u otros ejemplos */\n",
        "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = function() {\n",
        "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    if (!themeToggleButton) {\n",
        "        const button = document.createElement('button');\n",
        "        button.id = \"theme-toggle-btn\";\n",
        "        button.className = \"theme-toggle\";\n",
        "        button.title = \"Cambiar tema de color\";\n",
        "        button.onclick = toggleTheme;\n",
        "        document.body.appendChild(button);\n",
        "        themeToggleButton = button;\n",
        "    }\n",
        "\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let currentThemeIsDark = false;\n",
        "\n",
        "    if (savedTheme === \"dark\") {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    } else if (savedTheme === \"light\") {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        currentThemeIsDark = false;\n",
        "    } else if (prefersDark) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    }\n",
        "\n",
        "    if (themeToggleButton) {\n",
        "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
        "    }\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# 6. Ensamblar el HTML\n",
        "html_body_content_emb = f\"<h1>{highlighted_sections_emb.get('title', '')}</h1>\"\n",
        "html_body_content_emb += f\"<p class='subtitle-style'>{highlighted_sections_emb.get('subtitle', '')}</p>\"\n",
        "\n",
        "for key in ordered_sections_keys_emb:\n",
        "    if key not in [\"title\", \"subtitle\"] and key in highlighted_sections_emb:\n",
        "        if key == \"tabla_resumen_embedding\": # Evitar doble margen para la tabla\n",
        "             html_body_content_emb += highlighted_sections_emb[key]\n",
        "        else:\n",
        "             html_body_content_emb += f\"<div style='margin-top: 1.5em;'>{highlighted_sections_emb[key]}</div>\" # Ajuste de margen\n",
        "\n",
        "\n",
        "html_structure_emb = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{sections_embedding.get('title', 'Embeddings en NLP')}</title>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
        "    {css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
        "<div class=\"container\">\n",
        "    {html_body_content_emb}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_structure_emb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902,
          "referenced_widgets": [
            "bfcc5b0f6a1740b683883866c73c534f",
            "a1624052764244129b377cc61d0762e9",
            "e475cae1bd1447bd805b61deb0e691cb",
            "7ec4ae1ec09e4a0aa8332edaf004548c",
            "fe03ffd144ef437ebf9f47495bee4e57",
            "25c4de2f8f4a423394784d7ba56a2ae4",
            "bca35c96814b4668a4b98032b70a8d42",
            "27561268ba534f9a96bfa8911167aaf5",
            "2b83365a3cb64109b659f7f1245a8c60",
            "ae6a3d0e5e084ea395783d68531d90d5",
            "5923bbf7c5b44464ab656fe943b44345",
            "6591ce31174149a09ac246a2e051fdff",
            "b93f2efe86d8421d85e76dd6ac5a75e0",
            "ba1abc407393486fa76373dde164346f",
            "46712be7a51949f0a6f11357b0b4c7fe",
            "f6f9ad8aab9d463c88afefb59abe6b16",
            "4b454eed0951470d96c811340443d8d6",
            "3d860e2d9dd14977a481d4c2754e3004",
            "906a585ba06f479badd707767b9f161d",
            "ec2a630411524b238150a6681d938d49",
            "29374c1ae5b14b7ea1782a5f49eadd30",
            "a84db0ebaec14a40a054f310b45d5e4c",
            "8e8b3130dd9c4f9e87107c27e0dd6d3a",
            "28bd9d83e7f341ae84b190a7660122ce",
            "fca11e9860034b53885cffaf93ca17e3",
            "fbe79ac23c1a4d5da1323baea5599a55",
            "ddacfacc9f7f4697b44c1089fa9a3fd8",
            "b00761e205a441ce947c9bd8fcfc8e8c",
            "bf3e275739324454ae1c1bd9d2532b5d",
            "790c303b35a348729aef0f08385568c8",
            "4d0eba10762645228b35e6fb6f02c361",
            "e1d11965ce094dd182575db705e07d70",
            "eae05e7d38724908ab52d753c9bc1837",
            "337885f09c3f475a89ad29348b7f7f93",
            "aa9357d9fb1345569fbbfbaa8b345e4a",
            "dce7d6a2d3ff4a748e0984345be32abd"
          ]
        },
        "id": "0gD76opbLBdx",
        "outputId": "95457b56-e65b-4f6c-cf8e-789753ea08be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificando e instalacion de dependencias...\n",
            "Instalando scikit-learn...\n",
            "scikit-learn instalado correctamente.\n",
            "Error al instalar scikit-learn: No module named 'scikit_learn'\n",
            "\n",
            "Advertencia: Algunas dependencias no pudieron ser instaladas. El script podria no funcionar correctamente.\n",
            "\n",
            "Librerias cargadas.\n",
            "\n",
            "Inicializando analizador optimizado...\n",
            "Analizador inicializado (modelo SentenceTransformer se cargara bajo demanda).\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "        .widget-container { margin-bottom: 10px; }\n",
              "        .widget-label { font-weight: bold; margin-right: 5px; min-width: 80px !important; }\n",
              "        .widget-button { margin: 5px; }\n",
              "        .output-area-title {\n",
              "            font-size: 1.3em; font-weight: bold; color: #2c3e50;\n",
              "            padding: 10px; background-color: #ecf0f1; border-radius: 5px;\n",
              "            margin-top: 15px; margin-bottom: 10px; text-align: center;\n",
              "        }\n",
              "        .info-block {\n",
              "            background-color: #e8f4fd; border-left: 5px solid #3498db;\n",
              "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #2980b9;\n",
              "        }\n",
              "        .success-block {\n",
              "            background-color: #e6ffed; border-left: 5px solid #2ecc71;\n",
              "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #27ae60;\n",
              "        }\n",
              "        .warning-block {\n",
              "            background-color: #fff9e6; border-left: 5px solid #f39c12;\n",
              "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #d35400;\n",
              "        }\n",
              "        .error-block {\n",
              "            background-color: #ffe6e6; border-left: 5px solid #e74c3c;\n",
              "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #c0392b;\n",
              "        }\n",
              "        .embedding-lab-header {\n",
              "            background: linear-gradient(135deg, #5D9CEC 0%, #5A00A5 100%);\n",
              "            color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; text-align: center;\n",
              "            box-shadow: 0 5px 15px rgba(0,0,0,0.1);\n",
              "        }\n",
              "        .embedding-lab-header h2 { margin-top: 0; font-size: 24px; }\n",
              "        .embedding-lab-header p { font-size: 16px; opacity: 0.9; }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div class=\"embedding-lab-header\">\n",
              "        <h2>LABORATORIO DE EMBEDDINGS Y ESPACIO LATENTE</h2>\n",
              "        <p>Explora como los Modelos de Lenguaje representan el significado del texto.</p>\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfcc5b0f6a1740b683883866c73c534f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(VBox(children=(HTML(value=\"<h3 style='color:#34495e; margin-bottom:5px;'>Ingresa tus Textos:</h…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ==================================================================================\n",
        "# VISUALIZACION DE EMBEDDINGS OPTIMIZADA: DE TOKENS AL ESPACIO LATENTE\n",
        "# Laboratorio Avanzado Optimizado para Mejor Performance\n",
        "# ==================================================================================\n",
        "\n",
        "\"\"\"\n",
        "OPTIMIZACIONES IMPLEMENTADAS:\n",
        "- Carga lazy de modelos pesados\n",
        "- Cache de embeddings (en obtener_embedding_individual_con_cache, no usado por procesar_lote_optimizado directamente)\n",
        "- Parámetros optimizados para t-SNE\n",
        "- Manejo eficiente de memoria (procesamiento por lotes de únicos en una implementación anterior, ahora directo)\n",
        "- Visualizaciones con Matplotlib\n",
        "- Interfaz con widgets funcional\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==================================================================================\n",
        "# 1. INSTALACION E IMPORTACION OPTIMIZADA\n",
        "# ==================================================================================\n",
        "\n",
        "print(\"Verificando e instalacion de dependencias...\")\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib # Para una verificacion más robusta\n",
        "\n",
        "def install_if_missing(package_name, import_name=None):\n",
        "    if import_name is None:\n",
        "        import_name = package_name.replace('-', '_')\n",
        "    try:\n",
        "        importlib.import_module(import_name)\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"Instalando {package_name}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n",
        "            print(f\"{package_name} instalado correctamente.\")\n",
        "            importlib.import_module(import_name)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error al instalar {package_name}: {e}\")\n",
        "            return False\n",
        "\n",
        "# Instalar dependencias esenciales\n",
        "essential_packages = [\n",
        "    'tiktoken', 'numpy', 'matplotlib', 'pandas',\n",
        "    'scikit-learn', 'sentence-transformers', 'ipywidgets'\n",
        "]\n",
        "all_installed_successfully = True\n",
        "for package in essential_packages:\n",
        "    if not install_if_missing(package):\n",
        "        all_installed_successfully = False\n",
        "\n",
        "if not all_installed_successfully:\n",
        "    print(\"\\nAdvertencia: Algunas dependencias no pudieron ser instaladas. El script podria no funcionar correctamente.\")\n",
        "\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import time\n",
        "\n",
        "# Importar widgets para interfaz interactiva\n",
        "WIDGETS_AVAILABLE = False\n",
        "if install_if_missing('ipywidgets'):\n",
        "    try:\n",
        "        import ipywidgets as widgets\n",
        "        from IPython.display import display, HTML, clear_output\n",
        "        WIDGETS_AVAILABLE = True\n",
        "    except Exception as e:\n",
        "        print(f\"Widgets no disponibles o error al importar IPython.display ({e}), usando modo basico.\")\n",
        "        WIDGETS_AVAILABLE = False\n",
        "else:\n",
        "    print(\"ipywidgets no pudo ser instalado, usando modo basico.\")\n",
        "\n",
        "\n",
        "# Configuracion optimizada de matplotlib\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 7)\n",
        "plt.rcParams['figure.dpi'] = 90\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"\\nLibrerias cargadas.\\n\")\n",
        "\n",
        "# ==================================================================================\n",
        "# 2. CLASE OPTIMIZADA: ANALIZADOR DE EMBEDDINGS\n",
        "# ==================================================================================\n",
        "\n",
        "class AnalizadorEmbeddingsOptimizado:\n",
        "    \"\"\"\n",
        "    Version optimizada del analizador de embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        print(\"Inicializando analizador optimizado...\")\n",
        "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "        self._embedding_model = None\n",
        "        self.cache_embeddings_individuales = {}\n",
        "        print(\"Analizador inicializado (modelo SentenceTransformer se cargara bajo demanda).\\n\")\n",
        "\n",
        "    @property\n",
        "    def embedding_model(self):\n",
        "        \"\"\"Carga lazy del modelo de embeddings\"\"\"\n",
        "        if self._embedding_model is None:\n",
        "            print(\"Cargando modelo de embeddings SentenceTransformer ('all-MiniLM-L6-v2')... Esto puede tomar un momento la primera vez.\")\n",
        "            start_load_time = time.time()\n",
        "            try:\n",
        "                self._embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "                load_time = time.time() - start_load_time\n",
        "                print(f\"Modelo cargado en {load_time:.2f} segundos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error al cargar el modelo de embeddings: {e}\")\n",
        "                raise\n",
        "        return self._embedding_model\n",
        "\n",
        "    def obtener_embedding_individual_con_cache(self, texto):\n",
        "        \"\"\"Obtiene embedding para un solo texto con sistema de cache (no usado por procesar_lote_optimizado)\"\"\"\n",
        "        if texto in self.cache_embeddings_individuales:\n",
        "            return self.cache_embeddings_individuales[texto]\n",
        "\n",
        "        embedding = self.embedding_model.encode([texto])[0]\n",
        "        self.cache_embeddings_individuales[texto] = embedding\n",
        "        return embedding\n",
        "\n",
        "    def procesar_lote_optimizado(self, textos):\n",
        "        \"\"\"Procesamiento optimizado por lotes usando SentenceTransformer.encode en todo el lote.\"\"\"\n",
        "        if not textos:\n",
        "            print(\"Advertencia: No hay textos para procesar.\")\n",
        "            return np.array([])\n",
        "\n",
        "        print(f\"Procesando embeddings para {len(textos)} textos...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            embeddings_finales = self.embedding_model.encode(textos, show_progress_bar=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error durante la codificacion de embeddings: {e}\")\n",
        "            raise\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Embeddings procesados en {end_time - start_time:.2f} segundos.\")\n",
        "        return np.array(embeddings_finales)\n",
        "\n",
        "    def calcular_similitudes_optimizado(self, embeddings_matriz):\n",
        "        \"\"\"Calculo optimizado de similitudes\"\"\"\n",
        "        if embeddings_matriz.ndim != 2 or embeddings_matriz.shape[0] < 1:\n",
        "            print(\"Advertencia: Matriz de embeddings invalida para calcular similitudes.\")\n",
        "            return np.array([])\n",
        "        print(\"Calculando matriz de similitudes...\")\n",
        "        start_time = time.time()\n",
        "        sim = cosine_similarity(embeddings_matriz)\n",
        "        end_time = time.time()\n",
        "        print(f\"Matriz de similitudes calculada en {end_time - start_time:.2f} segundos.\")\n",
        "        return sim\n",
        "\n",
        "    def reducir_dimensionalidad_optimizada(self, embeddings_matriz, metodo='pca', n_components=2):\n",
        "        \"\"\"Reduccion dimensional optimizada\"\"\"\n",
        "        if embeddings_matriz.ndim != 2 or embeddings_matriz.shape[0] < 2 :\n",
        "             print(f\"Advertencia: No hay suficientes muestras ({embeddings_matriz.shape[0]}) para la reduccion de dimensionalidad. Se requieren al menos 2.\")\n",
        "             return np.array([])\n",
        "        if n_components >= embeddings_matriz.shape[1]:\n",
        "            print(f\"Advertencia: n_components ({n_components}) es >= que las dimensiones originales ({embeddings_matriz.shape[1]}). Devolviendo embeddings originales.\")\n",
        "            return embeddings_matriz[:, :n_components]\n",
        "\n",
        "        print(f\"Aplicando {metodo.upper()} para reducir a {n_components} dimensiones...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        if metodo.lower() == 'pca':\n",
        "            actual_n_components = min(n_components, embeddings_matriz.shape[0], embeddings_matriz.shape[1])\n",
        "            reducer = PCA(n_components=actual_n_components, random_state=42)\n",
        "        elif metodo.lower() == 'tsne':\n",
        "            if embeddings_matriz.shape[0] <= n_components:\n",
        "                 print(f\"Advertencia: Pocas muestras ({embeddings_matriz.shape[0]}) para t-SNE con {n_components} componentes. Usando PCA como fallback.\")\n",
        "                 actual_n_components = min(n_components, embeddings_matriz.shape[0], embeddings_matriz.shape[1])\n",
        "                 reducer = PCA(n_components=actual_n_components, random_state=42)\n",
        "            else:\n",
        "                perplexity_val = min(30, max(1, embeddings_matriz.shape[0] - 1))\n",
        "                reducer = TSNE(\n",
        "                    n_components=n_components,\n",
        "                    random_state=42,\n",
        "                    perplexity=perplexity_val,\n",
        "                    n_iter=300,\n",
        "                    init='pca',\n",
        "                    learning_rate='auto',\n",
        "                    n_jobs=1\n",
        "                )\n",
        "        else:\n",
        "            print(f\"Advertencia: Metodo '{metodo}' no reconocido, usando PCA como fallback.\")\n",
        "            actual_n_components = min(n_components, embeddings_matriz.shape[0], embeddings_matriz.shape[1])\n",
        "            reducer = PCA(n_components=actual_n_components, random_state=42)\n",
        "\n",
        "        try:\n",
        "            resultado = reducer.fit_transform(embeddings_matriz)\n",
        "        except Exception as e:\n",
        "            print(f\"Error durante la reduccion de dimensionalidad con {metodo.upper()}: {e}\")\n",
        "            raise\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Reduccion completada en {end_time - start_time:.2f} segundos.\")\n",
        "        return resultado\n",
        "\n",
        "    def clustering_optimizado(self, embeddings_matriz, n_clusters=3):\n",
        "        \"\"\"Clustering optimizado con KMeans\"\"\"\n",
        "        if embeddings_matriz.ndim != 2 or embeddings_matriz.shape[0] == 0:\n",
        "            print(\"Advertencia: Matriz de embeddings invalida para clustering.\")\n",
        "            return np.array([]), np.array([])\n",
        "\n",
        "        actual_n_clusters = min(n_clusters, embeddings_matriz.shape[0])\n",
        "        if actual_n_clusters < 1:\n",
        "            print(\"Advertencia: No se puede realizar clustering con menos de 1 cluster o sin muestras.\")\n",
        "            return np.array([]), np.array([])\n",
        "\n",
        "\n",
        "        print(f\"Aplicando KMeans clustering con {actual_n_clusters} clusters...\")\n",
        "        start_time = time.time()\n",
        "        kmeans = KMeans(n_clusters=actual_n_clusters, random_state=42, n_init='auto')\n",
        "        try:\n",
        "            clusters = kmeans.fit_predict(embeddings_matriz)\n",
        "            centers = kmeans.cluster_centers_\n",
        "        except Exception as e:\n",
        "            print(f\"Error durante el clustering: {e}\")\n",
        "            raise\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Clustering completado en {end_time - start_time:.2f} segundos.\")\n",
        "        return clusters, centers\n",
        "\n",
        "# ==================================================================================\n",
        "# 3. FUNCIONES DE VISUALIZACION OPTIMIZADAS (MATPLOTLIB)\n",
        "# ==================================================================================\n",
        "\n",
        "def visualizar_embeddings_matplotlib(embeddings_reducidos, textos, clusters=None, metodo='PCA'):\n",
        "    \"\"\"Visualizacion optimizada con matplotlib\"\"\"\n",
        "    if embeddings_reducidos.size == 0 or embeddings_reducidos.shape[1] < 2:\n",
        "        print(\"Advertencia: No hay datos suficientes o en el formato correcto para visualizar embeddings.\")\n",
        "        return\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    n_textos = len(textos)\n",
        "    unique_clusters = np.unique(clusters) if clusters is not None else []\n",
        "\n",
        "    if clusters is not None and len(unique_clusters) > 0:\n",
        "        try:\n",
        "            colors_map = plt.colormaps.get_cmap('tab10')\n",
        "        except AttributeError:\n",
        "            colors_map = plt.cm.get_cmap('tab10')\n",
        "\n",
        "        colors_for_clusters = [colors_map(i) for i in np.linspace(0, 1, len(unique_clusters))]\n",
        "        cluster_map = {cluster_val: i for i, cluster_val in enumerate(unique_clusters)}\n",
        "\n",
        "        for i, cluster_id_original in enumerate(unique_clusters):\n",
        "            mask = (clusters == cluster_id_original)\n",
        "            plt.scatter(\n",
        "                embeddings_reducidos[mask, 0],\n",
        "                embeddings_reducidos[mask, 1],\n",
        "                color=colors_for_clusters[cluster_map[cluster_id_original]],\n",
        "                label=f'Cluster {cluster_id_original + 1}',\n",
        "                s=80,\n",
        "                alpha=0.8,\n",
        "                edgecolors='k',\n",
        "                linewidth=0.5\n",
        "            )\n",
        "    else:\n",
        "        plt.scatter(\n",
        "            embeddings_reducidos[:, 0],\n",
        "            embeddings_reducidos[:, 1],\n",
        "            c='skyblue',\n",
        "            s=80,\n",
        "            alpha=0.7,\n",
        "            edgecolors='k',\n",
        "            linewidth=0.5\n",
        "        )\n",
        "\n",
        "    for i, texto in enumerate(textos):\n",
        "        etiqueta = f\"T{i+1}\"\n",
        "        plt.annotate(\n",
        "            etiqueta,\n",
        "            (embeddings_reducidos[i, 0], embeddings_reducidos[i, 1]),\n",
        "            xytext=(5, 5),\n",
        "            textcoords='offset points',\n",
        "            fontsize=8,\n",
        "            color='black',\n",
        "        )\n",
        "\n",
        "    plt.title(f'Espacio Latente de Embeddings 2D ({metodo.upper()})', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(f'{metodo.upper()} Componente 1', fontsize=12)\n",
        "    plt.ylabel(f'{metodo.upper()} Componente 2', fontsize=12)\n",
        "\n",
        "    if clusters is not None and len(unique_clusters) > 0:\n",
        "        plt.legend(fontsize=10, loc='best')\n",
        "\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "    plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualizar_matriz_similitudes_optimizada(similitudes, textos):\n",
        "    \"\"\"Visualizacion optimizada de matriz de similitudes con Matplotlib\"\"\"\n",
        "    if similitudes.size == 0:\n",
        "        print(\"Advertencia: No hay datos de similitud para visualizar.\")\n",
        "        return\n",
        "\n",
        "    n_textos = len(textos)\n",
        "    fig_height = max(6, n_textos * 0.8)\n",
        "    fig_width = max(7, n_textos * 0.9)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "    etiquetas = [f\"T{i+1}: {texto[:20]}...\" if len(texto) > 20 else f\"T{i+1}: {texto}\"\n",
        "                 for i, texto in enumerate(textos)]\n",
        "\n",
        "    im = ax.imshow(similitudes, cmap='RdYlBu', aspect='equal', vmin=-1, vmax=1)\n",
        "\n",
        "    ax.set_xticks(np.arange(n_textos))\n",
        "    ax.set_yticks(np.arange(n_textos))\n",
        "    ax.set_xticklabels(etiquetas, rotation=45, ha=\"right\", fontsize=9)\n",
        "    ax.set_yticklabels(etiquetas, fontsize=9)\n",
        "\n",
        "    if n_textos > 10:\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    if n_textos <= 10:\n",
        "        for i in range(n_textos):\n",
        "            for j in range(n_textos):\n",
        "                val = similitudes[i, j]\n",
        "                text_color = \"white\" if abs(val) > 0.6 else \"black\"\n",
        "                ax.text(j, i, f\"{val:.2f}\",\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='medium')\n",
        "\n",
        "    cbar = fig.colorbar(im, ax=ax, label='Similitud Coseno', shrink=0.8, aspect=20)\n",
        "    cbar.ax.tick_params(labelsize=9)\n",
        "    cbar.set_label('Similitud Coseno', size=10)\n",
        "\n",
        "    ax.set_title('Matriz de Similitudes entre Embeddings', fontsize=14, fontweight='bold', pad=15)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def mostrar_estadisticas_detalladas(embeddings_matriz, similitudes, textos):\n",
        "    \"\"\"Mostrar estadisticas detalladas del analisis. Asume que similitudes es la matriz completa.\"\"\"\n",
        "    if embeddings_matriz.size == 0 or similitudes.size == 0:\n",
        "        print(\"Advertencia: No hay suficientes datos para estadisticas.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ESTADISTICAS DEL ANALISIS DE EMBEDDINGS\".center(70))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    n_textos, n_dims = embeddings_matriz.shape\n",
        "    print(f\"  Textos analizados: {n_textos}\")\n",
        "    print(f\"  Dimensiones de embedding: {n_dims}\")\n",
        "\n",
        "    if n_textos < 2:\n",
        "        print(\"  Informacion: Se necesitan al menos 2 textos para estadisticas de similitud entre pares.\")\n",
        "        print(\"=\"*70)\n",
        "        return\n",
        "\n",
        "    mask_triu = np.triu_indices_from(similitudes, k=1)\n",
        "    similitudes_pares = similitudes[mask_triu]\n",
        "\n",
        "    if similitudes_pares.size > 0:\n",
        "        print(f\"\\n  ANALISIS DE SIMILITUDES ENTRE PARES ({len(similitudes_pares)} pares unicos):\")\n",
        "        print(f\"     Promedio: {np.mean(similitudes_pares):.3f}\")\n",
        "        print(f\"     Maxima:   {np.max(similitudes_pares):.3f}\")\n",
        "        print(f\"     Minima:   {np.min(similitudes_pares):.3f}\")\n",
        "        print(f\"     Mediana:  {np.median(similitudes_pares):.3f}\")\n",
        "        print(f\"     Desv. Estandar: {np.std(similitudes_pares):.3f}\")\n",
        "\n",
        "        idx_max_sim = np.argmax(similitudes_pares)\n",
        "        idx_min_sim = np.argmin(similitudes_pares)\n",
        "\n",
        "        par_mas_similar_indices = (mask_triu[0][idx_max_sim], mask_triu[1][idx_max_sim])\n",
        "        par_menos_similar_indices = (mask_triu[0][idx_min_sim], mask_triu[1][idx_min_sim])\n",
        "\n",
        "        print(f\"\\n  PAR MAS SIMILAR (Similitud: {similitudes_pares[idx_max_sim]:.3f}):\")\n",
        "        print(f\"     -> T{par_mas_similar_indices[0]+1}: \\\"{textos[par_mas_similar_indices[0]][:50]}...\\\"\")\n",
        "        print(f\"     -> T{par_mas_similar_indices[1]+1}: \\\"{textos[par_mas_similar_indices[1]][:50]}...\\\"\")\n",
        "\n",
        "        print(f\"\\n  PAR MENOS SIMILAR (Similitud: {similitudes_pares[idx_min_sim]:.3f}):\")\n",
        "        print(f\"     -> T{par_menos_similar_indices[0]+1}: \\\"{textos[par_menos_similar_indices[0]][:50]}...\\\"\")\n",
        "        print(f\"     -> T{par_menos_similar_indices[1]+1}: \\\"{textos[par_menos_similar_indices[1]][:50]}...\\\"\")\n",
        "    else:\n",
        "        print(\"\\n  Informacion: No hay suficientes pares unicos para estadisticas detalladas de similitud.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 4. INTERFAZ INTERACTIVA CON WIDGETS\n",
        "# ==================================================================================\n",
        "\n",
        "if WIDGETS_AVAILABLE:\n",
        "    analizador_widgets = AnalizadorEmbeddingsOptimizado()\n",
        "\n",
        "    estado_widgets = {\n",
        "        \"embeddings_matriz\": None,\n",
        "        \"textos_procesados\": None,\n",
        "        \"similitudes\": None\n",
        "    }\n",
        "\n",
        "    estilo_css_widgets = \"\"\"\n",
        "    <style>\n",
        "        .widget-container { margin-bottom: 10px; }\n",
        "        .widget-label { font-weight: bold; margin-right: 5px; min-width: 80px !important; }\n",
        "        .widget-button { margin: 5px; }\n",
        "        .output-area-title {\n",
        "            font-size: 1.3em; font-weight: bold; color: #2c3e50;\n",
        "            padding: 10px; background-color: #ecf0f1; border-radius: 5px;\n",
        "            margin-top: 15px; margin-bottom: 10px; text-align: center;\n",
        "        }\n",
        "        .info-block {\n",
        "            background-color: #e8f4fd; border-left: 5px solid #3498db;\n",
        "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #2980b9;\n",
        "        }\n",
        "        .success-block {\n",
        "            background-color: #e6ffed; border-left: 5px solid #2ecc71;\n",
        "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #27ae60;\n",
        "        }\n",
        "        .warning-block {\n",
        "            background-color: #fff9e6; border-left: 5px solid #f39c12;\n",
        "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #d35400;\n",
        "        }\n",
        "        .error-block {\n",
        "            background-color: #ffe6e6; border-left: 5px solid #e74c3c;\n",
        "            padding: 15px; margin: 10px 0; border-radius: 4px; color: #c0392b;\n",
        "        }\n",
        "        .embedding-lab-header {\n",
        "            background: linear-gradient(135deg, #5D9CEC 0%, #5A00A5 100%);\n",
        "            color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; text-align: center;\n",
        "            box-shadow: 0 5px 15px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        .embedding-lab-header h2 { margin-top: 0; font-size: 24px; }\n",
        "        .embedding-lab-header p { font-size: 16px; opacity: 0.9; }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    display(HTML(estilo_css_widgets))\n",
        "\n",
        "    display(HTML(\"\"\"\n",
        "    <div class=\"embedding-lab-header\">\n",
        "        <h2>LABORATORIO DE EMBEDDINGS Y ESPACIO LATENTE</h2>\n",
        "        <p>Explora como los Modelos de Lenguaje representan el significado del texto.</p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    entrada_textos_widget = widgets.Textarea(\n",
        "        value='''Inteligencia artificial y machine learning son campos fascinantes.\n",
        "Los gatos y los perros son animales domesticos populares.\n",
        "Python se utiliza ampliamente en ciencia de datos y desarrollo web.\n",
        "Los modelos de lenguaje grande estan transformando el procesamiento del lenguaje natural.\n",
        "Las matematicas y la estadistica son fundamentales para el aprendizaje automatico.\n",
        "La visualizacion de datos ayuda a comprender patrones complejos.''',\n",
        "        placeholder='Ingresa textos, uno por linea...',\n",
        "        description='',\n",
        "        layout=widgets.Layout(width='98%', height='150px')\n",
        "    )\n",
        "\n",
        "    config_reduccion_widget = widgets.Dropdown(\n",
        "        options=[('PCA (Rapido)', 'pca'), ('t-SNE (Detallado)', 'tsne')],\n",
        "        value='pca', description='Reduccion:', style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    config_clusters_widget = widgets.IntSlider(\n",
        "        value=3, min=1, max=5, step=1, description='Num. Clusters:',\n",
        "        style={'description_width': 'initial'}, continuous_update=False\n",
        "    )\n",
        "\n",
        "    boton_analizar_widget = widgets.Button(description='Analizar Textos', button_style='primary', layout=widgets.Layout(width='auto'))\n",
        "    boton_visualizar_espacio_widget = widgets.Button(description='Ver Espacio Latente', button_style='success', layout=widgets.Layout(width='auto'), disabled=True)\n",
        "    boton_matriz_similitudes_widget = widgets.Button(description='Ver Matriz Similitudes', button_style='info', layout=widgets.Layout(width='auto'), disabled=True)\n",
        "\n",
        "    input_section = widgets.VBox([\n",
        "        widgets.HTML(\"<h3 style='color:#34495e; margin-bottom:5px;'>Ingresa tus Textos:</h3>\"),\n",
        "        entrada_textos_widget\n",
        "    ])\n",
        "\n",
        "    config_section = widgets.VBox([\n",
        "         widgets.HTML(\"<h3 style='color:#34495e; margin-bottom:5px; margin-top:15px;'>Configuracion de Analisis:</h3>\"),\n",
        "         widgets.HBox([config_reduccion_widget, config_clusters_widget], layout=widgets.Layout(justify_content='space-between'))\n",
        "    ])\n",
        "\n",
        "    button_section = widgets.HBox(\n",
        "        [boton_analizar_widget, boton_visualizar_espacio_widget, boton_matriz_similitudes_widget],\n",
        "        layout=widgets.Layout(justify_content='space-around', margin='15px 0px')\n",
        "    )\n",
        "\n",
        "    salida_widgets = widgets.Output(layout=widgets.Layout(padding='10px'))\n",
        "\n",
        "    def handle_analizar_textos(button_event):\n",
        "        with salida_widgets:\n",
        "            clear_output(wait=True)\n",
        "            display(HTML(\"<div class='output-area-title'>PROCESANDO ANALISIS</div>\"))\n",
        "\n",
        "            textos_input_raw = entrada_textos_widget.value.strip()\n",
        "            if not textos_input_raw:\n",
        "                display(HTML(\"<div class='warning-block'>Advertencia: Por favor, ingresa al menos un texto para analizar.</div>\"))\n",
        "                boton_visualizar_espacio_widget.disabled = True\n",
        "                boton_matriz_similitudes_widget.disabled = True\n",
        "                return\n",
        "\n",
        "            textos_procesados = [t.strip() for t in textos_input_raw.split('\\n') if t.strip()]\n",
        "            if not textos_procesados:\n",
        "                display(HTML(\"<div class='warning-block'>Advertencia: No se encontraron textos validos despues de limpiar la entrada.</div>\"))\n",
        "                boton_visualizar_espacio_widget.disabled = True\n",
        "                boton_matriz_similitudes_widget.disabled = True\n",
        "                return\n",
        "\n",
        "            MAX_TEXTOS_INTERACTIVOS = 15\n",
        "            if len(textos_procesados) > MAX_TEXTOS_INTERACTIVOS:\n",
        "                textos_procesados = textos_procesados[:MAX_TEXTOS_INTERACTIVOS]\n",
        "                display(HTML(f\"<div class='warning-block'>Advertencia: Se procesaran los primeros {MAX_TEXTOS_INTERACTIVOS} textos para mantener la interactividad.</div>\"))\n",
        "\n",
        "            estado_widgets[\"textos_procesados\"] = textos_procesados\n",
        "\n",
        "            try:\n",
        "                display(HTML(\"<div class='info-block'>Generando embeddings...</div>\"))\n",
        "                embeddings = analizador_widgets.procesar_lote_optimizado(textos_procesados)\n",
        "                if embeddings.size == 0:\n",
        "                    display(HTML(\"<div class='error-block'>Error: No se pudieron generar embeddings. Revisa los textos o el modelo.</div>\"))\n",
        "                    boton_visualizar_espacio_widget.disabled = True\n",
        "                    boton_matriz_similitudes_widget.disabled = True\n",
        "                    return\n",
        "                estado_widgets[\"embeddings_matriz\"] = embeddings\n",
        "\n",
        "                similitudes_calc = None\n",
        "                if len(textos_procesados) >= 2:\n",
        "                    display(HTML(\"<div class='info-block'>Calculando similitudes...</div>\"))\n",
        "                    similitudes_calc = analizador_widgets.calcular_similitudes_optimizado(embeddings)\n",
        "                    estado_widgets[\"similitudes\"] = similitudes_calc\n",
        "                else:\n",
        "                    estado_widgets[\"similitudes\"] = None\n",
        "\n",
        "                clear_output(wait=True)\n",
        "                display(HTML(\"<div class='output-area-title'>ANALISIS COMPLETADO</div>\"))\n",
        "                display(HTML(f\"<div class='success-block'>Se analizaron {len(textos_procesados)} textos. Dimensiones del embedding: {embeddings.shape[1]}.</div>\"))\n",
        "\n",
        "                if similitudes_calc is not None and similitudes_calc.size > 0:\n",
        "                     mostrar_estadisticas_detalladas(embeddings, similitudes_calc, textos_procesados)\n",
        "                elif len(textos_procesados) == 1:\n",
        "                     display(HTML(\"<div class='info-block'>Se analizo 1 texto. Para estadisticas de similitud y visualizaciones comparativas, ingresa al menos 2 textos.</div>\"))\n",
        "\n",
        "                if len(textos_procesados) >= 1:\n",
        "                     boton_visualizar_espacio_widget.disabled = False\n",
        "                if len(textos_procesados) >= 2:\n",
        "                     boton_matriz_similitudes_widget.disabled = False\n",
        "                else:\n",
        "                     boton_matriz_similitudes_widget.disabled = True\n",
        "\n",
        "                max_c = len(textos_procesados) -1 if len(textos_procesados) > 1 else 1\n",
        "                config_clusters_widget.max = max(1, max_c)\n",
        "                if config_clusters_widget.value > config_clusters_widget.max :\n",
        "                    config_clusters_widget.value = config_clusters_widget.max\n",
        "                if len(textos_procesados) < 2:\n",
        "                    config_clusters_widget.disabled = True\n",
        "                else:\n",
        "                    config_clusters_widget.disabled = False\n",
        "\n",
        "            except Exception as e:\n",
        "                clear_output(wait=True)\n",
        "                display(HTML(\"<div class='output-area-title'>ERROR EN EL ANALISIS</div>\"))\n",
        "                display(HTML(f\"<div class='error-block'>Ocurrio un error: {str(e)}</div>\"))\n",
        "                import traceback\n",
        "                salida_widgets.append_stderr(traceback.format_exc())\n",
        "                boton_visualizar_espacio_widget.disabled = True\n",
        "                boton_matriz_similitudes_widget.disabled = True\n",
        "\n",
        "    def handle_visualizar_espacio(button_event):\n",
        "        with salida_widgets:\n",
        "            clear_output(wait=True)\n",
        "            display(HTML(\"<div class='output-area-title'>VISUALIZACION DEL ESPACIO LATENTE</div>\"))\n",
        "\n",
        "            if estado_widgets[\"embeddings_matriz\"] is None or estado_widgets[\"textos_procesados\"] is None:\n",
        "                display(HTML(\"<div class='error-block'>Error: No hay datos de embeddings analizados. Por favor, ejecuta 'Analizar Textos' primero.</div>\"))\n",
        "                return\n",
        "\n",
        "            embeddings_para_reducir = estado_widgets[\"embeddings_matriz\"]\n",
        "            textos_para_mostrar = estado_widgets[\"textos_procesados\"]\n",
        "\n",
        "            if embeddings_para_reducir.shape[0] == 0:\n",
        "                display(HTML(\"<div class='warning-block'>Advertencia: No hay embeddings para visualizar.</div>\"))\n",
        "                return\n",
        "\n",
        "            metodo_reduc = config_reduccion_widget.value\n",
        "            n_clusters_sel = config_clusters_widget.value\n",
        "\n",
        "            try:\n",
        "                display(HTML(f\"<div class='info-block'>Reduciendo dimensionalidad con {metodo_reduc.upper()}...</div>\"))\n",
        "                embeddings_reducidos_vis = analizador_widgets.reducir_dimensionalidad_optimizada(\n",
        "                    embeddings_para_reducir, metodo=metodo_reduc, n_components=2\n",
        "                )\n",
        "                if embeddings_reducidos_vis.size == 0:\n",
        "                    display(HTML(f\"<div class='warning-block'>Advertencia: No se pudo reducir la dimensionalidad. Puede que no haya suficientes datos ({embeddings_para_reducir.shape[0]} textos).</div>\"))\n",
        "                    return\n",
        "\n",
        "                clusters_vis = None\n",
        "                if len(textos_para_mostrar) >= 2 and not config_clusters_widget.disabled:\n",
        "                    display(HTML(f\"<div class='info-block'>Realizando clustering con {n_clusters_sel} clusters...</div>\"))\n",
        "                    clusters_vis, _ = analizador_widgets.clustering_optimizado(embeddings_para_reducir, n_clusters=n_clusters_sel)\n",
        "\n",
        "                clear_output(wait=True)\n",
        "                display(HTML(\"<div class='output-area-title'>VISUALIZACION DEL ESPACIO LATENTE</div>\"))\n",
        "                visualizar_embeddings_matplotlib(\n",
        "                    embeddings_reducidos_vis, textos_para_mostrar, clusters_vis, metodo_reduc.upper()\n",
        "                )\n",
        "\n",
        "                if clusters_vis is not None and len(np.unique(clusters_vis)) > 0:\n",
        "                    display(HTML(\"<h4 style='color:#34495e; margin-top:20px;'>Detalle de Clusters:</h4>\"))\n",
        "                    for cluster_val_uniq in sorted(np.unique(clusters_vis)):\n",
        "                        textos_en_cluster = [\n",
        "                            f\"<li>T{idx+1}: {textos_para_mostrar[idx][:60]}...</li>\"\n",
        "                            for idx, cl_id in enumerate(clusters_vis) if cl_id == cluster_val_uniq\n",
        "                        ]\n",
        "                        display(HTML(f\"\"\"\n",
        "                        <div class='info-block' style='background-color: #f9f9f9; border-left-color: #9b59b6;'>\n",
        "                            <strong>Cluster {cluster_val_uniq + 1}</strong> ({len(textos_en_cluster)} textos):\n",
        "                            <ul style='font-size:0.9em; margin-top:5px;'>{''.join(textos_en_cluster)}</ul>\n",
        "                        </div>\"\"\"))\n",
        "            except Exception as e:\n",
        "                clear_output(wait=True)\n",
        "                display(HTML(\"<div class='output-area-title'>ERROR EN VISUALIZACION</div>\"))\n",
        "                display(HTML(f\"<div class='error-block'>Ocurrio un error: {str(e)}</div>\"))\n",
        "                import traceback\n",
        "                salida_widgets.append_stderr(traceback.format_exc())\n",
        "\n",
        "    def handle_matriz_similitudes(button_event):\n",
        "        with salida_widgets:\n",
        "            clear_output(wait=True)\n",
        "            display(HTML(\"<div class='output-area-title'>MATRIZ DE SIMILITUDES</div>\"))\n",
        "\n",
        "            if estado_widgets[\"similitudes\"] is None or estado_widgets[\"textos_procesados\"] is None or len(estado_widgets[\"textos_procesados\"]) < 2:\n",
        "                display(HTML(\"<div class='error-block'>Error: No hay datos de similitudes o se necesitan al menos 2 textos. Ejecuta 'Analizar Textos' con 2 o mas textos.</div>\"))\n",
        "                return\n",
        "\n",
        "            similitudes_para_mostrar = estado_widgets[\"similitudes\"]\n",
        "            textos_para_mostrar_sim = estado_widgets[\"textos_procesados\"]\n",
        "\n",
        "            try:\n",
        "                visualizar_matriz_similitudes_optimizada(similitudes_para_mostrar, textos_para_mostrar_sim)\n",
        "            except Exception as e:\n",
        "                clear_output(wait=True)\n",
        "                display(HTML(\"<div class='output-area-title'>ERROR EN MATRIZ DE SIMILITUDES</div>\"))\n",
        "                display(HTML(f\"<div class='error-block'>Ocurrio un error: {str(e)}</div>\"))\n",
        "                import traceback\n",
        "                salida_widgets.append_stderr(traceback.format_exc())\n",
        "\n",
        "    boton_analizar_widget.on_click(handle_analizar_textos)\n",
        "    boton_visualizar_espacio_widget.on_click(handle_visualizar_espacio)\n",
        "    boton_matriz_similitudes_widget.on_click(handle_matriz_similitudes)\n",
        "\n",
        "    display(widgets.VBox([input_section, config_section, button_section, salida_widgets]))\n",
        "\n",
        "    with salida_widgets:\n",
        "        clear_output()\n",
        "        display(HTML(\"\"\"\n",
        "        <div class='info-block' style='text-align:center; background-color: #e0f7fa; border-left-color: #00bcd4;'>\n",
        "            <b>Bienvenido/a al Laboratorio de Embeddings!</b><br><br>\n",
        "            1. Ingresa los textos que deseas analizar en el area de arriba.<br>\n",
        "            2. Presiona <b>'Analizar Textos'</b> para generar los embeddings y estadisticas basicas.<br>\n",
        "            3. Usa los botones <b>'Ver Espacio Latente'</b> y <b>'Ver Matriz Similitudes'</b> para explorar los resultados visualmente.\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "# ==================================================================================\n",
        "# 5. EJECUCION PRINCIPAL PARA MODO NO-INTERACTIVO\n",
        "# ==================================================================================\n",
        "def ejecutar_analisis_completo():\n",
        "    \"\"\"Funcion principal que ejecuta todo el analisis de forma optimizada\"\"\"\n",
        "    analizador = AnalizadorEmbeddingsOptimizado()\n",
        "    textos_ejemplo = [\n",
        "        \"Inteligencia artificial y machine learning\",\n",
        "        \"Gatos y perros son mascotas queridas\",\n",
        "        \"Python es un lenguaje de programacion\",\n",
        "        \"Los modelos de lenguaje procesan texto\",\n",
        "        \"Matematicas y estadistica avanzada\",\n",
        "        \"Ciencia de datos y analisis predictivo\"\n",
        "    ]\n",
        "    if len(textos_ejemplo) == 0:\n",
        "        print(\"No hay textos de ejemplo para analizar.\")\n",
        "        return\n",
        "\n",
        "    print(\"INICIANDO ANALISIS DE EMBEDDINGS (MODO NO-INTERACTIVO)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        print(\"\\nPaso 1: Generando Embeddings...\")\n",
        "        embeddings_matriz = analizador.procesar_lote_optimizado(textos_ejemplo)\n",
        "        if embeddings_matriz.size == 0:\n",
        "            print(\"Error: No se pudieron generar embeddings.\")\n",
        "            return None, None, None\n",
        "\n",
        "        similitudes = None\n",
        "        if embeddings_matriz.shape[0] >= 2:\n",
        "            print(\"\\nPaso 2: Calculando Similitudes...\")\n",
        "            similitudes = analizador.calcular_similitudes_optimizado(embeddings_matriz)\n",
        "            if similitudes.size == 0:\n",
        "                print(\"Error: No se pudieron calcular similitudes.\")\n",
        "        else:\n",
        "            print(\"\\nInformacion: Se necesita al menos 2 textos para calcular similitudes.\")\n",
        "\n",
        "        print(\"\\nPaso 3: Mostrando Estadisticas Detalladas...\")\n",
        "        mostrar_estadisticas_detalladas(embeddings_matriz, similitudes if similitudes is not None else np.array([]), textos_ejemplo)\n",
        "\n",
        "        if similitudes is not None and similitudes.size > 0:\n",
        "            print(\"\\nPaso 4: Generando Visualizacion de Matriz de Similitudes...\")\n",
        "            visualizar_matriz_similitudes_optimizada(similitudes, textos_ejemplo)\n",
        "        else:\n",
        "            print(\"\\nInformacion: No se visualiza matriz de similitudes (se necesitan >= 2 textos).\")\n",
        "\n",
        "        print(\"\\nPaso 5: Generando Visualizaciones del Espacio Latente...\")\n",
        "        n_samples = embeddings_matriz.shape[0]\n",
        "        n_clusters_ejemplo = 1\n",
        "        if n_samples >=2:\n",
        "             n_clusters_ejemplo = min(3, n_samples -1)\n",
        "        n_clusters_ejemplo = max(1, n_clusters_ejemplo)\n",
        "\n",
        "        for metodo_reduc in ['pca', 'tsne']:\n",
        "            print(f\"\\n  Aplicando {metodo_reduc.upper()}...\")\n",
        "            if n_samples < 2 and metodo_reduc == 'tsne':\n",
        "                print(f\"     Advertencia: Saltando t-SNE, se necesitan al menos 2 textos.\")\n",
        "                continue\n",
        "            if n_samples == 0:\n",
        "                print(f\"     Advertencia: Saltando {metodo_reduc.upper()}, no hay embeddings.\")\n",
        "                continue\n",
        "\n",
        "            embeddings_reducidos = analizador.reducir_dimensionalidad_optimizada(\n",
        "                embeddings_matriz, metodo=metodo_reduc, n_components=2\n",
        "            )\n",
        "            if embeddings_reducidos.size == 0:\n",
        "                print(f\"     Error: No se pudo reducir la dimensionalidad con {metodo_reduc.upper()}.\")\n",
        "                continue\n",
        "\n",
        "            clusters = None\n",
        "            if n_samples >= n_clusters_ejemplo and n_clusters_ejemplo > 0:\n",
        "                 clusters, _ = analizador.clustering_optimizado(embeddings_matriz, n_clusters=n_clusters_ejemplo)\n",
        "\n",
        "            visualizar_embeddings_matplotlib(\n",
        "                embeddings_reducidos, textos_ejemplo, clusters, metodo_reduc.upper()\n",
        "            )\n",
        "\n",
        "            if clusters is not None:\n",
        "                print(f\"\\n  CLUSTERS IDENTIFICADOS CON {metodo_reduc.upper()}:\")\n",
        "                for i in sorted(np.unique(clusters)):\n",
        "                    textos_cluster = [textos_ejemplo[j] for j, cl_id in enumerate(clusters) if cl_id == i]\n",
        "                    print(f\"     Cluster {i+1}: ({len(textos_cluster)} textos)\")\n",
        "                    for texto_cl in textos_cluster:\n",
        "                        print(f\"        - \\\"{texto_cl[:60]}...\\\"\")\n",
        "            elif n_samples > 0:\n",
        "                print(f\"  Informacion: No se generaron clusters para {metodo_reduc.upper()} (o no se solicitaron).\")\n",
        "\n",
        "        print(\"\\nANALISIS COMPLETADO EXITOSAMENTE (MODO NO-INTERACTIVO)\")\n",
        "        print(\"=\"*70)\n",
        "        return analizador, embeddings_matriz, similitudes\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR DURANTE EL ANALISIS NO-INTERACTIVO: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "if not WIDGETS_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" EJECUTANDO EN MODO NO-INTERACTIVO (SIN WIDGETS) \".center(70, \"=\"))\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    resultados_no_interactivos = ejecutar_analisis_completo()\n",
        "    if resultados_no_interactivos:\n",
        "        print(\"\\nResultados del analisis no interactivo disponibles (analizador, embeddings, similitudes).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6MQXq4dkOBpg",
        "outputId": "6c9e8623-51b0-4fff-dc2c-3e62c3b6b623"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>Temperatura en Modelos de Lenguaje: Ajustando la Creatividad y Aleatoriedad</title>\n",
              "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #1e88e5;\n",
              "  --secondary-color: #00acc1;\n",
              "  --text-color: #37474f;\n",
              "  --bg-color: #f4f6f8;\n",
              "  --container-bg: #ffffff;\n",
              "  --keyword-bg: #e0f7fa;\n",
              "  --keyword-text: #00796b;\n",
              "  --button-bg: #e9ecef;\n",
              "  --button-hover-bg: #ced4da;\n",
              "  --button-text-color: #212529;\n",
              "  --shadow-color: rgba(0,0,0,0.08);\n",
              "  --table-border-color: #dee2e6;\n",
              "  --row-bg-odd: #f8f9fa;\n",
              "  --row-bg-even: #ffffff;\n",
              "  --pre-bg: #e9ecef;\n",
              "  --pre-text: #212529;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #42a5f5;\n",
              "  --secondary-color: #26c6da;\n",
              "  --text-color: #e0e0e0;\n",
              "  --bg-color: #121212;\n",
              "  --container-bg: #1e1e1e;\n",
              "  --keyword-bg: #37474f;\n",
              "  --keyword-text: #80deea;\n",
              "  --button-bg: #343a40;\n",
              "  --button-hover-bg: #495057;\n",
              "  --button-text-color: #f8f9fa;\n",
              "  --shadow-color: rgba(0,0,0,0.5);\n",
              "  --table-border-color: #495057;\n",
              "  --row-bg-odd: #2c3034;\n",
              "  --row-bg-even: #212529;\n",
              "  --pre-bg: #2c3034;\n",
              "  --pre-text: #f8f9fa;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Roboto', 'Arial', sans-serif;\n",
              "  line-height: 1.75;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 20px;\n",
              "  margin: 0;\n",
              "}\n",
              ".container {\n",
              "  max-width: 980px;\n",
              "  margin: 30px auto;\n",
              "  padding: 30px 40px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 12px;\n",
              "  box-shadow: 0 6px 18px var(--shadow-color);\n",
              "  position: relative;\n",
              "  transition: background-color .3s, box-shadow .3s;\n",
              "  border-top: 7px solid var(--primary-color);\n",
              "}\n",
              "h1 {\n",
              "  color: var(--primary-color);\n",
              "  font-size: 2.4em;\n",
              "  margin-bottom: .1em;\n",
              "  line-height: 1.25;\n",
              "  text-align: center;\n",
              "  border-bottom: 2px solid var(--secondary-color);\n",
              "  padding-bottom: 0.3em;\n",
              "}\n",
              "h2 {\n",
              "  color: var(--secondary-color);\n",
              "  text-align: left;\n",
              "  margin-top: 2.3em;\n",
              "  margin-bottom: .8em;\n",
              "  font-size: 1.8em;\n",
              "  border-bottom: 1px solid #ddd;\n",
              "  padding-bottom: 0.2em;\n",
              "}\n",
              "body.dark-mode h2 {\n",
              "    border-bottom: 1px solid #444;\n",
              "}\n",
              ".subtitle-style {\n",
              "  font-style:italic;\n",
              "  font-weight:400;\n",
              "  color: var(--text-color);\n",
              "  opacity: 0.85;\n",
              "  text-align:center;\n",
              "  margin-top:0.2em;\n",
              "  margin-bottom: 1.8em;\n",
              "  font-size: 1.15em;\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.2em 0.4em;\n",
              "  border-radius: 5px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--button-bg);\n",
              "  color: var(--button-text-color);\n",
              "  border: 1.5px solid var(--secondary-color);\n",
              "  padding: 9px 14px;\n",
              "  border-radius: 6px;\n",
              "  cursor: pointer;\n",
              "  position: fixed;\n",
              "  top: 20px;\n",
              "  right: 25px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
              "  z-index: 1000;\n",
              "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--button-hover-bg);\n",
              "    transform: translateY(-1px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 3px solid var(--primary-color);\n",
              "    outline-offset: 2px;\n",
              "    border-color: var(--primary-color);\n",
              "}\n",
              "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
              "ol li, ul li { margin-bottom:0.7em; } \n",
              "p { margin-bottom: 1.3em; } \n",
              "b { color: var(--primary-color); font-weight: 600;}\n",
              "table {\n",
              "    font-size:0.95em;\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    width: 100%; \n",
              "    border-collapse: collapse; \n",
              "    margin: 1.5em 0; \n",
              "}\n",
              "table th, table td {\n",
              "    padding:10px 12px !important; \n",
              "    border:1px solid var(--table-border-color) !important;\n",
              "    text-align: left;\n",
              "    vertical-align: top;\n",
              "}\n",
              "table th { font-weight: 600; background-color: var(--row-bg-odd); }\n",
              "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
              "\n",
              "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
              "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
              "\n",
              "pre {\n",
              "    background: var(--pre-bg);\n",
              "    color: var(--pre-text);\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    border-radius: 8px;\n",
              "    padding: 12px 16px;\n",
              "    font-size: 0.9em;\n",
              "    line-height: 1.6;\n",
              "    overflow-x: auto;\n",
              "    margin: 1.2em 0;\n",
              "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
              "}\n",
              "code.language-python, code.nohighlight { \n",
              "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
              "<div class=\"container\">\n",
              "    <h1><strong class=\"keyword\">Temperatura</strong> en Modelos de Lenguaje: Ajustando la <strong class=\"keyword\">Creatividad</strong> y <strong class=\"keyword\">Aleatoriedad</strong></h1><p class='subtitle-style'>Una guía profunda sobre cómo este <strong class=\"keyword\">parámetro</strong> moldea la <strong class=\"keyword\">generación de texto</strong> en modelos como <strong class=\"keyword\">GPT</strong></p><div style='margin-top: 1.5em;'>\n",
              "Cuando interactuamos con un <b><strong class=\"keyword\">modelo de lenguaje</strong></b> generativo como <b><strong class=\"keyword\">GPT</strong></b>, uno de los <b>parámetros</b> más influyentes que podemos ajustar para controlar la naturaleza de su <b><strong class=\"keyword\">respuesta</strong></b> es la <b><strong class=\"keyword\">temperatura</strong></b>. Este <b><strong class=\"keyword\">parámetro</strong></b> modula el nivel de <b><strong class=\"keyword\">aleatoriedad</strong></b> (o carácter <b><strong class=\"keyword\">estocástico</strong></b>) en el proceso de <b><strong class=\"keyword\">selección</strong></b> del siguiente <b><strong class=\"keyword\">token</strong></b> durante la <b><strong class=\"keyword\">generación de texto</strong></b>. Entender la <b><strong class=\"keyword\">temperatura</strong></b> es clave para afinar la <b><strong class=\"keyword\">creatividad</strong></b>, <b><strong class=\"keyword\">coherencia</strong></b> y <b><strong class=\"keyword\">diversidad</strong></b> de las salidas del modelo.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>¿Por Qué es Necesaria la <strong class=\"keyword\">Temperatura</strong>? El Proceso de <strong class=\"keyword\">Selección</strong> de <strong class=\"keyword\">Tokens</strong></h2>\n",
              "Un <b><strong class=\"keyword\">modelo de lenguaje</strong></b>, en cada paso de la <b><strong class=\"keyword\">generación de texto</strong></b>, no elige simplemente la palabra \"más obvia\". El proceso es más matizado:\n",
              "<ol>\n",
              "    <li><b>Cálculo de <strong class=\"keyword\">Logits</strong>:</b> Dada una secuencia de <b><strong class=\"keyword\">tokens</strong></b> de <b><strong class=\"keyword\">contexto</strong></b>, el modelo calcula una puntuación (un <b>logit</b>) para cada <b><strong class=\"keyword\">token</strong></b> posible en su vocabulario, indicando cuán probable considera que cada uno sea el siguiente. Los <b><strong class=\"keyword\">logits</strong></b> son valores numéricos brutos, no normalizados.</li>\n",
              "    <li><b>Aplicación de la <strong class=\"keyword\">Temperatura</strong> (Re-escalado de <strong class=\"keyword\">Logits</strong>):</b> Aquí es donde interviene la <b><strong class=\"keyword\">temperatura</strong></b> (T). Los <b><strong class=\"keyword\">logits</strong></b> originales se dividen por el valor de la <b><strong class=\"keyword\">temperatura</strong></b>: <code>nuevos_logits = <strong class=\"keyword\">logits</strong> / T</code>.\n",
              "        <ul>\n",
              "            <li>Si T=1, los <b><strong class=\"keyword\">logits</strong></b> no cambian.</li>\n",
              "            <li>Si T < 1 (ej. 0.5), las diferencias entre los <b><strong class=\"keyword\">logits</strong></b> se magnifican. Los <b><strong class=\"keyword\">logits</strong></b> altos se vuelven aún más altos en relación con los bajos.</li>\n",
              "            <li>Si T > 1 (ej. 1.5), las diferencias entre los <b><strong class=\"keyword\">logits</strong></b> se suavizan o \"aplanan\".</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Conversión a Probabilidades (<strong class=\"keyword\">Softmax</strong>):</b> Los <code>nuevos_logits</code> (re-escalados por la <b><strong class=\"keyword\">temperatura</strong></b>) se pasan a través de una función <b><strong class=\"keyword\">softmax</strong></b>. Esta función convierte los <b><strong class=\"keyword\">logits</strong></b> en una <b><strong class=\"keyword\">distribución de probabilidad</strong></b>, donde cada <b><strong class=\"keyword\">token</strong></b> del vocabulario tiene una <b><strong class=\"keyword\">probabilidad</strong></b> entre 0 y 1, y la suma de todas las probabilidades es 1.</li>\n",
              "    <li><b><strong class=\"keyword\">Muestreo</strong> (Sampling):</b> Finalmente, el siguiente <b><strong class=\"keyword\">token</strong></b> se selecciona (se \"muestrea\") de esta <b><strong class=\"keyword\">distribución de probabilidad</strong></b> modificada. No siempre se elige el <b><strong class=\"keyword\">token</strong></b> con la <b><strong class=\"keyword\">probabilidad</strong></b> más alta (a menos que se use <b><strong class=\"keyword\">greedy search</strong></b>).</li>\n",
              "</ol>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b>, al modificar los <b><strong class=\"keyword\">logits</strong></b> antes del <b><strong class=\"keyword\">softmax</strong></b>, nos permite influir en la forma de esta <b><strong class=\"keyword\">distribución de probabilidad</strong></b> final, y por ende, en cuán predecible o sorprendente será la <b><strong class=\"keyword\">selección</strong></b> del siguiente <b><strong class=\"keyword\">token</strong></b>.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>¿Cómo Afecta la <strong class=\"keyword\">Temperatura</strong> a la <strong class=\"keyword\">Distribución de Probabilidad</strong>?</h2>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b> (T) es un valor numérico, típicamente en el rango de 0.0 a 2.0 (aunque algunos sistemas pueden permitir rangos más amplios).\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Temperatura</strong> Baja (ej., T = 0.2 a 0.7):</b>\n",
              "        <ul>\n",
              "            <li><b>Efecto en <strong class=\"keyword\">Logits</strong>:</b> Al dividir los <b><strong class=\"keyword\">logits</strong></b> por un número pequeño (T < 1), las diferencias entre ellos se acentúan. Los <b><strong class=\"keyword\">tokens</strong></b> que ya eran probables (<b><strong class=\"keyword\">logits</strong></b> altos) se vuelven mucho más dominantes en la <b><strong class=\"keyword\">distribución de probabilidad</strong></b> después del <b><strong class=\"keyword\">softmax</strong></b>.</li>\n",
              "            <li><b>Comportamiento del Modelo:</b> El modelo se vuelve más <b><strong class=\"keyword\">determinista</strong></b> y conservador. Tiende a elegir los <b><strong class=\"keyword\">tokens</strong></b> más probables y predecibles según el <b><strong class=\"keyword\">contexto</strong></b>.</li>\n",
              "            <li><b>Resultado:</b> La <b><strong class=\"keyword\">respuesta</strong></b> es más enfocada, coherente y factual, pero puede carecer de <b><strong class=\"keyword\">creatividad</strong></b>, volverse repetitiva o sonar genérica.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b><strong class=\"keyword\">Temperatura</strong> Moderada (ej., T ≈ 0.7 a 1.0):</b>\n",
              "        <ul>\n",
              "            <li><b>Efecto en <strong class=\"keyword\">Logits</strong>:</b> T=1 significa que los <b><strong class=\"keyword\">logits</strong></b> originales se usan directamente para el <b><strong class=\"keyword\">softmax</strong></b> (o un valor cercano a 1 ofrece un buen equilibrio).</li>\n",
              "            <li><b>Comportamiento del Modelo:</b> Ofrece un balance entre <b><strong class=\"keyword\">coherencia</strong></b> y <b><strong class=\"keyword\">creatividad</strong></b>. El modelo puede generar <b>respuestas</b> interesantes sin desviarse demasiado.</li>\n",
              "            <li><b>Resultado:</b> A menudo es un buen punto de partida para muchas tareas.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b><strong class=\"keyword\">Temperatura</strong> Alta (ej., T = 1.1 a 2.0):</b>\n",
              "        <ul>\n",
              "            <li><b>Efecto en <strong class=\"keyword\">Logits</strong>:</b> Al dividir los <b><strong class=\"keyword\">logits</strong></b> por un número grande (T > 1), las diferencias entre ellos se reducen, aplanando la <b><strong class=\"keyword\">distribución de probabilidad</strong></b> después del <b><strong class=\"keyword\">softmax</strong></b>. Esto significa que <b><strong class=\"keyword\">tokens</strong></b> menos probables (con <b><strong class=\"keyword\">logits</strong></b> originalmente más bajos) ahora tienen una <b><strong class=\"keyword\">probabilidad</strong></b> más comparable a los <b><strong class=\"keyword\">tokens</strong></b> más probables.</li>\n",
              "            <li><b>Comportamiento del Modelo:</b> El modelo se vuelve más <b><strong class=\"keyword\">estocástico</strong></b>, experimental y \"atrevido\". Es más propenso a seleccionar <b><strong class=\"keyword\">tokens</strong></b> inesperados o menos comunes.</li>\n",
              "            <li><b>Resultado:</b> La <b><strong class=\"keyword\">respuesta</strong></b> puede ser más diversa, original, sorprendente y <b>creativa</b>. Sin embargo, también aumenta el riesgo de generar texto inconexo, sin sentido, con errores factuales o \"<b><strong class=\"keyword\">alucinaciones</strong></b>\".</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Casos Extremos:</b>\n",
              "        <ul>\n",
              "            <li><b>T → 0 (<strong class=\"keyword\">Temperatura</strong> muy cercana a cero):</b> La <b><strong class=\"keyword\">distribución de probabilidad</strong></b> se vuelve extremadamente puntiaguda, concentrando casi toda la masa de <b><strong class=\"keyword\">probabilidad</strong></b> en el <b><strong class=\"keyword\">token</strong></b> con el <b>logit</b> más alto. Esto se aproxima al <b><strong class=\"keyword\">muestreo</strong></b> <b><strong class=\"keyword\">greedy search</strong></b> (elegir siempre el más probable), resultando en una <b><strong class=\"keyword\">generación de texto</strong></b> muy <b><strong class=\"keyword\">determinista</strong></b>.</li>\n",
              "            <li><b>T → ∞ (<strong class=\"keyword\">Temperatura</strong> muy alta):</b> La <b><strong class=\"keyword\">distribución de probabilidad</strong></b> se vuelve casi uniforme sobre todos los <b><strong class=\"keyword\">tokens</strong></b> del vocabulario, lo que significa que el modelo elige <b><strong class=\"keyword\">tokens</strong></b> de manera casi completamente aleatoria, produciendo galimatías.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "</ul>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Ejemplo Ilustrativo del Efecto de la <strong class=\"keyword\">Temperatura</strong></h2>\n",
              "Supongamos que, para completar la frase \"El cielo es de color...\", el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> internamente calcula los siguientes <b><strong class=\"keyword\">logits</strong></b> (puntuaciones brutas) para algunos <b><strong class=\"keyword\">tokens</strong></b> candidatos:\n",
              "<table style=\"border-collapse:collapse;width:auto;margin:1em auto;\">\n",
              "<tr style=\"background:#f0f0f0;\"><th style=\"padding:8px;border:1px solid #ccc;\"><strong class=\"keyword\">Token</strong> Candidato</th><th style=\"padding:8px;border:1px solid #ccc;\">Logit Original</th></tr>\n",
              "<tr><td style=\"padding:8px;border:1px solid #ccc;\">azul</td><td style=\"padding:8px;border:1px solid #ccc;\">3.0</td></tr>\n",
              "<tr><td style=\"padding:8px;border:1px solid #ccc;\">gris</td><td style=\"padding:8px;border:1px solid #ccc;\">1.5</td></tr>\n",
              "<tr><td style=\"padding:8px;border:1px solid #ccc;\">rojo</td><td style=\"padding:8px;border:1px solid #ccc;\">0.5</td></tr>\n",
              "<tr><td style=\"padding:8px;border:1px solid #ccc;\">misterioso</td><td style=\"padding:8px;border:1px solid #ccc;\">-1.0</td></tr>\n",
              "</table>\n",
              "\n",
              "<p><b>Caso 1: <strong class=\"keyword\">Temperatura</strong> Baja (T = 0.5)</b></p>\n",
              "Nuevos <strong class=\"keyword\">Logits</strong> = <strong class=\"keyword\">Logits</strong> Originales / 0.5:\n",
              "<ul>\n",
              "    <li>azul: 3.0 / 0.5 = 6.0</li>\n",
              "    <li>gris: 1.5 / 0.5 = 3.0</li>\n",
              "    <li>rojo: 0.5 / 0.5 = 1.0</li>\n",
              "    <li>misterioso: -1.0 / 0.5 = -2.0</li>\n",
              "</ul>\n",
              "Después de aplicar <b><strong class=\"keyword\">softmax</strong></b> a estos nuevos <b><strong class=\"keyword\">logits</strong></b>, la <b><strong class=\"keyword\">probabilidad</strong></b> de \"azul\" será abrumadoramente alta. El modelo casi siempre elegirá \"azul\".<br>\n",
              "<i>Resultado probable: \"El cielo es de color azul.\"</i>\n",
              "\n",
              "<p><b>Caso 2: <strong class=\"keyword\">Temperatura</strong> Alta (T = 1.5)</b></p>\n",
              "Nuevos <strong class=\"keyword\">Logits</strong> = <strong class=\"keyword\">Logits</strong> Originales / 1.5:\n",
              "<ul>\n",
              "    <li>azul: 3.0 / 1.5 = 2.0</li>\n",
              "    <li>gris: 1.5 / 1.5 = 1.0</li>\n",
              "    <li>rojo: 0.5 / 1.5 ≈ 0.33</li>\n",
              "    <li>misterioso: -1.0 / 1.5 ≈ -0.67</li>\n",
              "</ul>\n",
              "Después de aplicar <b><strong class=\"keyword\">softmax</strong></b>, las probabilidades estarán más distribuidas. \"azul\" sigue siendo el más probable, pero \"gris\", \"rojo\" e incluso \"misterioso\" tendrán una oportunidad no despreciable de ser seleccionados durante el <b><strong class=\"keyword\">muestreo</strong></b>.<br>\n",
              "<i>Resultados posibles: \"El cielo es de color gris.\", \"El cielo es de color rojo.\" (quizás al atardecer), o incluso la más <b>creativa</b> \"El cielo es de color misterioso.\"</i>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2><strong class=\"keyword\">Temperatura</strong> y el Dilema <strong class=\"keyword\">Exploración</strong> vs. <strong class=\"keyword\">Explotación</strong></h2>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b> es una forma directa de controlar el balance entre dos comportamientos fundamentales en la toma de decisiones y el aprendizaje:\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Explotación</strong> (Baja <strong class=\"keyword\">Temperatura</strong>):</b> El <b><strong class=\"keyword\">modelo de lenguaje</strong></b> \"explota\" su conocimiento actual, eligiendo las opciones que considera más seguras y probables según lo aprendido durante el <b>preentrenamiento</b> y el <b><strong class=\"keyword\">contexto</strong></b> actual. Se enfoca en la <b><strong class=\"keyword\">coherencia</strong></b> y la precisión.</li>\n",
              "    <li><b><strong class=\"keyword\">Exploración</strong> (Alta <strong class=\"keyword\">Temperatura</strong>):</b> El <b><strong class=\"keyword\">modelo de lenguaje</strong></b> \"explora\" el espacio de posibles <b>respuestas</b>, atreviéndose a probar alternativas menos convencionales, más novedosas o incluso arriesgadas. Se enfoca en la <b><strong class=\"keyword\">diversidad</strong></b> y la <b><strong class=\"keyword\">creatividad</strong></b>.</li>\n",
              "</ul>\n",
              "No hay un ajuste universalmente \"correcto\"; la elección depende del objetivo de la <b><strong class=\"keyword\">generación de texto</strong></b>.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>¿Cuándo Usar Qué <strong class=\"keyword\">Temperatura</strong>? Guía Práctica</h2>\n",
              "<ul>\n",
              "    <li><b>Temperaturas Bajas (0.1 - 0.6):</b>\n",
              "        <ul>\n",
              "            <li><b>Casos de Uso:</b> <strong class=\"keyword\">Respuesta</strong> a preguntas basadas en hechos, resumen de textos, extracción de información, generación de código, explicaciones técnicas, tareas que requieren alta precisión y facticidad.</li>\n",
              "            <li><b>Objetivo:</b> Minimizar <b><strong class=\"keyword\">alucinaciones</strong></b>, mantener la <b><strong class=\"keyword\">coherencia</strong></b>, producir <b>respuestas</b> predecibles y fiables.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Temperaturas Medias (0.7 - 1.0):</b>\n",
              "        <ul>\n",
              "            <li><b>Casos de Uso:</b> Escritura general, lluvia de ideas controlada, chatbots conversacionales equilibrados, redacción de correos electrónicos o borradores de documentos.</li>\n",
              "            <li><b>Objetivo:</b> Un buen equilibrio entre <b><strong class=\"keyword\">creatividad</strong></b> y <b><strong class=\"keyword\">coherencia</strong></b>. Las <b>respuestas</b> son interesantes pero generalmente se mantienen en el tema. <b>OpenAI</b> suele usar un valor por defecto alrededor de 0.7 para muchos de sus modelos <b><strong class=\"keyword\">GPT</strong></b>.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "    <li><b>Temperaturas Altas (1.1 - 2.0):</b>\n",
              "        <ul>\n",
              "            <li><b>Casos de Uso:</b> Escritura creativa (poesía, ficción, guiones), generación de ideas diversas, brainstorming sin restricciones, creación de personajes o historias, arte generativo.</li>\n",
              "            <li><b>Objetivo:</b> Maximizar la <b><strong class=\"keyword\">diversidad</strong></b>, la sorpresa y la originalidad. Se acepta un mayor riesgo de incoherencias o salidas extrañas a cambio de potencial novedad.</li>\n",
              "        </ul>\n",
              "    </li>\n",
              "</ul>\n",
              "Es crucial experimentar con diferentes valores de <b><strong class=\"keyword\">temperatura</strong></b> para una tarea y <b><strong class=\"keyword\">modelo de lenguaje</strong></b> específicos, ya que la percepción de \"<strong class=\"keyword\">creatividad</strong>\" o \"<strong class=\"keyword\">coherencia</strong>\" puede variar.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Relación con Otras Técnicas de <strong class=\"keyword\">Muestreo</strong> (<strong class=\"keyword\">Top-K</strong>, <strong class=\"keyword\">Top-P</strong>)</h2>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b> no es el único <b><strong class=\"keyword\">parámetro</strong></b> que controla la <b><strong class=\"keyword\">selección</strong></b> de <b><strong class=\"keyword\">tokens</strong></b>. A menudo se usa en conjunto con otras estrategias de <b><strong class=\"keyword\">muestreo</strong></b>:\n",
              "<ul>\n",
              "    <li><b><strong class=\"keyword\">Greedy Search</strong> (Búsqueda Voraz):</b> Simplemente elige el <b><strong class=\"keyword\">token</strong></b> con la <b><strong class=\"keyword\">probabilidad</strong></b> más alta en cada paso. Es <b><strong class=\"keyword\">determinista</strong></b> y equivale a usar una <b><strong class=\"keyword\">temperatura</strong></b> muy cercana a cero. Puede llevar a <b>respuestas</b> repetitivas.</li>\n",
              "    <li><b><strong class=\"keyword\">Top-K</strong> Sampling:</b> En cada paso, el modelo considera solo los K <b><strong class=\"keyword\">tokens</strong></b> más probables de la <b><strong class=\"keyword\">distribución de probabilidad</strong></b> (después de aplicar <b><strong class=\"keyword\">temperatura</strong></b> y <b><strong class=\"keyword\">softmax</strong></b>). Luego, muestrea de este subconjunto truncado. Ayuda a evitar <b><strong class=\"keyword\">tokens</strong></b> muy improbables y extraños.</li>\n",
              "    <li><b><strong class=\"keyword\">Top-P</strong> Sampling (<strong class=\"keyword\">Nucleus Sampling</strong>):</b> Considera el conjunto más pequeño de <b><strong class=\"keyword\">tokens</strong></b> cuya <b><strong class=\"keyword\">probabilidad</strong></b> acumulada supera un umbral P (el \"núcleo\"). Por ejemplo, si P=0.9, se consideran los <b><strong class=\"keyword\">tokens</strong></b> más probables hasta que su suma de probabilidades alcance el 90%. El tamaño de este conjunto de candidatos es dinámico. Es muy efectivo para equilibrar <b><strong class=\"keyword\">diversidad</strong></b> y <b><strong class=\"keyword\">coherencia</strong></b>.</li>\n",
              "</ul>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b> ajusta la \"forma\" de la <b><strong class=\"keyword\">distribución de probabilidad</strong></b> inicial. Luego, <b><strong class=\"keyword\">Top-K</strong></b> o <b><strong class=\"keyword\">Top-P</strong></b> pueden filtrar aún más los candidatos antes del <b><strong class=\"keyword\">muestreo</strong></b> final. Es común usar <b><strong class=\"keyword\">temperatura</strong></b> junto con <b><strong class=\"keyword\">Top-P</strong></b>.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Consideraciones y Advertencias al Usar la <strong class=\"keyword\">Temperatura</strong></h2>\n",
              "<ul>\n",
              "    <li><b>No Mejora el Conocimiento:</b> La <b><strong class=\"keyword\">temperatura</strong></b> no hace que el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> \"sepa\" más o sea más inteligente. Simplemente altera cómo elige entre las opciones que ya considera plausibles según su entrenamiento.</li>\n",
              "    <li><b>Riesgo de <strong class=\"keyword\">Alucinaciones</strong>:</b> Temperaturas muy altas pueden llevar al modelo a generar información incorrecta, sin sentido o completamente inventada (<b><strong class=\"keyword\">alucinaciones</strong></b>) con gran confianza.</li>\n",
              "    <li><b>Dependencia del Modelo y la Tarea:</b> El efecto de un valor de <b><strong class=\"keyword\">temperatura</strong></b> específico puede variar entre diferentes <b>modelos de lenguaje</b> y según la naturaleza de la tarea de <b><strong class=\"keyword\">generación de texto</strong></b>.</li>\n",
              "    <li><b>Interacción con el Prompt:</b> La calidad y especificidad del prompt de <b>entrada</b> siguen siendo cruciales. Una <b><strong class=\"keyword\">temperatura</strong></b> alta no compensará un mal prompt.</li>\n",
              "    <li><b>Experimentación Necesaria:</b> La \"mejor\" <b><strong class=\"keyword\">temperatura</strong></b> a menudo se encuentra a través de la experimentación y la evaluación de las salidas para un caso de uso particular.</li>\n",
              "</ul>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Impacto en la Percepción del Modelo</h2>\n",
              "Al ajustar la <b><strong class=\"keyword\">temperatura</strong></b>, podemos cambiar significativamente cómo percibimos la \"personalidad\" o el estilo de un <b><strong class=\"keyword\">modelo de lenguaje</strong></b>:\n",
              "<ul>\n",
              "    <li><b>Baja <strong class=\"keyword\">Temperatura</strong>:</b> Puede parecer más cauteloso, factual, preciso, pero quizás un poco aburrido o robótico.</li>\n",
              "    <li><b>Media <strong class=\"keyword\">Temperatura</strong>:</b> Puede parecer más equilibrado, útil y conversacionalmente natural.</li>\n",
              "    <li><b>Alta <strong class=\"keyword\">Temperatura</strong>:</b> Puede parecer más imaginativo, juguetón, sorprendente, pero también potencialmente errático o poco fiable.</li>\n",
              "</ul>\n",
              "Esta capacidad de ajuste fino es una de las razones por las que los LLMs son herramientas tan versátiles.\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Resumen Clave: <strong class=\"keyword\">Temperatura</strong> en LLMs</h2>\n",
              "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
              "<thead>\n",
              "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Característica</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Efecto de T Baja (↓)</th>\n",
              "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Efecto de T Alta (↑)</th>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Definición</b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Parámetro</strong></b> que controla la <b><strong class=\"keyword\">aleatoriedad</strong></b> en la <b><strong class=\"keyword\">selección</strong></b> de <b><strong class=\"keyword\">tokens</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Más <b><strong class=\"keyword\">determinista</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Más <b><strong class=\"keyword\">estocástico</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Mecanismo</b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Re-escala los <b><strong class=\"keyword\">logits</strong></b> antes de la función <b><strong class=\"keyword\">softmax</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Acentúa diferencias de <b><strong class=\"keyword\">probabilidad</strong></b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Suaviza diferencias de <b><strong class=\"keyword\">probabilidad</strong></b>.</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Coherencia</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Fidelidad al <b><strong class=\"keyword\">contexto</strong></b> y lógica.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Alta.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Baja (riesgo de divagación).</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-odd);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b><strong class=\"keyword\">Creatividad</strong></b> / <b><strong class=\"keyword\">Diversidad</strong></b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Originalidad y variedad de las <b>respuestas</b>.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Baja (<b>respuestas</b> predecibles).</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Alta (<b>respuestas</b> sorprendentes).</td>\n",
              "</tr>\n",
              "<tr style=\"background-color: var(--row-bg-even);\">\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Casos de Uso Típicos</b></td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Aplicaciones recomendadas.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Tareas factuales, resúmenes, código.</td>\n",
              "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Escritura creativa, brainstorming.</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div><div style='margin-top: 1.5em;'>\n",
              "<h2>Conclusión: La <strong class=\"keyword\">Temperatura</strong> como Herramienta Esencial de Ajuste Fino</h2>\n",
              "La <b><strong class=\"keyword\">temperatura</strong></b> es un <b><strong class=\"keyword\">parámetro</strong></b> deceptivamente simple pero increíblemente poderoso para dirigir el comportamiento de los <b>modelos de lenguaje</b> generativos. Al permitirnos navegar el espectro entre la <b><strong class=\"keyword\">explotación</strong></b> del conocimiento aprendido y la <b><strong class=\"keyword\">exploración</strong></b> de nuevas posibilidades, nos da un control significativo sobre el tono, estilo y naturaleza de la <b><strong class=\"keyword\">generación de texto</strong></b>.<br><br>\n",
              "Dominar el uso de la <b><strong class=\"keyword\">temperatura</strong></b>, a menudo en combinación con otras técnicas de <b><strong class=\"keyword\">muestreo</strong></b> como <b><strong class=\"keyword\">Top-P</strong></b> o <b><strong class=\"keyword\">Top-K</strong></b>, es fundamental para adaptar los <b>modelos de lenguaje</b> a tareas específicas y para lograr el delicado equilibrio entre <b><strong class=\"keyword\">coherencia</strong></b> y <b><strong class=\"keyword\">creatividad</strong></b> que define a las aplicaciones de <b>NLP</b> más impactantes. Es una perilla de ajuste fino que, sin modificar los <b>parámetros</b> internos del modelo ni requerir reentrenamiento, transforma la manera en que interactuamos y obtenemos valor de estos sistemas de IA.\n",
              "</div>\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = function() {\n",
              "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    if (!themeToggleButton) {\n",
              "        const button = document.createElement('button');\n",
              "        button.id = \"theme-toggle-btn\";\n",
              "        button.className = \"theme-toggle\";\n",
              "        button.title = \"Cambiar tema de color\";\n",
              "        button.onclick = toggleTheme;\n",
              "        document.body.appendChild(button);\n",
              "        themeToggleButton = button;\n",
              "    }\n",
              "\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let currentThemeIsDark = false;\n",
              "\n",
              "    if (savedTheme === \"dark\") {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    } else if (savedTheme === \"light\") {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        currentThemeIsDark = false;\n",
              "    } else if (prefersDark) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        currentThemeIsDark = true;\n",
              "    }\n",
              "\n",
              "    if (themeToggleButton) {\n",
              "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
              "    }\n",
              "};\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "import re\n",
        "import traceback\n",
        "\n",
        "# 1. Función para resaltar palabras clave (tu versión robusta)\n",
        "def highlight_keywords(text, keywords):\n",
        "    # Ordenar keywords por longitud descendente para evitar coincidencias parciales\n",
        "    keywords_sorted = sorted(keywords, key=len, reverse=True)\n",
        "    parts = []\n",
        "\n",
        "    if not keywords_sorted: return text\n",
        "    keyword_pattern = '|'.join(r'(?<![\\w])(?:' + re.escape(kw) + r')(?![\\w])' for kw in keywords_sorted)\n",
        "\n",
        "    if not keyword_pattern.strip():\n",
        "        return text\n",
        "\n",
        "    pattern = f'({keyword_pattern})'\n",
        "\n",
        "    try:\n",
        "        for match in re.finditer(pattern, text, flags=re.IGNORECASE):\n",
        "            start, end = match.span()\n",
        "            last_open_bracket = text.rfind('<', 0, start)\n",
        "            last_close_bracket = text.rfind('>', 0, start)\n",
        "            if last_open_bracket > last_close_bracket:\n",
        "                continue\n",
        "\n",
        "            in_attribute_value = False\n",
        "            if start > 2:\n",
        "                segment_before_match = text[max(0, start - 30):start] # Ampliar un poco la búsqueda hacia atrás\n",
        "                # Buscar patrones como attr=\" o attr=' o incluso data-kw=\"\n",
        "                # Esta es una heurística. Un parser HTML sería más robusto.\n",
        "                # Simplificamos para no hacerla demasiado compleja aquí.\n",
        "                # Si encontramos un = seguido de comilla antes del match, es una fuerte señal.\n",
        "                if re.search(r'=\\s*(\"|\\')', segment_before_match):\n",
        "                    # Ahora, verificar si el match está realmente DENTRO de esas comillas\n",
        "                    # Esta parte es la más difícil de hacer 100% correcta con regex.\n",
        "                    # Tu lógica original con conteo de comillas es más precisa aquí:\n",
        "                    last_double_quote = text.rfind('\"', 0, start)\n",
        "                    last_single_quote = text.rfind(\"'\", 0, start)\n",
        "                    latest_quote = max(last_double_quote, last_single_quote)\n",
        "\n",
        "                    # Solo considerar si la comilla está después de la última etiqueta cerrada\n",
        "                    # Y antes del inicio del match\n",
        "                    if latest_quote != -1 and latest_quote > last_close_bracket:\n",
        "                        quote_char = '\"' if last_double_quote > last_single_quote else \"'\"\n",
        "                        # Contar comillas del tipo `quote_char` en el segmento desde la última etiqueta cerrada hasta el inicio del match\n",
        "                        segment_for_quote_count = text[last_close_bracket + 1 : start]\n",
        "                        if segment_for_quote_count.count(quote_char) % 2 != 0: # Número impar de comillas -> estamos dentro\n",
        "                            in_attribute_value = True\n",
        "\n",
        "            if in_attribute_value:\n",
        "                continue\n",
        "\n",
        "            parts.append({'start': start, 'end': end, 'text': match.group(1)})\n",
        "\n",
        "    except re.error as e:\n",
        "        print(f\"Advertencia: Error en el patrón regex combinado: {e}\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado en highlight_keywords: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return text\n",
        "\n",
        "    parts.sort(key=lambda x: x['start'])\n",
        "    filtered_parts = []\n",
        "    last_part_end = -1\n",
        "    for part in parts:\n",
        "        if part['start'] >= last_part_end:\n",
        "            filtered_parts.append(part)\n",
        "            last_part_end = part['end']\n",
        "\n",
        "    highlighted_text = \"\"\n",
        "    current_pos = 0\n",
        "    for part in filtered_parts:\n",
        "        highlighted_text += text[current_pos:part['start']]\n",
        "        highlighted_text += f'<strong class=\"keyword\">{part[\"text\"]}</strong>'\n",
        "        current_pos = part['end']\n",
        "    highlighted_text += text[current_pos:]\n",
        "    return highlighted_text\n",
        "\n",
        "\n",
        "# 2. Palabras clave para resaltar\n",
        "keywords_temp = [\n",
        "    \"temperatura\", \"modelo de lenguaje\", \"GPT\", \"aleatoriedad\", \"token\", \"tokens\", \"probabilidad\",\n",
        "    \"distribución de probabilidad\", \"creatividad\", \"explotación\", \"exploración\",\n",
        "    \"top-k\", \"top-p\", \"nucleus sampling\", \"muestreo\", \"coherencia\", \"diversidad\",\n",
        "    \"respuesta\", \"selección\", \"parámetro\", \"contexto\", \"logits\", \"softmax\",\n",
        "    \"greedy search\", \"determinista\", \"estocástico\", \"alucinaciones\", \"generación de texto\"\n",
        "]\n",
        "\n",
        "# 3. Secciones didácticas (expandidas y mejoradas)\n",
        "sections_temp = {\n",
        "    \"title\": \"Temperatura en Modelos de Lenguaje: Ajustando la Creatividad y Aleatoriedad\",\n",
        "    \"subtitle\": \"Una guía profunda sobre cómo este parámetro moldea la generación de texto en modelos como GPT\",\n",
        "    \"intro\": \"\"\"\n",
        "Cuando interactuamos con un <b>modelo de lenguaje</b> generativo como <b>GPT</b>, uno de los <b>parámetros</b> más influyentes que podemos ajustar para controlar la naturaleza de su <b>respuesta</b> es la <b>temperatura</b>. Este <b>parámetro</b> modula el nivel de <b>aleatoriedad</b> (o carácter <b>estocástico</b>) en el proceso de <b>selección</b> del siguiente <b>token</b> durante la <b>generación de texto</b>. Entender la <b>temperatura</b> es clave para afinar la <b>creatividad</b>, <b>coherencia</b> y <b>diversidad</b> de las salidas del modelo.\n",
        "\"\"\",\n",
        "    \"por_que\": \"\"\"\n",
        "<h2>¿Por Qué es Necesaria la Temperatura? El Proceso de Selección de Tokens</h2>\n",
        "Un <b>modelo de lenguaje</b>, en cada paso de la <b>generación de texto</b>, no elige simplemente la palabra \"más obvia\". El proceso es más matizado:\n",
        "<ol>\n",
        "    <li><b>Cálculo de Logits:</b> Dada una secuencia de <b>tokens</b> de <b>contexto</b>, el modelo calcula una puntuación (un <b>logit</b>) para cada <b>token</b> posible en su vocabulario, indicando cuán probable considera que cada uno sea el siguiente. Los <b>logits</b> son valores numéricos brutos, no normalizados.</li>\n",
        "    <li><b>Aplicación de la Temperatura (Re-escalado de Logits):</b> Aquí es donde interviene la <b>temperatura</b> (T). Los <b>logits</b> originales se dividen por el valor de la <b>temperatura</b>: <code>nuevos_logits = logits / T</code>.\n",
        "        <ul>\n",
        "            <li>Si T=1, los <b>logits</b> no cambian.</li>\n",
        "            <li>Si T < 1 (ej. 0.5), las diferencias entre los <b>logits</b> se magnifican. Los <b>logits</b> altos se vuelven aún más altos en relación con los bajos.</li>\n",
        "            <li>Si T > 1 (ej. 1.5), las diferencias entre los <b>logits</b> se suavizan o \"aplanan\".</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Conversión a Probabilidades (Softmax):</b> Los <code>nuevos_logits</code> (re-escalados por la <b>temperatura</b>) se pasan a través de una función <b>softmax</b>. Esta función convierte los <b>logits</b> en una <b>distribución de probabilidad</b>, donde cada <b>token</b> del vocabulario tiene una <b>probabilidad</b> entre 0 y 1, y la suma de todas las probabilidades es 1.</li>\n",
        "    <li><b>Muestreo (Sampling):</b> Finalmente, el siguiente <b>token</b> se selecciona (se \"muestrea\") de esta <b>distribución de probabilidad</b> modificada. No siempre se elige el <b>token</b> con la <b>probabilidad</b> más alta (a menos que se use <b>greedy search</b>).</li>\n",
        "</ol>\n",
        "La <b>temperatura</b>, al modificar los <b>logits</b> antes del <b>softmax</b>, nos permite influir en la forma de esta <b>distribución de probabilidad</b> final, y por ende, en cuán predecible o sorprendente será la <b>selección</b> del siguiente <b>token</b>.\n",
        "\"\"\",\n",
        "    \"como_funciona\": \"\"\"\n",
        "<h2>¿Cómo Afecta la Temperatura a la Distribución de Probabilidad?</h2>\n",
        "La <b>temperatura</b> (T) es un valor numérico, típicamente en el rango de 0.0 a 2.0 (aunque algunos sistemas pueden permitir rangos más amplios).\n",
        "<ul>\n",
        "    <li><b>Temperatura Baja (ej., T = 0.2 a 0.7):</b>\n",
        "        <ul>\n",
        "            <li><b>Efecto en Logits:</b> Al dividir los <b>logits</b> por un número pequeño (T < 1), las diferencias entre ellos se acentúan. Los <b>tokens</b> que ya eran probables (<b>logits</b> altos) se vuelven mucho más dominantes en la <b>distribución de probabilidad</b> después del <b>softmax</b>.</li>\n",
        "            <li><b>Comportamiento del Modelo:</b> El modelo se vuelve más <b>determinista</b> y conservador. Tiende a elegir los <b>tokens</b> más probables y predecibles según el <b>contexto</b>.</li>\n",
        "            <li><b>Resultado:</b> La <b>respuesta</b> es más enfocada, coherente y factual, pero puede carecer de <b>creatividad</b>, volverse repetitiva o sonar genérica.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Temperatura Moderada (ej., T ≈ 0.7 a 1.0):</b>\n",
        "        <ul>\n",
        "            <li><b>Efecto en Logits:</b> T=1 significa que los <b>logits</b> originales se usan directamente para el <b>softmax</b> (o un valor cercano a 1 ofrece un buen equilibrio).</li>\n",
        "            <li><b>Comportamiento del Modelo:</b> Ofrece un balance entre <b>coherencia</b> y <b>creatividad</b>. El modelo puede generar <b>respuestas</b> interesantes sin desviarse demasiado.</li>\n",
        "            <li><b>Resultado:</b> A menudo es un buen punto de partida para muchas tareas.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Temperatura Alta (ej., T = 1.1 a 2.0):</b>\n",
        "        <ul>\n",
        "            <li><b>Efecto en Logits:</b> Al dividir los <b>logits</b> por un número grande (T > 1), las diferencias entre ellos se reducen, aplanando la <b>distribución de probabilidad</b> después del <b>softmax</b>. Esto significa que <b>tokens</b> menos probables (con <b>logits</b> originalmente más bajos) ahora tienen una <b>probabilidad</b> más comparable a los <b>tokens</b> más probables.</li>\n",
        "            <li><b>Comportamiento del Modelo:</b> El modelo se vuelve más <b>estocástico</b>, experimental y \"atrevido\". Es más propenso a seleccionar <b>tokens</b> inesperados o menos comunes.</li>\n",
        "            <li><b>Resultado:</b> La <b>respuesta</b> puede ser más diversa, original, sorprendente y <b>creativa</b>. Sin embargo, también aumenta el riesgo de generar texto inconexo, sin sentido, con errores factuales o \"<b>alucinaciones</b>\".</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Casos Extremos:</b>\n",
        "        <ul>\n",
        "            <li><b>T → 0 (Temperatura muy cercana a cero):</b> La <b>distribución de probabilidad</b> se vuelve extremadamente puntiaguda, concentrando casi toda la masa de <b>probabilidad</b> en el <b>token</b> con el <b>logit</b> más alto. Esto se aproxima al <b>muestreo</b> <b>greedy search</b> (elegir siempre el más probable), resultando en una <b>generación de texto</b> muy <b>determinista</b>.</li>\n",
        "            <li><b>T → ∞ (Temperatura muy alta):</b> La <b>distribución de probabilidad</b> se vuelve casi uniforme sobre todos los <b>tokens</b> del vocabulario, lo que significa que el modelo elige <b>tokens</b> de manera casi completamente aleatoria, produciendo galimatías.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"ejemplo_ilustrativo\": \"\"\"\n",
        "<h2>Ejemplo Ilustrativo del Efecto de la Temperatura</h2>\n",
        "Supongamos que, para completar la frase \"El cielo es de color...\", el <b>modelo de lenguaje</b> internamente calcula los siguientes <b>logits</b> (puntuaciones brutas) para algunos <b>tokens</b> candidatos:\n",
        "<table style=\"border-collapse:collapse;width:auto;margin:1em auto;\">\n",
        "<tr style=\"background:#f0f0f0;\"><th style=\"padding:8px;border:1px solid #ccc;\">Token Candidato</th><th style=\"padding:8px;border:1px solid #ccc;\">Logit Original</th></tr>\n",
        "<tr><td style=\"padding:8px;border:1px solid #ccc;\">azul</td><td style=\"padding:8px;border:1px solid #ccc;\">3.0</td></tr>\n",
        "<tr><td style=\"padding:8px;border:1px solid #ccc;\">gris</td><td style=\"padding:8px;border:1px solid #ccc;\">1.5</td></tr>\n",
        "<tr><td style=\"padding:8px;border:1px solid #ccc;\">rojo</td><td style=\"padding:8px;border:1px solid #ccc;\">0.5</td></tr>\n",
        "<tr><td style=\"padding:8px;border:1px solid #ccc;\">misterioso</td><td style=\"padding:8px;border:1px solid #ccc;\">-1.0</td></tr>\n",
        "</table>\n",
        "\n",
        "<p><b>Caso 1: Temperatura Baja (T = 0.5)</b></p>\n",
        "Nuevos Logits = Logits Originales / 0.5:\n",
        "<ul>\n",
        "    <li>azul: 3.0 / 0.5 = 6.0</li>\n",
        "    <li>gris: 1.5 / 0.5 = 3.0</li>\n",
        "    <li>rojo: 0.5 / 0.5 = 1.0</li>\n",
        "    <li>misterioso: -1.0 / 0.5 = -2.0</li>\n",
        "</ul>\n",
        "Después de aplicar <b>softmax</b> a estos nuevos <b>logits</b>, la <b>probabilidad</b> de \"azul\" será abrumadoramente alta. El modelo casi siempre elegirá \"azul\".<br>\n",
        "<i>Resultado probable: \"El cielo es de color azul.\"</i>\n",
        "\n",
        "<p><b>Caso 2: Temperatura Alta (T = 1.5)</b></p>\n",
        "Nuevos Logits = Logits Originales / 1.5:\n",
        "<ul>\n",
        "    <li>azul: 3.0 / 1.5 = 2.0</li>\n",
        "    <li>gris: 1.5 / 1.5 = 1.0</li>\n",
        "    <li>rojo: 0.5 / 1.5 ≈ 0.33</li>\n",
        "    <li>misterioso: -1.0 / 1.5 ≈ -0.67</li>\n",
        "</ul>\n",
        "Después de aplicar <b>softmax</b>, las probabilidades estarán más distribuidas. \"azul\" sigue siendo el más probable, pero \"gris\", \"rojo\" e incluso \"misterioso\" tendrán una oportunidad no despreciable de ser seleccionados durante el <b>muestreo</b>.<br>\n",
        "<i>Resultados posibles: \"El cielo es de color gris.\", \"El cielo es de color rojo.\" (quizás al atardecer), o incluso la más <b>creativa</b> \"El cielo es de color misterioso.\"</i>\n",
        "\"\"\",\n",
        "    \"exploracion_explotacion\": \"\"\"\n",
        "<h2>Temperatura y el Dilema Exploración vs. Explotación</h2>\n",
        "La <b>temperatura</b> es una forma directa de controlar el balance entre dos comportamientos fundamentales en la toma de decisiones y el aprendizaje:\n",
        "<ul>\n",
        "    <li><b>Explotación (Baja Temperatura):</b> El <b>modelo de lenguaje</b> \"explota\" su conocimiento actual, eligiendo las opciones que considera más seguras y probables según lo aprendido durante el <b>preentrenamiento</b> y el <b>contexto</b> actual. Se enfoca en la <b>coherencia</b> y la precisión.</li>\n",
        "    <li><b>Exploración (Alta Temperatura):</b> El <b>modelo de lenguaje</b> \"explora\" el espacio de posibles <b>respuestas</b>, atreviéndose a probar alternativas menos convencionales, más novedosas o incluso arriesgadas. Se enfoca en la <b>diversidad</b> y la <b>creatividad</b>.</li>\n",
        "</ul>\n",
        "No hay un ajuste universalmente \"correcto\"; la elección depende del objetivo de la <b>generación de texto</b>.\n",
        "\"\"\",\n",
        "    \"cuando_usar\": \"\"\"\n",
        "<h2>¿Cuándo Usar Qué Temperatura? Guía Práctica</h2>\n",
        "<ul>\n",
        "    <li><b>Temperaturas Bajas (0.1 - 0.6):</b>\n",
        "        <ul>\n",
        "            <li><b>Casos de Uso:</b> Respuesta a preguntas basadas en hechos, resumen de textos, extracción de información, generación de código, explicaciones técnicas, tareas que requieren alta precisión y facticidad.</li>\n",
        "            <li><b>Objetivo:</b> Minimizar <b>alucinaciones</b>, mantener la <b>coherencia</b>, producir <b>respuestas</b> predecibles y fiables.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Temperaturas Medias (0.7 - 1.0):</b>\n",
        "        <ul>\n",
        "            <li><b>Casos de Uso:</b> Escritura general, lluvia de ideas controlada, chatbots conversacionales equilibrados, redacción de correos electrónicos o borradores de documentos.</li>\n",
        "            <li><b>Objetivo:</b> Un buen equilibrio entre <b>creatividad</b> y <b>coherencia</b>. Las <b>respuestas</b> son interesantes pero generalmente se mantienen en el tema. <b>OpenAI</b> suele usar un valor por defecto alrededor de 0.7 para muchos de sus modelos <b>GPT</b>.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Temperaturas Altas (1.1 - 2.0):</b>\n",
        "        <ul>\n",
        "            <li><b>Casos de Uso:</b> Escritura creativa (poesía, ficción, guiones), generación de ideas diversas, brainstorming sin restricciones, creación de personajes o historias, arte generativo.</li>\n",
        "            <li><b>Objetivo:</b> Maximizar la <b>diversidad</b>, la sorpresa y la originalidad. Se acepta un mayor riesgo de incoherencias o salidas extrañas a cambio de potencial novedad.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "Es crucial experimentar con diferentes valores de <b>temperatura</b> para una tarea y <b>modelo de lenguaje</b> específicos, ya que la percepción de \"creatividad\" o \"coherencia\" puede variar.\n",
        "\"\"\",\n",
        "    \"otras_tecnicas_muestreo\": \"\"\"\n",
        "<h2>Relación con Otras Técnicas de Muestreo (Top-K, Top-P)</h2>\n",
        "La <b>temperatura</b> no es el único <b>parámetro</b> que controla la <b>selección</b> de <b>tokens</b>. A menudo se usa en conjunto con otras estrategias de <b>muestreo</b>:\n",
        "<ul>\n",
        "    <li><b>Greedy Search (Búsqueda Voraz):</b> Simplemente elige el <b>token</b> con la <b>probabilidad</b> más alta en cada paso. Es <b>determinista</b> y equivale a usar una <b>temperatura</b> muy cercana a cero. Puede llevar a <b>respuestas</b> repetitivas.</li>\n",
        "    <li><b>Top-K Sampling:</b> En cada paso, el modelo considera solo los K <b>tokens</b> más probables de la <b>distribución de probabilidad</b> (después de aplicar <b>temperatura</b> y <b>softmax</b>). Luego, muestrea de este subconjunto truncado. Ayuda a evitar <b>tokens</b> muy improbables y extraños.</li>\n",
        "    <li><b>Top-P Sampling (Nucleus Sampling):</b> Considera el conjunto más pequeño de <b>tokens</b> cuya <b>probabilidad</b> acumulada supera un umbral P (el \"núcleo\"). Por ejemplo, si P=0.9, se consideran los <b>tokens</b> más probables hasta que su suma de probabilidades alcance el 90%. El tamaño de este conjunto de candidatos es dinámico. Es muy efectivo para equilibrar <b>diversidad</b> y <b>coherencia</b>.</li>\n",
        "</ul>\n",
        "La <b>temperatura</b> ajusta la \"forma\" de la <b>distribución de probabilidad</b> inicial. Luego, <b>Top-K</b> o <b>Top-P</b> pueden filtrar aún más los candidatos antes del <b>muestreo</b> final. Es común usar <b>temperatura</b> junto con <b>Top-P</b>.\n",
        "\"\"\",\n",
        "    \"consideraciones_advertencias\": \"\"\"\n",
        "<h2>Consideraciones y Advertencias al Usar la Temperatura</h2>\n",
        "<ul>\n",
        "    <li><b>No Mejora el Conocimiento:</b> La <b>temperatura</b> no hace que el <b>modelo de lenguaje</b> \"sepa\" más o sea más inteligente. Simplemente altera cómo elige entre las opciones que ya considera plausibles según su entrenamiento.</li>\n",
        "    <li><b>Riesgo de Alucinaciones:</b> Temperaturas muy altas pueden llevar al modelo a generar información incorrecta, sin sentido o completamente inventada (<b>alucinaciones</b>) con gran confianza.</li>\n",
        "    <li><b>Dependencia del Modelo y la Tarea:</b> El efecto de un valor de <b>temperatura</b> específico puede variar entre diferentes <b>modelos de lenguaje</b> y según la naturaleza de la tarea de <b>generación de texto</b>.</li>\n",
        "    <li><b>Interacción con el Prompt:</b> La calidad y especificidad del prompt de <b>entrada</b> siguen siendo cruciales. Una <b>temperatura</b> alta no compensará un mal prompt.</li>\n",
        "    <li><b>Experimentación Necesaria:</b> La \"mejor\" <b>temperatura</b> a menudo se encuentra a través de la experimentación y la evaluación de las salidas para un caso de uso particular.</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"impacto_percepcion\": \"\"\"\n",
        "<h2>Impacto en la Percepción del Modelo</h2>\n",
        "Al ajustar la <b>temperatura</b>, podemos cambiar significativamente cómo percibimos la \"personalidad\" o el estilo de un <b>modelo de lenguaje</b>:\n",
        "<ul>\n",
        "    <li><b>Baja Temperatura:</b> Puede parecer más cauteloso, factual, preciso, pero quizás un poco aburrido o robótico.</li>\n",
        "    <li><b>Media Temperatura:</b> Puede parecer más equilibrado, útil y conversacionalmente natural.</li>\n",
        "    <li><b>Alta Temperatura:</b> Puede parecer más imaginativo, juguetón, sorprendente, pero también potencialmente errático o poco fiable.</li>\n",
        "</ul>\n",
        "Esta capacidad de ajuste fino es una de las razones por las que los LLMs son herramientas tan versátiles.\n",
        "\"\"\",\n",
        "    \"tabla_resumen_temp\": \"\"\"\n",
        "<h2>Resumen Clave: Temperatura en LLMs</h2>\n",
        "<table style=\"border-collapse:collapse;width:100%;margin-top:1em; box-shadow: 0 2px 4px var(--shadow-color);\">\n",
        "<thead>\n",
        "<tr style=\"background-color: var(--secondary-color); color: white; text-align:left;\">\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Característica</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Descripción</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Efecto de T Baja (↓)</th>\n",
        "  <th style=\"padding:10px;border:1px solid var(--table-border-color);\">Efecto de T Alta (↑)</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Definición</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Parámetro</b> que controla la <b>aleatoriedad</b> en la <b>selección</b> de <b>tokens</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Más <b>determinista</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Más <b>estocástico</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Mecanismo</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Re-escala los <b>logits</b> antes de la función <b>softmax</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Acentúa diferencias de <b>probabilidad</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Suaviza diferencias de <b>probabilidad</b>.</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Coherencia</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Fidelidad al <b>contexto</b> y lógica.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Alta.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Baja (riesgo de divagación).</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-odd);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Creatividad</b> / <b>Diversidad</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Originalidad y variedad de las <b>respuestas</b>.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Baja (<b>respuestas</b> predecibles).</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Alta (<b>respuestas</b> sorprendentes).</td>\n",
        "</tr>\n",
        "<tr style=\"background-color: var(--row-bg-even);\">\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\"><b>Casos de Uso Típicos</b></td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Aplicaciones recomendadas.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Tareas factuales, resúmenes, código.</td>\n",
        "  <td style=\"padding:8px;border:1px solid var(--table-border-color);\">Escritura creativa, brainstorming.</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\"\"\",\n",
        "    \"conclusion_temp\": \"\"\"\n",
        "<h2>Conclusión: La Temperatura como Herramienta Esencial de Ajuste Fino</h2>\n",
        "La <b>temperatura</b> es un <b>parámetro</b> deceptivamente simple pero increíblemente poderoso para dirigir el comportamiento de los <b>modelos de lenguaje</b> generativos. Al permitirnos navegar el espectro entre la <b>explotación</b> del conocimiento aprendido y la <b>exploración</b> de nuevas posibilidades, nos da un control significativo sobre el tono, estilo y naturaleza de la <b>generación de texto</b>.<br><br>\n",
        "Dominar el uso de la <b>temperatura</b>, a menudo en combinación con otras técnicas de <b>muestreo</b> como <b>Top-P</b> o <b>Top-K</b>, es fundamental para adaptar los <b>modelos de lenguaje</b> a tareas específicas y para lograr el delicado equilibrio entre <b>coherencia</b> y <b>creatividad</b> que define a las aplicaciones de <b>NLP</b> más impactantes. Es una perilla de ajuste fino que, sin modificar los <b>parámetros</b> internos del modelo ni requerir reentrenamiento, transforma la manera en que interactuamos y obtenemos valor de estos sistemas de IA.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "ordered_sections_keys_temp = [\n",
        "    \"title\", \"subtitle\", \"intro\", \"por_que\", \"como_funciona\", \"ejemplo_ilustrativo\",\n",
        "    \"exploracion_explotacion\", \"cuando_usar\", \"otras_tecnicas_muestreo\",\n",
        "    \"consideraciones_advertencias\", \"impacto_percepcion\", \"tabla_resumen_temp\", \"conclusion_temp\"\n",
        "]\n",
        "\n",
        "# 4. Aplicar el resaltado\n",
        "highlighted_sections_temp = {\n",
        "    k: highlight_keywords(sections_temp[k], keywords_temp)\n",
        "    for k in ordered_sections_keys_temp if k in sections_temp\n",
        "}\n",
        "\n",
        "# 5. CSS + JS (reutilizando los estilos mejorados)\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #1e88e5;\n",
        "  --secondary-color: #00acc1;\n",
        "  --text-color: #37474f;\n",
        "  --bg-color: #f4f6f8;\n",
        "  --container-bg: #ffffff;\n",
        "  --keyword-bg: #e0f7fa;\n",
        "  --keyword-text: #00796b;\n",
        "  --button-bg: #e9ecef;\n",
        "  --button-hover-bg: #ced4da;\n",
        "  --button-text-color: #212529;\n",
        "  --shadow-color: rgba(0,0,0,0.08);\n",
        "  --table-border-color: #dee2e6;\n",
        "  --row-bg-odd: #f8f9fa;\n",
        "  --row-bg-even: #ffffff;\n",
        "  --pre-bg: #e9ecef;\n",
        "  --pre-text: #212529;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #42a5f5;\n",
        "  --secondary-color: #26c6da;\n",
        "  --text-color: #e0e0e0;\n",
        "  --bg-color: #121212;\n",
        "  --container-bg: #1e1e1e;\n",
        "  --keyword-bg: #37474f;\n",
        "  --keyword-text: #80deea;\n",
        "  --button-bg: #343a40;\n",
        "  --button-hover-bg: #495057;\n",
        "  --button-text-color: #f8f9fa;\n",
        "  --shadow-color: rgba(0,0,0,0.5);\n",
        "  --table-border-color: #495057;\n",
        "  --row-bg-odd: #2c3034;\n",
        "  --row-bg-even: #212529;\n",
        "  --pre-bg: #2c3034;\n",
        "  --pre-text: #f8f9fa;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Roboto', 'Arial', sans-serif;\n",
        "  line-height: 1.75;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 20px;\n",
        "  margin: 0;\n",
        "}\n",
        ".container {\n",
        "  max-width: 980px;\n",
        "  margin: 30px auto;\n",
        "  padding: 30px 40px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 12px;\n",
        "  box-shadow: 0 6px 18px var(--shadow-color);\n",
        "  position: relative;\n",
        "  transition: background-color .3s, box-shadow .3s;\n",
        "  border-top: 7px solid var(--primary-color);\n",
        "}\n",
        "h1 {\n",
        "  color: var(--primary-color);\n",
        "  font-size: 2.4em;\n",
        "  margin-bottom: .1em;\n",
        "  line-height: 1.25;\n",
        "  text-align: center;\n",
        "  border-bottom: 2px solid var(--secondary-color);\n",
        "  padding-bottom: 0.3em;\n",
        "}\n",
        "h2 {\n",
        "  color: var(--secondary-color);\n",
        "  text-align: left;\n",
        "  margin-top: 2.3em;\n",
        "  margin-bottom: .8em;\n",
        "  font-size: 1.8em;\n",
        "  border-bottom: 1px solid #ddd;\n",
        "  padding-bottom: 0.2em;\n",
        "}\n",
        "body.dark-mode h2 {\n",
        "    border-bottom: 1px solid #444;\n",
        "}\n",
        ".subtitle-style {\n",
        "  font-style:italic;\n",
        "  font-weight:400;\n",
        "  color: var(--text-color);\n",
        "  opacity: 0.85;\n",
        "  text-align:center;\n",
        "  margin-top:0.2em;\n",
        "  margin-bottom: 1.8em;\n",
        "  font-size: 1.15em;\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.2em 0.4em;\n",
        "  border-radius: 5px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--button-bg);\n",
        "  color: var(--button-text-color);\n",
        "  border: 1.5px solid var(--secondary-color);\n",
        "  padding: 9px 14px;\n",
        "  border-radius: 6px;\n",
        "  cursor: pointer;\n",
        "  position: fixed;\n",
        "  top: 20px;\n",
        "  right: 25px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, color .2s, border-color .2s, transform .2s;\n",
        "  z-index: 1000;\n",
        "  box-shadow: 0 2px 5px rgba(0,0,0,0.15);\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--button-hover-bg);\n",
        "    transform: translateY(-1px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 3px solid var(--primary-color);\n",
        "    outline-offset: 2px;\n",
        "    border-color: var(--primary-color);\n",
        "}\n",
        "ul, ol { margin-top:0.8em; margin-bottom:1.4em; padding-left: 25px;}\n",
        "ol li, ul li { margin-bottom:0.7em; }\n",
        "p { margin-bottom: 1.3em; }\n",
        "b { color: var(--primary-color); font-weight: 600;}\n",
        "table {\n",
        "    font-size:0.95em;\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    width: 100%;\n",
        "    border-collapse: collapse;\n",
        "    margin: 1.5em 0;\n",
        "}\n",
        "table th, table td {\n",
        "    padding:10px 12px !important;\n",
        "    border:1px solid var(--table-border-color) !important;\n",
        "    text-align: left;\n",
        "    vertical-align: top;\n",
        "}\n",
        "table th { font-weight: 600; background-color: var(--row-bg-odd); }\n",
        "body.dark-mode table th { background-color: var(--row-bg-odd); }\n",
        "\n",
        "tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "body.dark-mode tr:nth-child(even) {background-color: var(--row-bg-even);}\n",
        "body.dark-mode tr:nth-child(odd) {background-color: var(--row-bg-odd);}\n",
        "\n",
        "pre {\n",
        "    background: var(--pre-bg);\n",
        "    color: var(--pre-text);\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    border-radius: 8px;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 0.9em;\n",
        "    line-height: 1.6;\n",
        "    overflow-x: auto;\n",
        "    margin: 1.2em 0;\n",
        "    box-shadow: inset 0 1px 3px rgba(0,0,0,0.07);\n",
        "}\n",
        "code.language-python, code.nohighlight {\n",
        "    font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = function() {\n",
        "    let themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    if (!themeToggleButton) {\n",
        "        const button = document.createElement('button');\n",
        "        button.id = \"theme-toggle-btn\";\n",
        "        button.className = \"theme-toggle\";\n",
        "        button.title = \"Cambiar tema de color\";\n",
        "        button.onclick = toggleTheme;\n",
        "        document.body.appendChild(button);\n",
        "        themeToggleButton = button;\n",
        "    }\n",
        "\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let currentThemeIsDark = false;\n",
        "\n",
        "    if (savedTheme === \"dark\") {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    } else if (savedTheme === \"light\") {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        currentThemeIsDark = false;\n",
        "    } else if (prefersDark) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        currentThemeIsDark = true;\n",
        "    }\n",
        "\n",
        "    if (themeToggleButton) {\n",
        "         themeToggleButton.textContent = currentThemeIsDark ? \"Modo Claro\" : \"Modo Oscuro\";\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", currentThemeIsDark ? \"true\" : \"false\");\n",
        "    }\n",
        "};\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# 6. Ensamblar el HTML\n",
        "html_body_content_temp = f\"<h1>{highlighted_sections_temp.get('title', '')}</h1>\"\n",
        "html_body_content_temp += f\"<p class='subtitle-style'>{highlighted_sections_temp.get('subtitle', '')}</p>\"\n",
        "\n",
        "for key in ordered_sections_keys_temp:\n",
        "    if key not in [\"title\", \"subtitle\"] and key in highlighted_sections_temp:\n",
        "        html_body_content_temp += f\"<div style='margin-top: 1.5em;'>{highlighted_sections_temp[key]}</div>\"\n",
        "\n",
        "\n",
        "html_structure_temp = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{sections_temp.get('title', 'Temperatura en LLMs')}</title>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
        "    {css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\" aria-pressed=\"false\">Modo Oscuro</button>\n",
        "<div class=\"container\">\n",
        "    {html_body_content_temp}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_structure_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYnljadcxEdZ",
        "outputId": "72d08b93-f3c7-4611-8eb4-8d3bc1bb6816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Probabilidades reales con softmax:\n",
            "\n",
            "1. Token: ' un'  →  Probabilidad: 0.1058\n",
            "2. Token: ' la'  →  Probabilidad: 0.0622\n",
            "3. Token: ' el'  →  Probabilidad: 0.0534\n",
            "4. Token: 'pa'  →  Probabilidad: 0.0351\n",
            "5. Token: ' que'  →  Probabilidad: 0.0262\n",
            "6. Token: ' m'  →  Probabilidad: 0.0159\n",
            "7. Token: ' est'  →  Probabilidad: 0.0130\n",
            "8. Token: ' p'  →  Probabilidad: 0.0127\n",
            "9. Token: ' a'  →  Probabilidad: 0.0116\n",
            "10. Token: ' c'  →  Probabilidad: 0.0104\n",
            "\n",
            " Top 10 Logits para la continuación de: 'El cielo es'\n",
            "\n",
            "1. Token: ' un'  →  Logit: -79.57\n",
            "2. Token: ' la'  →  Logit: -80.10\n",
            "3. Token: ' el'  →  Logit: -80.25\n",
            "4. Token: 'pa'  →  Logit: -80.68\n",
            "5. Token: ' que'  →  Logit: -80.97\n",
            "6. Token: ' m'  →  Logit: -81.47\n",
            "7. Token: ' est'  →  Logit: -81.66\n",
            "8. Token: ' p'  →  Logit: -81.69\n",
            "9. Token: ' a'  →  Logit: -81.79\n",
            "10. Token: ' c'  →  Logit: -81.89\n"
          ]
        }
      ],
      "source": [
        "# /gpt2_logit_example.py\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 1. Cargar modelo y tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.eval()\n",
        "\n",
        "# 2. Texto de entrada\n",
        "input_text = \"El cielo es\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")  # (1, seq_len)\n",
        "\n",
        "# 3. Ejecutar el modelo\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "    logits = outputs.logits  # shape: (1, seq_len, vocab_size)\n",
        "\n",
        "# 4. Obtener logits del último token\n",
        "last_token_logits = logits[0, -1]  # shape: (vocab_size,)\n",
        "# Calcular probabilidades con softmax\n",
        "probs = F.softmax(last_token_logits, dim=0)\n",
        "\n",
        "# Mostrar las probabilidades de los top 10 tokens\n",
        "print(f\"\\n Probabilidades reales con softmax:\\n\")\n",
        "for i in range(10):\n",
        "    token = tokenizer.decode([top_indices[i].item()])\n",
        "    probability = probs[top_indices[i]].item()\n",
        "    print(f\"{i+1}. Token: '{token}'  →  Probabilidad: {probability:.4f}\")\n",
        "\n",
        "\n",
        "# 5. Mostrar los top 10 tokens con logits más altos\n",
        "topk = torch.topk(last_token_logits, k=10)\n",
        "top_indices = topk.indices\n",
        "top_values = topk.values\n",
        "\n",
        "print(f\"\\n Top 10 Logits para la continuación de: '{input_text}'\\n\")\n",
        "for i in range(10):\n",
        "    token = tokenizer.decode([top_indices[i].item()])\n",
        "    logit = top_values[i].item()\n",
        "    print(f\"{i+1}. Token: '{token}'  →  Logit: {logit:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b89c4c3fbc446059654a2060cd07e8d",
            "ff482fd49f3649b9a5ad79f137c4af7a",
            "6e42d1de29c9461a99d0e7a2473436d0",
            "f172878ca54343d3a73a4df27489d9d4",
            "1891bc390c194983922c21b54250b495",
            "dc0d4030682440ca9384ebef37cb6d0a",
            "61c42471e0a64c4cb849859caa627006",
            "7e9b96baded14576a4483b085e6fa333",
            "8e2505b076fe4efd9062c13f56852ec7",
            "426757ce0b694acdb30e1e76507d7272",
            "695efcc3b403470096e3a563f29470c8",
            "1ec2dfb271ed4b2c951b8f051ee9f078",
            "a5f5d2332d074657a6f4dbb7dd4d0079",
            "1ae166fe366f404fb942e80ee4de6c82",
            "b47875796c8449cd9c49647af46296c5",
            "c650a792f6c64c5c956883be31ee71f5",
            "abcaa8f6d691498b8bd3379eb8c2b5b8",
            "88d1857083ae478092cfec7197858c9b",
            "33f4e11a12724c2598c7de89ea0f0770",
            "3cdcd0cbce194070990e4a9f2d5a96dd",
            "397a99e2168f4bf4a686fe98ab80f101",
            "a1624b47a47e476e8014084a81bbfca0",
            "f69ba65f70234906a88142dd99a951e6",
            "3851bb1d88ac4f20ad31a40d7063cbc2",
            "b4254f9d75ba42ad84f8d1a069aa3319",
            "5af38d6bcc2b4542830f3b5476af7e83",
            "2ed3167d78864a9c90b59b310b4e694e",
            "b62b921832b14652a98f33be185901e8",
            "18cf328452cd430b82fe646c09fd4c95",
            "788e013d3c6d4808835a04b968e5f2f6",
            "541502b97cd0486fb5fa2e18dcad56d5",
            "8d2516e0ae2e4779bbb495a99bc4e169",
            "4d14bae0a4f44b8580c60e736142ec0c",
            "0116a3272aff45ddb51735c2147757db",
            "f511ce5e4cb343f19c0587e8b265dcbf",
            "59871166745740e7bc09259860de6816",
            "87050290d8fb43d9984461c79891b081",
            "46005ee0263f402095eaa9994ab445cd",
            "be246970341c4dc78da3f5a970072640",
            "8b21778a05214396b95cd36c4d5a8457",
            "fc9dc96878e44d558d7cf2cf683b813a",
            "bfc2bec826b341639ca7e975a4cd796f",
            "6047220606924f6d98dc1e36e721d296",
            "c206b233b89d4b03b030eb83cfdfa3e4",
            "dd0ebd8387a94da6b0324ab173a643ac",
            "2a17c4fef26046d5a168825cb7e9192c",
            "93f74334c2ab443ea831a54688f8f8d3",
            "94332f5fcf454e288fc6d9f5d8a680ca",
            "355ee08086a64d0c9829643858512005",
            "1242dcb4696a4e97ba7558996b7bf141",
            "b1041f3c38ea4c2aa71d67a0f8ad38fd",
            "d998b21b7f784c0bb1fc6a6c21b19702",
            "f78d8b62fc6d44dcb815f77b9446f5bb",
            "4322c6a25c4a4fca8fb0d4330ee18420",
            "c9f7dae120004818a596866126c0bee3",
            "ba0ef4e7433c4e1188d6b74bc490ada3",
            "0555dd5029504a2f8c471d34965daaa1",
            "e22681294ea84d29a53b41c1811f3f9e"
          ]
        },
        "id": "5satqz1WgFj3",
        "outputId": "8ab58382-b253-453b-c2ac-577026ac71c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b89c4c3fbc446059654a2060cd07e8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value=\"\\n        <style>\\n        .experiment-container {\\n            background: linear-…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c206b233b89d4b03b030eb83cfdfa3e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='\\n    <div style=\"margin-top: 20px; padding: 15px; background: #e8f4f8; border-radius: 8px; border…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Experimento Avanzado: Temperatura en Modelos de Lenguaje\n",
        "# Versión mejorada sin emojis y con mejores prácticas\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from typing import Optional, Dict, List, Tuple, Any\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suprimir warnings de transformers\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Instalación de dependencias\n",
        "def install_dependencies():\n",
        "    \"\"\"Instala las dependencias necesarias de forma silenciosa.\"\"\"\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    packages = [\n",
        "        'transformers[torch]>=4.30.0',\n",
        "        'ipywidgets>=8.0.0',\n",
        "        'matplotlib>=3.6.0',\n",
        "        'torch>=2.0.0',\n",
        "        'numpy>=1.21.0',\n",
        "        'seaborn>=0.12.0'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            logger.warning(f\"No se pudo instalar {package}: {e}\")\n",
        "\n",
        "# Ejecutar instalación\n",
        "try:\n",
        "    install_dependencies()\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error en la instalación de dependencias: {e}\")\n",
        "\n",
        "# Importaciones principales\n",
        "try:\n",
        "    import torch\n",
        "    from transformers import (\n",
        "        AutoTokenizer, AutoModelForCausalLM,\n",
        "        set_seed, GenerationConfig,\n",
        "        pipeline, logging as transformers_logging\n",
        "    )\n",
        "    from IPython.display import display, clear_output\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import VBox, HBox, Layout, interactive, HTML as WidgetHTML\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "    from matplotlib.patches import Rectangle\n",
        "    import matplotlib.patches as mpatches\n",
        "\n",
        "    # Configurar transformers logging\n",
        "    transformers_logging.set_verbosity_error()\n",
        "\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Error importando librerías: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Configuración del experimento.\"\"\"\n",
        "    model_name: str = \"gpt2\"\n",
        "    max_tokens: int = 50\n",
        "    top_k: int = 50\n",
        "    top_p: float = 0.9\n",
        "    device: str = \"auto\"\n",
        "    cache_dir: Optional[str] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.device == \"auto\":\n",
        "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "class LLMTemperatureExplorer:\n",
        "    \"\"\"Clase principal para explorar el efecto de la temperatura en LLMs.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ExperimentConfig):\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.pipeline = None\n",
        "        self.model_loaded = False\n",
        "\n",
        "        # Configuración visual\n",
        "        self.setup_visual_config()\n",
        "\n",
        "        # Datos demo para visualización\n",
        "        self.demo_tokens = [\"inteligente\", \"fascinante\", \"complejo\", \"simple\", \"innovador\"]\n",
        "        self.demo_logits = np.array([4.2, 3.8, 2.1, 1.5, 0.8])\n",
        "\n",
        "        # Cargar modelo\n",
        "        self._load_model()\n",
        "\n",
        "        # Setup UI\n",
        "        self._setup_ui()\n",
        "\n",
        "    def setup_visual_config(self):\n",
        "        \"\"\"Configura los estilos visuales y colores.\"\"\"\n",
        "        self.colors = {\n",
        "            'primary': '#2E86AB',\n",
        "            'secondary': '#A23B72',\n",
        "            'accent': '#F18F01',\n",
        "            'success': '#C73E1D',\n",
        "            'text': '#2C3E50',\n",
        "            'light_bg': '#F8F9FA',\n",
        "            'dark_bg': '#343A40',\n",
        "            'grid': '#E9ECEF'\n",
        "        }\n",
        "\n",
        "        # Configurar matplotlib\n",
        "        plt.style.use('seaborn-v0_8-whitegrid')\n",
        "        plt.rcParams.update({\n",
        "            'figure.figsize': (15, 6),\n",
        "            'figure.dpi': 100,\n",
        "            'font.size': 10,\n",
        "            'axes.titlesize': 12,\n",
        "            'axes.labelsize': 11,\n",
        "            'xtick.labelsize': 9,\n",
        "            'ytick.labelsize': 9,\n",
        "            'legend.fontsize': 9,\n",
        "            'figure.facecolor': 'white',\n",
        "            'axes.facecolor': 'white'\n",
        "        })\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Carga el modelo y tokenizador de forma robusta.\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Cargando modelo {self.config.model_name}...\")\n",
        "\n",
        "            # Cargar tokenizador\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.config.model_name,\n",
        "                cache_dir=self.config.cache_dir,\n",
        "                use_fast=True\n",
        "            )\n",
        "\n",
        "            # Configurar pad_token si no existe\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # Cargar modelo\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.config.model_name,\n",
        "                cache_dir=self.config.cache_dir,\n",
        "                torch_dtype=torch.float16 if self.config.device == \"cuda\" else torch.float32,\n",
        "                device_map=\"auto\" if self.config.device == \"cuda\" else None,\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            # Mover a dispositivo si es necesario\n",
        "            if self.config.device == \"cpu\":\n",
        "                self.model = self.model.to(\"cpu\")\n",
        "\n",
        "            # Crear pipeline\n",
        "            self.pipeline = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=self.model,\n",
        "                tokenizer=self.tokenizer,\n",
        "                device=0 if self.config.device == \"cuda\" else -1,\n",
        "                torch_dtype=torch.float16 if self.config.device == \"cuda\" else torch.float32\n",
        "            )\n",
        "\n",
        "            self.model_loaded = True\n",
        "            logger.info(f\"Modelo cargado exitosamente en {self.config.device}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cargando modelo: {e}\")\n",
        "            self.model_loaded = False\n",
        "\n",
        "    def _setup_ui(self):\n",
        "        \"\"\"Configura la interfaz de usuario.\"\"\"\n",
        "        # Estilos CSS\n",
        "        self.css_styles = \"\"\"\n",
        "        <style>\n",
        "        .experiment-container {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            padding: 20px;\n",
        "            border-radius: 15px;\n",
        "            margin: 10px 0;\n",
        "            color: white;\n",
        "            box-shadow: 0 8px 32px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        .control-panel {\n",
        "            background: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            margin: 15px 0;\n",
        "            box-shadow: 0 4px 16px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        .result-box {\n",
        "            background: #f8f9fa;\n",
        "            border-left: 4px solid #2E86AB;\n",
        "            padding: 20px;\n",
        "            margin: 15px 0;\n",
        "            border-radius: 0 8px 8px 0;\n",
        "        }\n",
        "        .generated-text {\n",
        "            background: white;\n",
        "            border: 2px solid #e9ecef;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            margin: 10px 0;\n",
        "            font-family: 'Georgia', serif;\n",
        "            font-size: 1.1em;\n",
        "            line-height: 1.6;\n",
        "            color: #2c3e50;\n",
        "            box-shadow: inset 0 2px 4px rgba(0,0,0,0.06);\n",
        "        }\n",
        "        .metric-badge {\n",
        "            display: inline-block;\n",
        "            background: #2E86AB;\n",
        "            color: white;\n",
        "            padding: 5px 12px;\n",
        "            border-radius: 15px;\n",
        "            font-size: 0.9em;\n",
        "            margin: 3px;\n",
        "        }\n",
        "        .warning-box {\n",
        "            background: #fff3cd;\n",
        "            border: 1px solid #ffeaa7;\n",
        "            color: #856404;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\"\n",
        "\n",
        "        # Widgets de control\n",
        "        self.seed_text_widget = widgets.Textarea(\n",
        "            value='La inteligencia artificial revolucionará',\n",
        "            description='Texto inicial:',\n",
        "            layout=Layout(width='100%', height='60px'),\n",
        "            style={'description_width': '120px'}\n",
        "        )\n",
        "\n",
        "        self.temperature_widget = widgets.FloatSlider(\n",
        "            value=0.8,\n",
        "            min=0.1,\n",
        "            max=2.5,\n",
        "            step=0.1,\n",
        "            description='Temperatura:',\n",
        "            readout_format='.1f',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=Layout(width='48%')\n",
        "        )\n",
        "\n",
        "        self.max_tokens_widget = widgets.IntSlider(\n",
        "            value=30,\n",
        "            min=10,\n",
        "            max=100,\n",
        "            step=5,\n",
        "            description='Max Tokens:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=Layout(width='48%')\n",
        "        )\n",
        "\n",
        "        self.seed_widget = widgets.IntSlider(\n",
        "            value=42,\n",
        "            min=1,\n",
        "            max=999,\n",
        "            step=1,\n",
        "            description='Semilla:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=Layout(width='48%')\n",
        "        )\n",
        "\n",
        "        self.top_k_widget = widgets.IntSlider(\n",
        "            value=50,\n",
        "            min=1,\n",
        "            max=100,\n",
        "            step=5,\n",
        "            description='Top-K:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=Layout(width='48%')\n",
        "        )\n",
        "\n",
        "        # Botones\n",
        "        self.generate_btn = widgets.Button(\n",
        "            description='Generar texto',\n",
        "            button_style='info',\n",
        "            layout=Layout(width='200px', height='40px'),\n",
        "            tooltip='Generar texto con los parámetros seleccionados'\n",
        "        )\n",
        "\n",
        "        self.compare_btn = widgets.Button(\n",
        "            description='Comparar temperaturas',\n",
        "            button_style='warning',\n",
        "            layout=Layout(width='200px', height='40px'),\n",
        "            tooltip='Comparar diferentes temperaturas'\n",
        "        )\n",
        "\n",
        "        # Widget de salida\n",
        "        self.output_widget = widgets.Output()\n",
        "\n",
        "        # Conectar eventos\n",
        "        self.generate_btn.on_click(self._on_generate_click)\n",
        "        self.compare_btn.on_click(self._on_compare_click)\n",
        "\n",
        "        # Layout principal (solo ipywidgets)\n",
        "        self.main_ui = VBox([\n",
        "            WidgetHTML(self.css_styles),\n",
        "            WidgetHTML(self._get_header_html()),\n",
        "            WidgetHTML('<div class=\"control-panel\">'),\n",
        "            self.seed_text_widget,\n",
        "            HBox([self.temperature_widget, self.max_tokens_widget]),\n",
        "            HBox([self.seed_widget, self.top_k_widget]),\n",
        "            HBox([self.generate_btn, self.compare_btn],\n",
        "                 layout=Layout(justify_content='center', margin='15px 0')),\n",
        "            WidgetHTML('</div>'),\n",
        "            self.output_widget\n",
        "        ])\n",
        "\n",
        "    def _get_header_html(self) -> str:\n",
        "        \"\"\"Genera el HTML del encabezado.\"\"\"\n",
        "        status = \"Modelo cargado\" if self.model_loaded else \"Modelo no disponible\"\n",
        "        device_info = f\"Dispositivo: {self.config.device.upper()}\"\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div class=\"experiment-container\">\n",
        "            <h1>Explorador de Temperatura en Modelos de Lenguaje</h1>\n",
        "            <p>Experimenta con diferentes temperaturas para entender cómo afectan la creatividad y coherencia del texto generado.</p>\n",
        "            <div style=\"margin-top: 15px;\">\n",
        "                <span class=\"metric-badge\">{status}</span>\n",
        "                <span class=\"metric-badge\">Modelo: {self.config.model_name}</span>\n",
        "                <span class=\"metric-badge\">{device_info}</span>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x: np.ndarray, temperature: float = 1.0) -> np.ndarray:\n",
        "        \"\"\"Aplica softmax con temperatura a un array de logits.\"\"\"\n",
        "        if temperature <= 0:\n",
        "            temperature = 1e-8\n",
        "\n",
        "        x_temp = x / temperature\n",
        "        exp_x = np.exp(x_temp - np.max(x_temp))\n",
        "        return exp_x / np.sum(exp_x)\n",
        "\n",
        "    def generate_text(self, prompt: str, temperature: float, max_tokens: int,\n",
        "                     seed: int, top_k: int) -> Dict[str, Any]:\n",
        "        \"\"\"Genera texto con los parámetros especificados.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return {\n",
        "                'text': 'Modelo no disponible para generación',\n",
        "                'error': True,\n",
        "                'metrics': {}\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            set_seed(seed)\n",
        "\n",
        "            # Configuración de generación\n",
        "            generation_config = GenerationConfig(\n",
        "                temperature=max(temperature, 0.1),\n",
        "                max_new_tokens=max_tokens,\n",
        "                top_k=top_k,\n",
        "                top_p=self.config.top_p,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                length_penalty=1.0\n",
        "            )\n",
        "\n",
        "            # Generar\n",
        "            result = self.pipeline(\n",
        "                prompt,\n",
        "                generation_config=generation_config,\n",
        "                return_full_text=True,\n",
        "                num_return_sequences=1\n",
        "            )\n",
        "\n",
        "            generated_text = result[0]['generated_text']\n",
        "\n",
        "            # Calcular métricas\n",
        "            input_length = len(self.tokenizer.encode(prompt))\n",
        "            total_length = len(self.tokenizer.encode(generated_text))\n",
        "            new_tokens = total_length - input_length\n",
        "\n",
        "            metrics = {\n",
        "                'input_tokens': input_length,\n",
        "                'generated_tokens': new_tokens,\n",
        "                'total_tokens': total_length,\n",
        "                'repetition_score': self._calculate_repetition_score(generated_text)\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                'text': generated_text,\n",
        "                'error': False,\n",
        "                'metrics': metrics\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error en generación: {e}\")\n",
        "            return {\n",
        "                'text': f'Error en la generación: {str(e)}',\n",
        "                'error': True,\n",
        "                'metrics': {}\n",
        "            }\n",
        "\n",
        "    def _calculate_repetition_score(self, text: str) -> float:\n",
        "        \"\"\"Calcula un score de repetición básico.\"\"\"\n",
        "        words = text.lower().split()\n",
        "        if len(words) <= 1:\n",
        "            return 0.0\n",
        "\n",
        "        unique_words = len(set(words))\n",
        "        return 1.0 - (unique_words / len(words))\n",
        "\n",
        "    def create_probability_visualization(self, temperatures: List[float]) -> None:\n",
        "        \"\"\"Crea visualización de probabilidades con diferentes temperaturas.\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "        fig.suptitle('Efecto de la Temperatura en la Distribución de Probabilidades',\n",
        "                    fontsize=16, fontweight='bold', color=self.colors['text'])\n",
        "\n",
        "        # Graficar para cada temperatura\n",
        "        temp_colors = [self.colors['primary'], self.colors['secondary'],\n",
        "                      self.colors['accent'], self.colors['success']]\n",
        "\n",
        "        for i, (temp, color) in enumerate(zip(temperatures, temp_colors)):\n",
        "            row, col = i // 2, i % 2\n",
        "            ax = axes[row, col]\n",
        "\n",
        "            # Calcular probabilidades\n",
        "            probs = self.softmax(self.demo_logits, temp)\n",
        "\n",
        "            # Crear gráfico de barras\n",
        "            bars = ax.bar(self.demo_tokens, probs, color=color, alpha=0.8,\n",
        "                         edgecolor='white', linewidth=1.5)\n",
        "\n",
        "            # Personalizar\n",
        "            ax.set_title(f'Temperatura = {temp}', fontsize=14, fontweight='bold',\n",
        "                        color=self.colors['text'])\n",
        "            ax.set_ylabel('Probabilidad', fontsize=12, color=self.colors['text'])\n",
        "            ax.tick_params(axis='x', rotation=45, labelsize=10, colors=self.colors['text'])\n",
        "            ax.tick_params(axis='y', labelsize=10, colors=self.colors['text'])\n",
        "            ax.grid(True, alpha=0.3, axis='y')\n",
        "            ax.set_ylim(0, 1)\n",
        "\n",
        "            # Añadir valores en las barras\n",
        "            for bar, prob in zip(bars, probs):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                       f'{prob:.3f}', ha='center', va='bottom',\n",
        "                       fontsize=9, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Interpretación\n",
        "        interpretation = \"\"\"\n",
        "        <div class=\"result-box\">\n",
        "            <h3>Interpretación de la Visualización</h3>\n",
        "            <ul>\n",
        "                <li><strong>Temperatura Baja (0.2):</strong> La distribución es muy puntiaguda. El modelo se enfoca en las opciones más probables.</li>\n",
        "                <li><strong>Temperatura Media (0.8):</strong> Balance entre predictibilidad y creatividad.</li>\n",
        "                <li><strong>Temperatura Alta (1.5):</strong> Distribución más plana, mayor diversidad en la selección.</li>\n",
        "                <li><strong>Temperatura Muy Alta (2.0):</strong> Distribución casi uniforme, máxima aleatoriedad.</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(WidgetHTML(interpretation))\n",
        "\n",
        "    def _on_generate_click(self, button):\n",
        "        \"\"\"Maneja el evento de generar texto.\"\"\"\n",
        "        with self.output_widget:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # Generar texto\n",
        "            result = self.generate_text(\n",
        "                prompt=self.seed_text_widget.value,\n",
        "                temperature=self.temperature_widget.value,\n",
        "                max_tokens=self.max_tokens_widget.value,\n",
        "                seed=self.seed_widget.value,\n",
        "                top_k=self.top_k_widget.value\n",
        "            )\n",
        "\n",
        "            # Mostrar resultados\n",
        "            self._display_generation_results(result)\n",
        "\n",
        "            # Mostrar visualización de probabilidades\n",
        "            temps = [0.2, self.temperature_widget.value, 1.5, 2.0]\n",
        "            self.create_probability_visualization(temps)\n",
        "\n",
        "    def _on_compare_click(self, button):\n",
        "        \"\"\"Maneja el evento de comparar temperaturas.\"\"\"\n",
        "        with self.output_widget:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            temperatures = [0.2, 0.7, 1.0, 1.5]\n",
        "            results = []\n",
        "\n",
        "            display(WidgetHTML(\"<h3>Generando comparaciones...</h3>\"))\n",
        "\n",
        "            for temp in temperatures:\n",
        "                result = self.generate_text(\n",
        "                    prompt=self.seed_text_widget.value,\n",
        "                    temperature=temp,\n",
        "                    max_tokens=self.max_tokens_widget.value,\n",
        "                    seed=self.seed_widget.value,\n",
        "                    top_k=self.top_k_widget.value\n",
        "                )\n",
        "                results.append((temp, result))\n",
        "\n",
        "            # Mostrar comparación\n",
        "            self._display_comparison_results(results)\n",
        "\n",
        "    def _display_generation_results(self, result: Dict[str, Any]):\n",
        "        \"\"\"Muestra los resultados de la generación.\"\"\"\n",
        "        if result['error']:\n",
        "            warning_html = f\"\"\"\n",
        "            <div class=\"warning-box\">\n",
        "                <strong>Error:</strong> {result['text']}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(WidgetHTML(warning_html))\n",
        "            return\n",
        "\n",
        "        metrics = result['metrics']\n",
        "\n",
        "        result_html = f\"\"\"\n",
        "        <div class=\"result-box\">\n",
        "            <h3>Texto generado</h3>\n",
        "            <div class=\"generated-text\">{result['text']}</div>\n",
        "\n",
        "            <h4>Métricas de generación</h4>\n",
        "            <span class=\"metric-badge\">Temperatura: {self.temperature_widget.value}</span>\n",
        "            <span class=\"metric-badge\">Tokens generados: {metrics.get('generated_tokens', 'N/A')}</span>\n",
        "            <span class=\"metric-badge\">Score repetición: {metrics.get('repetition_score', 0):.3f}</span>\n",
        "            <span class=\"metric-badge\">Semilla: {self.seed_widget.value}</span>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(WidgetHTML(result_html))\n",
        "\n",
        "    def _display_comparison_results(self, results: List[Tuple[float, Dict[str, Any]]]):\n",
        "        \"\"\"Muestra los resultados de la comparación.\"\"\"\n",
        "        comparison_html = \"<div class='result-box'><h3>Comparación de temperaturas</h3>\"\n",
        "\n",
        "        for temp, result in results:\n",
        "            if not result['error']:\n",
        "                comparison_html += f\"\"\"\n",
        "                <div style=\"margin: 15px 0; padding: 15px; border-left: 3px solid #2E86AB; background: #f8f9fa;\">\n",
        "                    <h4 style=\"color: #2E86AB;\">Temperatura {temp}</h4>\n",
        "                    <div style=\"background: white; padding: 12px; border-radius: 6px; font-family: Georgia, serif;\">\n",
        "                        {result['text']}\n",
        "                    </div>\n",
        "                    <small style=\"color: #666;\">\n",
        "                        Tokens: {result['metrics'].get('generated_tokens', 'N/A')} |\n",
        "                        Repetición: {result['metrics'].get('repetition_score', 0):.3f}\n",
        "                    </small>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "        comparison_html += \"</div>\"\n",
        "        display(WidgetHTML(comparison_html))\n",
        "\n",
        "        # Análisis adicional\n",
        "        analysis_html = \"\"\"\n",
        "        <div class=\"result-box\">\n",
        "            <h3>Análisis comparativo</h3>\n",
        "            <p><strong>Observa las diferencias:</strong></p>\n",
        "            <ul>\n",
        "                <li><strong>Temperatura 0.2:</strong> Texto más predecible y coherente</li>\n",
        "                <li><strong>Temperatura 0.7:</strong> Balance entre coherencia y creatividad</li>\n",
        "                <li><strong>Temperatura 1.0:</strong> Creatividad moderada con buena coherencia</li>\n",
        "                <li><strong>Temperatura 1.5:</strong> Mayor creatividad, posible pérdida de coherencia</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(WidgetHTML(analysis_html))\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Muestra la interfaz principal.\"\"\"\n",
        "        display(self.main_ui)\n",
        "\n",
        "        # Mostrar mensaje inicial si el modelo no está cargado\n",
        "        if not self.model_loaded:\n",
        "            with self.output_widget:\n",
        "                warning_html = \"\"\"\n",
        "                <div class=\"warning-box\">\n",
        "                    <strong>Advertencia:</strong> El modelo no pudo cargarse.\n",
        "                    Las visualizaciones conceptuales funcionarán, pero no se generará texto real.\n",
        "                    <br><br>\n",
        "                    <strong>Posibles soluciones:</strong>\n",
        "                    <ul>\n",
        "                        <li>Verificar la conexión a internet</li>\n",
        "                        <li>Intentar con un modelo más pequeño (distilgpt2)</li>\n",
        "                        <li>Verificar la disponibilidad de memoria</li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "                display(WidgetHTML(warning_html))\n",
        "\n",
        "\n",
        "# Función principal para inicializar el experimento\n",
        "def crear_experimento_temperatura(model_name: str = \"gpt2\") -> LLMTemperatureExplorer:\n",
        "    \"\"\"\n",
        "    Crea y retorna una instancia del explorador de temperatura.\n",
        "\n",
        "    Args:\n",
        "        model_name: Nombre del modelo a utilizar (por defecto \"gpt2\")\n",
        "\n",
        "    Returns:\n",
        "        Instancia de LLMTemperatureExplorer\n",
        "    \"\"\"\n",
        "    config = ExperimentConfig(model_name=model_name)\n",
        "    return LLMTemperatureExplorer(config)\n",
        "\n",
        "\n",
        "# Crear y mostrar el experimento\n",
        "if __name__ == \"__main__\":\n",
        "    # Crear el experimento\n",
        "    experimento = crear_experimento_temperatura()\n",
        "\n",
        "    # Mostrar la interfaz\n",
        "    experimento.display()\n",
        "\n",
        "    # Información adicional\n",
        "    info_html = \"\"\"\n",
        "    <div style=\"margin-top: 20px; padding: 15px; background: #e8f4f8; border-radius: 8px; border-left: 4px solid #2E86AB;\">\n",
        "        <h4>Consejos para experimentar</h4>\n",
        "        <ul>\n",
        "            <li><strong>Prueba diferentes prompts:</strong> Textos técnicos vs. creativos responden diferente a la temperatura</li>\n",
        "            <li><strong>Observa la repetición:</strong> Temperaturas muy bajas pueden generar bucles repetitivos</li>\n",
        "            <li><strong>Experimenta con semillas:</strong> La misma configuración con diferente semilla produce resultados distintos</li>\n",
        "            <li><strong>Combina parámetros:</strong> Top-K y temperatura trabajan juntos para controlar la generación</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(WidgetHTML(info_html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6rjL7IQvkBQu",
        "outputId": "fa9f0dbb-8be5-40d8-c819-17c2fc54c430"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>¿Qué es Top-p sampling (nucleus sampling)?</title>\n",
              "    \n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #2e86de;\n",
              "  --secondary-color: #00b894;\n",
              "  --text-color: #222;\n",
              "  --bg-color: #f9fafb;\n",
              "  --container-bg: #fff;\n",
              "  --keyword-bg: #dff9fb;\n",
              "  --keyword-text: #0652dd;\n",
              "  --button-bg: #f1f2f6;\n",
              "  --button-hover-bg: #dfe4ea;\n",
              "  --button-text-color: #222f3e;\n",
              "  --shadow-color: rgba(0,0,0,0.07);\n",
              "  --table-header-bg: #f1f2f6;\n",
              "  --table-border-color: #aaa;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #0984e3;\n",
              "  --secondary-color: #00cec9;\n",
              "  --text-color: #f5f6fa;\n",
              "  --bg-color: #222f3e;\n",
              "  --container-bg: #1e272e;\n",
              "  --keyword-bg: #576574;\n",
              "  --keyword-text: #00d2d3;\n",
              "  --button-bg: #2c3e50;\n",
              "  --button-hover-bg: #34495e;\n",
              "  --button-text-color: #ecf0f1;\n",
              "  --shadow-color: rgba(0,0,0,0.4);\n",
              "  --table-header-bg: #2c3e50;\n",
              "  --table-border-color: #576574;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
              "  line-height: 1.7;\n",
              "  background-color: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  transition: background-color .3s, color .3s;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  font-size: 16px;\n",
              "}\n",
              ".container {\n",
              "  max-width: 850px;\n",
              "  margin: 28px auto;\n",
              "  padding: 30px 35px 30px 35px;\n",
              "  background-color: var(--container-bg);\n",
              "  border-radius: 9px;\n",
              "  box-shadow: 0 4px 12px var(--shadow-color);\n",
              "  position: relative;\n",
              "  border-top: 6px solid var(--primary-color);\n",
              "}\n",
              "h1 {\n",
              "  color: var(--primary-color);\n",
              "  font-size: 2.1em;\n",
              "  text-align: center;\n",
              "  margin-bottom: .1em;\n",
              "  line-height: 1.2;\n",
              "}\n",
              "h2 {\n",
              "  color: var(--secondary-color);\n",
              "  font-size: 1.3em;\n",
              "  text-align: left;\n",
              "  margin-top: 2em;\n",
              "  margin-bottom: .7em;\n",
              "  border-bottom: 2px solid var(--primary-color);\n",
              "  padding-bottom: 0.2em;\n",
              "}\n",
              ".subtitle-main {\n",
              "    font-style:italic;\n",
              "    font-weight:400;\n",
              "    color: var(--text-color);\n",
              "    opacity: 0.87;\n",
              "    text-align:center;\n",
              "    margin-top:-0.3em;\n",
              "    margin-bottom: 1.2em;\n",
              "    font-size: 1.04em;\n",
              "}\n",
              ".keyword {\n",
              "  background-color: var(--keyword-bg);\n",
              "  color: var(--keyword-text);\n",
              "  padding: 0.18em 0.4em;\n",
              "  border-radius: 4px;\n",
              "  font-weight: 600;\n",
              "  display: inline-block;\n",
              "  margin: 0 1px;\n",
              "  transition: background-color .2s, color .2s;\n",
              "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--button-bg);\n",
              "  color: var(--button-text-color);\n",
              "  border: 1.5px solid var(--secondary-color);\n",
              "  padding: 9px 14px;\n",
              "  border-radius: 5px;\n",
              "  cursor: pointer;\n",
              "  position: absolute;\n",
              "  top: 18px;\n",
              "  right: 18px;\n",
              "  font-size: 0.95em;\n",
              "  transition: background-color .2s, color .2s, border-color .2s, transform .1s;\n",
              "  z-index: 10;\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "    background-color: var(--button-hover-bg);\n",
              "    transform: translateY(-1px);\n",
              "}\n",
              ".theme-toggle:focus {\n",
              "    outline: 2px solid var(--primary-color);\n",
              "    outline-offset: 2px;\n",
              "    border-color: var(--primary-color);\n",
              "}\n",
              "table {\n",
              "    font-size: 0.97em;\n",
              "    width:100%;\n",
              "    border-collapse:collapse;\n",
              "    margin-top:1em;\n",
              "    margin-bottom:1.3em;\n",
              "    box-shadow: 0 2px 4px var(--shadow-color);\n",
              "}\n",
              "th, td {\n",
              "    padding: 8px 10px;\n",
              "    border: 1px solid var(--table-border-color);\n",
              "    text-align: left;\n",
              "}\n",
              "th { background-color: var(--table-header-bg); font-weight: 600;}\n",
              "b, strong { color: var(--primary-color); font-weight: 600;}\n",
              "ul, ol { margin-top:0.7em; margin-bottom:1.2em; padding-left: 25px; }\n",
              "li { margin-bottom:0.6em; }\n",
              "hr { border: none; height: 1px; background-color: #e0e0e0; margin:30px 0 18px 0; }\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<div class=\"container\">\n",
              "    <button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
              "    <h1>¿Qué es <strong class=\"keyword\">Top-p</strong> sampling (<strong class=\"keyword\">nucleus sampling</strong>)?</h1>\n",
              "    <h2 class=\"subtitle-main\">Selección probabilística adaptativa en modelos de lenguaje</h2>\n",
              "    <div style=\"margin-top: 1.3em;\">\n",
              "<b><strong class=\"keyword\">Top-p</strong> sampling</b> (también conocido como <b><strong class=\"keyword\">nucleus sampling</strong></b>) es una técnica fundamental utilizada en la <b>generación de texto</b> por <b>modelos de lenguaje</b> modernos como <b><strong class=\"keyword\">GPT</strong></b>. Su objetivo es equilibrar la <b><strong class=\"keyword\">aleatoriedad</strong></b> y la coherencia del texto generado, permitiendo que el modelo produzca respuestas creativas pero relevantes.<br><br>\n",
              "A diferencia de otros métodos de muestreo, <b><strong class=\"keyword\">Top-p</strong></b> no se limita a un número fijo de opciones posibles, sino que determina dinámicamente el conjunto de <b>tokens</b> candidatos a partir de la <b><strong class=\"keyword\">distribución de probabilidad</strong></b> que el modelo calcula para cada posible palabra siguiente. De este modo, se crea un \"<b><strong class=\"keyword\">núcleo</strong></b>\" adaptativo, que incluye solo aquellas palabras cuya <b><strong class=\"keyword\">probabilidad acumulada</strong></b> supera un determinado <b><strong class=\"keyword\">umbral</strong> <strong class=\"keyword\">p</strong></b> (por ejemplo, 0.9).\n",
              "</div>\n",
              "    \n",
              "<h2>¿Cómo funciona <strong class=\"keyword\">Top-p</strong> sampling?</h2>\n",
              "En cada paso de la generación, el <b><strong class=\"keyword\">modelo de lenguaje</strong></b> predice una <b><strong class=\"keyword\">distribución de probabilidad</strong></b> sobre todo su <b><strong class=\"keyword\">vocabulario</strong></b>. Estas probabilidades reflejan la confianza del modelo en cada palabra candidata como próxima.<br><br>\n",
              "El proceso es el siguiente:\n",
              "<ol>\n",
              "<li>Se ordenan las palabras candidatas por su <b>probabilidad</b>, de mayor a menor.</li>\n",
              "<li>Se suman las probabilidades desde la opción más probable hasta alcanzar el <b><strong class=\"keyword\">umbral</strong> <strong class=\"keyword\">p</strong></b> predefinido.</li>\n",
              "<li>Solo las palabras dentro de este “<strong class=\"keyword\">núcleo</strong>” (<b>nucleus</b>) son consideradas para el muestreo final; el resto se descarta completamente.</li>\n",
              "<li>El <b>modelo</b> selecciona aleatoriamente la siguiente palabra únicamente de entre las opciones en el <strong class=\"keyword\">núcleo</strong>.</li>\n",
              "</ol>\n",
              "Este enfoque permite que el tamaño del conjunto de palabras candidatas se adapte dinámicamente a la “certeza” del modelo en cada contexto. Si hay pocas opciones muy probables, el <strong class=\"keyword\">núcleo</strong> será pequeño; si hay muchas opciones plausibles, el <strong class=\"keyword\">núcleo</strong> se expandirá.\n",
              "\n",
              "    \n",
              "<h2>¿Qué significa el parámetro \"p\"?</h2>\n",
              "El parámetro <b><strong class=\"keyword\">p</strong></b> es un <b><strong class=\"keyword\">umbral</strong></b> que define cuánta <b><strong class=\"keyword\">probabilidad acumulada</strong></b> se requiere para formar el <strong class=\"keyword\">núcleo</strong> de muestreo. Por ejemplo:\n",
              "<ul>\n",
              "<li>Un <b><strong class=\"keyword\">p</strong></b> bajo (por ejemplo, 0.7) resultará en un <strong class=\"keyword\">núcleo</strong> pequeño y opciones más conservadoras y repetitivas.</li>\n",
              "<li>Un <b><strong class=\"keyword\">p</strong></b> alto (por ejemplo, 0.95) permitirá más diversidad, pero aumenta el riesgo de generar palabras incoherentes si el modelo no está seguro.</li>\n",
              "</ul>\n",
              "Elegir el valor de <b><strong class=\"keyword\">p</strong></b> es crucial para controlar el balance entre creatividad (<b><strong class=\"keyword\">exploración</strong></b>) y precisión (<b><strong class=\"keyword\">explotación</strong></b>).\n",
              "\n",
              "    \n",
              "<h2>Ventajas de <strong class=\"keyword\">Top-p</strong> sampling</h2>\n",
              "<ul>\n",
              "<li><b>Adaptabilidad:</b> Ajusta automáticamente el tamaño del <strong class=\"keyword\">núcleo</strong> según la confianza del modelo, a diferencia de <b><strong class=\"keyword\">Top-k</strong></b> que usa un número fijo de candidatos.</li>\n",
              "<li><b>Mejor balance creatividad-coherencia:</b> Permite resultados novedosos sin perder relevancia, evitando tanto la repetición como la incoherencia.</li>\n",
              "<li><b>Previene resultados extremos:</b> Limita la selección a palabras plausibles y reduce el riesgo de elegir tokens inusuales o absurdos.</li>\n",
              "<li><b>Complementariedad:</b> Se puede combinar con la <b><strong class=\"keyword\">temperatura</strong></b> para un control más fino del “estilo” de la generación textual.</li>\n",
              "</ul>\n",
              "\n",
              "    \n",
              "<h2>Comparación: <strong class=\"keyword\">Top-p</strong>, <strong class=\"keyword\">Top-k</strong> y otros métodos</h2>\n",
              "<table style=\"border-collapse:collapse;width:100%;margin-top:1em;\">\n",
              "<tr style=\"background:#f1f2f6;\">\n",
              "  <th style=\"padding:6px;border:1px solid #aaa;\">Método</th>\n",
              "  <th style=\"padding:6px;border:1px solid #aaa;\">¿Cómo funciona?</th>\n",
              "  <th style=\"padding:6px;border:1px solid #aaa;\">Características</th>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\"><b><strong class=\"keyword\">Argmax</strong></b></td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Siempre elige el <b><strong class=\"keyword\">token</strong></b> más probable.</td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Determinista y repetitivo; sin creatividad.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\"><b><strong class=\"keyword\">Temperatura</strong></b></td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Escala las probabilidades antes de muestrear de todo el <b><strong class=\"keyword\">vocabulario</strong></b>.</td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Controla la <strong class=\"keyword\">aleatoriedad</strong> global; T alta es más creativa, T baja más precisa.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\"><b><strong class=\"keyword\">Top-k</strong></b></td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Selecciona solo entre los k tokens más probables.</td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Rápido y fácil, pero no siempre flexible ante contextos cambiantes.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\"><b><strong class=\"keyword\">Top-p</strong> (<strong class=\"keyword\">Nucleus Sampling</strong>)</b></td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Selecciona entre el <strong class=\"keyword\">núcleo</strong> de tokens cuya <b><strong class=\"keyword\">probabilidad acumulada</strong></b> supera el <strong class=\"keyword\">umbral</strong> <b><strong class=\"keyword\">p</strong></b>.</td>\n",
              "    <td style=\"padding:6px;border:1px solid #aaa;\">Tamaño del <strong class=\"keyword\">núcleo</strong> adaptativo y dinámico; favorece la diversidad controlada.</td>\n",
              "</tr>\n",
              "</table>\n",
              "\n",
              "    \n",
              "<h2>En resumen</h2>\n",
              "<p>\n",
              "<b><strong class=\"keyword\">Top-p</strong> sampling</b> ha revolucionado la generación de texto en <b>modelos de lenguaje</b> al permitir una mayor flexibilidad, adaptabilidad y control de la creatividad. Gracias a su diseño, se obtienen resultados más naturales, menos deterministas y ajustados a la incertidumbre inherente al lenguaje humano.<br><br>\n",
              "Entender y aplicar correctamente esta técnica es clave para investigadores y profesionales de NLP que deseen sacar el máximo partido a los modelos generativos de nueva generación.\n",
              "</p>\n",
              "\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "function applyInitialTheme() {\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let useDarkMode = false;\n",
              "    if (savedTheme) {\n",
              "        useDarkMode = savedTheme === \"dark\";\n",
              "    } else {\n",
              "        useDarkMode = prefersDark;\n",
              "    }\n",
              "    if (useDarkMode) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
              "        }\n",
              "    } else {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
              "        }\n",
              "    }\n",
              "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = applyInitialTheme;\n",
              "if (window.matchMedia) {\n",
              "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
              "        if (!localStorage.getItem(\"theme\")) {\n",
              "            applyInitialTheme();\n",
              "        }\n",
              "    });\n",
              "}\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "import re\n",
        "\n",
        "# 1. Palabras clave y función de resaltado\n",
        "keywords_top_p = [\n",
        "    \"Top-p\", \"nucleus sampling\", \"probabilidad acumulada\", \"umbral\", \"p\", \"modelo de lenguaje\",\n",
        "    \"GPT\", \"token\", \"aleatoriedad\", \"núcleo\", \"Top-k\", \"argmax\", \"temperatura\", \"exploración\", \"explotación\",\n",
        "    \"distribución de probabilidad\", \"vocabulario\"\n",
        "]\n",
        "\n",
        "def highlight_keywords(text, keywords):\n",
        "    parts = []\n",
        "    keyword_pattern = '|'.join(r'(?<![\\w])(?:' + re.escape(kw) + r')(?![\\w])' for kw in keywords)\n",
        "    pattern = f'({keyword_pattern})'\n",
        "    for match in re.finditer(pattern, text, flags=re.IGNORECASE):\n",
        "        start, end = match.span()\n",
        "        last_open_bracket = text.rfind('<', 0, start)\n",
        "        last_close_bracket = text.rfind('>', 0, start)\n",
        "        if last_open_bracket > last_close_bracket:\n",
        "            continue\n",
        "        last_double_quote = text.rfind('\"', 0, start)\n",
        "        last_single_quote = text.rfind(\"'\", 0, start)\n",
        "        latest_quote = max(last_double_quote, last_single_quote)\n",
        "        if latest_quote != -1 and latest_quote > last_close_bracket:\n",
        "            quote_char = '\"' if last_double_quote > last_single_quote else \"'\"\n",
        "            segment_before_match = text[last_close_bracket + 1 : start]\n",
        "            if segment_before_match.count(quote_char) % 2 != 0:\n",
        "                continue\n",
        "        parts.append({'start': start, 'end': end, 'text': match.group(1)})\n",
        "    parts.sort(key=lambda x: x['start'])\n",
        "    filtered_parts = []\n",
        "    last_part_end = -1\n",
        "    for part in parts:\n",
        "        if part['start'] >= last_part_end:\n",
        "            filtered_parts.append(part)\n",
        "            last_part_end = part['end']\n",
        "    highlighted_text = \"\"\n",
        "    current_pos = 0\n",
        "    for part in filtered_parts:\n",
        "        highlighted_text += text[current_pos:part['start']]\n",
        "        highlighted_text += f'<strong class=\"keyword\">{part[\"text\"]}</strong>'\n",
        "        current_pos = part['end']\n",
        "    highlighted_text += text[current_pos:]\n",
        "    return highlighted_text\n",
        "\n",
        "# 2. Texto ampliado y estructurado (sin ejemplos numéricos, solo teoría y comparación)\n",
        "\n",
        "sections = {\n",
        "    \"title\": \"¿Qué es Top-p sampling (nucleus sampling)?\",\n",
        "    \"subtitle\": \"Selección probabilística adaptativa en modelos de lenguaje\",\n",
        "    \"intro\": \"\"\"\n",
        "<b>Top-p sampling</b> (también conocido como <b>nucleus sampling</b>) es una técnica fundamental utilizada en la <b>generación de texto</b> por <b>modelos de lenguaje</b> modernos como <b>GPT</b>. Su objetivo es equilibrar la <b>aleatoriedad</b> y la coherencia del texto generado, permitiendo que el modelo produzca respuestas creativas pero relevantes.<br><br>\n",
        "A diferencia de otros métodos de muestreo, <b>Top-p</b> no se limita a un número fijo de opciones posibles, sino que determina dinámicamente el conjunto de <b>tokens</b> candidatos a partir de la <b>distribución de probabilidad</b> que el modelo calcula para cada posible palabra siguiente. De este modo, se crea un \"<b>núcleo</b>\" adaptativo, que incluye solo aquellas palabras cuya <b>probabilidad acumulada</b> supera un determinado <b>umbral p</b> (por ejemplo, 0.9).\n",
        "\"\"\",\n",
        "    \"como_funciona\": \"\"\"\n",
        "<h2>¿Cómo funciona Top-p sampling?</h2>\n",
        "En cada paso de la generación, el <b>modelo de lenguaje</b> predice una <b>distribución de probabilidad</b> sobre todo su <b>vocabulario</b>. Estas probabilidades reflejan la confianza del modelo en cada palabra candidata como próxima.<br><br>\n",
        "El proceso es el siguiente:\n",
        "<ol>\n",
        "<li>Se ordenan las palabras candidatas por su <b>probabilidad</b>, de mayor a menor.</li>\n",
        "<li>Se suman las probabilidades desde la opción más probable hasta alcanzar el <b>umbral p</b> predefinido.</li>\n",
        "<li>Solo las palabras dentro de este “núcleo” (<b>nucleus</b>) son consideradas para el muestreo final; el resto se descarta completamente.</li>\n",
        "<li>El <b>modelo</b> selecciona aleatoriamente la siguiente palabra únicamente de entre las opciones en el núcleo.</li>\n",
        "</ol>\n",
        "Este enfoque permite que el tamaño del conjunto de palabras candidatas se adapte dinámicamente a la “certeza” del modelo en cada contexto. Si hay pocas opciones muy probables, el núcleo será pequeño; si hay muchas opciones plausibles, el núcleo se expandirá.\n",
        "\"\"\",\n",
        "    \"que_es_p\": \"\"\"\n",
        "<h2>¿Qué significa el parámetro \"p\"?</h2>\n",
        "El parámetro <b>p</b> es un <b>umbral</b> que define cuánta <b>probabilidad acumulada</b> se requiere para formar el núcleo de muestreo. Por ejemplo:\n",
        "<ul>\n",
        "<li>Un <b>p</b> bajo (por ejemplo, 0.7) resultará en un núcleo pequeño y opciones más conservadoras y repetitivas.</li>\n",
        "<li>Un <b>p</b> alto (por ejemplo, 0.95) permitirá más diversidad, pero aumenta el riesgo de generar palabras incoherentes si el modelo no está seguro.</li>\n",
        "</ul>\n",
        "Elegir el valor de <b>p</b> es crucial para controlar el balance entre creatividad (<b>exploración</b>) y precisión (<b>explotación</b>).\n",
        "\"\"\",\n",
        "    \"ventajas\": \"\"\"\n",
        "<h2>Ventajas de Top-p sampling</h2>\n",
        "<ul>\n",
        "<li><b>Adaptabilidad:</b> Ajusta automáticamente el tamaño del núcleo según la confianza del modelo, a diferencia de <b>Top-k</b> que usa un número fijo de candidatos.</li>\n",
        "<li><b>Mejor balance creatividad-coherencia:</b> Permite resultados novedosos sin perder relevancia, evitando tanto la repetición como la incoherencia.</li>\n",
        "<li><b>Previene resultados extremos:</b> Limita la selección a palabras plausibles y reduce el riesgo de elegir tokens inusuales o absurdos.</li>\n",
        "<li><b>Complementariedad:</b> Se puede combinar con la <b>temperatura</b> para un control más fino del “estilo” de la generación textual.</li>\n",
        "</ul>\n",
        "\"\"\",\n",
        "    \"comparativa\": \"\"\"\n",
        "<h2>Comparación: Top-p, Top-k y otros métodos</h2>\n",
        "<table style=\"border-collapse:collapse;width:100%;margin-top:1em;\">\n",
        "<tr style=\"background:#f1f2f6;\">\n",
        "  <th style=\"padding:6px;border:1px solid #aaa;\">Método</th>\n",
        "  <th style=\"padding:6px;border:1px solid #aaa;\">¿Cómo funciona?</th>\n",
        "  <th style=\"padding:6px;border:1px solid #aaa;\">Características</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\"><b>Argmax</b></td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Siempre elige el <b>token</b> más probable.</td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Determinista y repetitivo; sin creatividad.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\"><b>Temperatura</b></td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Escala las probabilidades antes de muestrear de todo el <b>vocabulario</b>.</td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Controla la aleatoriedad global; T alta es más creativa, T baja más precisa.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\"><b>Top-k</b></td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Selecciona solo entre los k tokens más probables.</td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Rápido y fácil, pero no siempre flexible ante contextos cambiantes.</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\"><b>Top-p (Nucleus Sampling)</b></td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Selecciona entre el núcleo de tokens cuya <b>probabilidad acumulada</b> supera el umbral <b>p</b>.</td>\n",
        "    <td style=\"padding:6px;border:1px solid #aaa;\">Tamaño del núcleo adaptativo y dinámico; favorece la diversidad controlada.</td>\n",
        "</tr>\n",
        "</table>\n",
        "\"\"\",\n",
        "    \"resumen\": \"\"\"\n",
        "<h2>En resumen</h2>\n",
        "<p>\n",
        "<b>Top-p sampling</b> ha revolucionado la generación de texto en <b>modelos de lenguaje</b> al permitir una mayor flexibilidad, adaptabilidad y control de la creatividad. Gracias a su diseño, se obtienen resultados más naturales, menos deterministas y ajustados a la incertidumbre inherente al lenguaje humano.<br><br>\n",
        "Entender y aplicar correctamente esta técnica es clave para investigadores y profesionales de NLP que deseen sacar el máximo partido a los modelos generativos de nueva generación.\n",
        "</p>\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# Aplica resaltado a todas las secciones\n",
        "highlighted_sections = {k: highlight_keywords(v, keywords_top_p) for k, v in sections.items()}\n",
        "\n",
        "# 3. CSS y JS para modo oscuro/claro y keywords (botón destacado arriba derecha)\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #2e86de;\n",
        "  --secondary-color: #00b894;\n",
        "  --text-color: #222;\n",
        "  --bg-color: #f9fafb;\n",
        "  --container-bg: #fff;\n",
        "  --keyword-bg: #dff9fb;\n",
        "  --keyword-text: #0652dd;\n",
        "  --button-bg: #f1f2f6;\n",
        "  --button-hover-bg: #dfe4ea;\n",
        "  --button-text-color: #222f3e;\n",
        "  --shadow-color: rgba(0,0,0,0.07);\n",
        "  --table-header-bg: #f1f2f6;\n",
        "  --table-border-color: #aaa;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #0984e3;\n",
        "  --secondary-color: #00cec9;\n",
        "  --text-color: #f5f6fa;\n",
        "  --bg-color: #222f3e;\n",
        "  --container-bg: #1e272e;\n",
        "  --keyword-bg: #576574;\n",
        "  --keyword-text: #00d2d3;\n",
        "  --button-bg: #2c3e50;\n",
        "  --button-hover-bg: #34495e;\n",
        "  --button-text-color: #ecf0f1;\n",
        "  --shadow-color: rgba(0,0,0,0.4);\n",
        "  --table-header-bg: #2c3e50;\n",
        "  --table-border-color: #576574;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "  line-height: 1.7;\n",
        "  background-color: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  transition: background-color .3s, color .3s;\n",
        "  padding: 0;\n",
        "  margin: 0;\n",
        "  font-size: 16px;\n",
        "}\n",
        ".container {\n",
        "  max-width: 850px;\n",
        "  margin: 28px auto;\n",
        "  padding: 30px 35px 30px 35px;\n",
        "  background-color: var(--container-bg);\n",
        "  border-radius: 9px;\n",
        "  box-shadow: 0 4px 12px var(--shadow-color);\n",
        "  position: relative;\n",
        "  border-top: 6px solid var(--primary-color);\n",
        "}\n",
        "h1 {\n",
        "  color: var(--primary-color);\n",
        "  font-size: 2.1em;\n",
        "  text-align: center;\n",
        "  margin-bottom: .1em;\n",
        "  line-height: 1.2;\n",
        "}\n",
        "h2 {\n",
        "  color: var(--secondary-color);\n",
        "  font-size: 1.3em;\n",
        "  text-align: left;\n",
        "  margin-top: 2em;\n",
        "  margin-bottom: .7em;\n",
        "  border-bottom: 2px solid var(--primary-color);\n",
        "  padding-bottom: 0.2em;\n",
        "}\n",
        ".subtitle-main {\n",
        "    font-style:italic;\n",
        "    font-weight:400;\n",
        "    color: var(--text-color);\n",
        "    opacity: 0.87;\n",
        "    text-align:center;\n",
        "    margin-top:-0.3em;\n",
        "    margin-bottom: 1.2em;\n",
        "    font-size: 1.04em;\n",
        "}\n",
        ".keyword {\n",
        "  background-color: var(--keyword-bg);\n",
        "  color: var(--keyword-text);\n",
        "  padding: 0.18em 0.4em;\n",
        "  border-radius: 4px;\n",
        "  font-weight: 600;\n",
        "  display: inline-block;\n",
        "  margin: 0 1px;\n",
        "  transition: background-color .2s, color .2s;\n",
        "  box-shadow: 0 1px 2px rgba(0,0,0,0.05);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--button-bg);\n",
        "  color: var(--button-text-color);\n",
        "  border: 1.5px solid var(--secondary-color);\n",
        "  padding: 9px 14px;\n",
        "  border-radius: 5px;\n",
        "  cursor: pointer;\n",
        "  position: absolute;\n",
        "  top: 18px;\n",
        "  right: 18px;\n",
        "  font-size: 0.95em;\n",
        "  transition: background-color .2s, color .2s, border-color .2s, transform .1s;\n",
        "  z-index: 10;\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "    background-color: var(--button-hover-bg);\n",
        "    transform: translateY(-1px);\n",
        "}\n",
        ".theme-toggle:focus {\n",
        "    outline: 2px solid var(--primary-color);\n",
        "    outline-offset: 2px;\n",
        "    border-color: var(--primary-color);\n",
        "}\n",
        "table {\n",
        "    font-size: 0.97em;\n",
        "    width:100%;\n",
        "    border-collapse:collapse;\n",
        "    margin-top:1em;\n",
        "    margin-bottom:1.3em;\n",
        "    box-shadow: 0 2px 4px var(--shadow-color);\n",
        "}\n",
        "th, td {\n",
        "    padding: 8px 10px;\n",
        "    border: 1px solid var(--table-border-color);\n",
        "    text-align: left;\n",
        "}\n",
        "th { background-color: var(--table-header-bg); font-weight: 600;}\n",
        "b, strong { color: var(--primary-color); font-weight: 600;}\n",
        "ul, ol { margin-top:0.7em; margin-bottom:1.2em; padding-left: 25px; }\n",
        "li { margin-bottom:0.6em; }\n",
        "hr { border: none; height: 1px; background-color: #e0e0e0; margin:30px 0 18px 0; }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "function applyInitialTheme() {\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let useDarkMode = false;\n",
        "    if (savedTheme) {\n",
        "        useDarkMode = savedTheme === \"dark\";\n",
        "    } else {\n",
        "        useDarkMode = prefersDark;\n",
        "    }\n",
        "    if (useDarkMode) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
        "        }\n",
        "    } else {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
        "        }\n",
        "    }\n",
        "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = applyInitialTheme;\n",
        "if (window.matchMedia) {\n",
        "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
        "        if (!localStorage.getItem(\"theme\")) {\n",
        "            applyInitialTheme();\n",
        "        }\n",
        "    });\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# 4. Ensamblar HTML (solo texto, botón tema y resaltado)\n",
        "html_structure = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>{sections['title']}</title>\n",
        "    {css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"container\">\n",
        "    <button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
        "    <h1>{highlighted_sections['title']}</h1>\n",
        "    <h2 class=\"subtitle-main\">{highlighted_sections['subtitle']}</h2>\n",
        "    <div style=\"margin-top: 1.3em;\">{highlighted_sections['intro']}</div>\n",
        "    {highlighted_sections['como_funciona']}\n",
        "    {highlighted_sections['que_es_p']}\n",
        "    {highlighted_sections['ventajas']}\n",
        "    {highlighted_sections['comparativa']}\n",
        "    {highlighted_sections['resumen']}\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_structure))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812,
          "referenced_widgets": [
            "d471f4c46f284adcac5a31166a32f9d3",
            "d144db421408451fb83182cd83b8c8e6",
            "5dc140bbc6404d8d8e0965d6739175cf",
            "79ad004b6ebd43ab9024020c06e5c49f",
            "c0882cbd95e148a4b8db59b1bc518869",
            "8ac84165ec1a4499ba85dfbc7bc8fb0b",
            "096c10297f984ee18106fc3c42a8ffb1"
          ]
        },
        "id": "CNPCin-3lbcC",
        "outputId": "bd9e4ed0-49dd-4792-dd2b-1aaef2524e2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d471f4c46f284adcac5a31166a32f9d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(FloatSlider(value=0.9, description='Umbral p (Top-p):', layout=Layout(margin='10px auto'…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>plot_top_p_legible</b><br/>def plot_top_p_legible(p_umbral=0.9)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-11-1b218a2d2c40&gt;</a>&lt;no docstring&gt;</pre></div>"
            ],
            "text/plain": [
              "<function __main__.plot_top_p_legible(p_umbral=0.9)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "palabras = [\"feliz\", \"cansado\", \"inspirado\", \"vacío\", \"aburrido\", \"perdido\", \"eufórico\", \"desencajado\"]\n",
        "probabilidades = np.array([0.45, 0.25, 0.12, 0.07, 0.05, 0.03, 0.02, 0.01])\n",
        "\n",
        "sorted_indices = np.argsort(-probabilidades)\n",
        "palabras_ordenadas = [palabras[i] for i in sorted_indices]\n",
        "prob_ind_ordenadas = probabilidades[sorted_indices]\n",
        "\n",
        "def plot_top_p_legible(p_umbral=0.9):\n",
        "    clear_output(wait=True)\n",
        "    prob_acumulada = np.cumsum(prob_ind_ordenadas)\n",
        "    nucleo_mask = np.zeros_like(prob_acumulada, dtype=bool)\n",
        "    for i in range(len(prob_acumulada)):\n",
        "        nucleo_mask[i] = True\n",
        "        if prob_acumulada[i] >= p_umbral:\n",
        "            break\n",
        "\n",
        "    # Colores y fuentes\n",
        "    color_nucleo = '#2ecc71'\n",
        "    color_descartada = '#e74c3c'\n",
        "    edge_nucleo = '#196f3d'\n",
        "    edge_descartada = '#922b21'\n",
        "\n",
        "    colores_barras = [color_nucleo if m else color_descartada for m in nucleo_mask]\n",
        "    colores_borde = [edge_nucleo if m else edge_descartada for m in nucleo_mask]\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    bars = ax.bar(palabras_ordenadas, prob_ind_ordenadas, color=colores_barras, edgecolor=colores_borde, linewidth=2, alpha=0.92)\n",
        "\n",
        "    # Solo una etiqueta: Acumulada arriba, Núcleo/Descartada debajo del eje X\n",
        "    for i, bar in enumerate(bars):\n",
        "        y = bar.get_height()\n",
        "        # Probabilidad acumulada arriba\n",
        "        ax.text(bar.get_x() + bar.get_width()/2.0, y + 0.01,\n",
        "                f\"Acum: {prob_acumulada[i]:.2f}\",\n",
        "                ha='center', va='bottom',\n",
        "                fontsize=10, color=\"#222\" if nucleo_mask[i] else \"#922b21\", weight='bold')\n",
        "        # Estado debajo del eje x\n",
        "        ax.text(bar.get_x() + bar.get_width()/2.0, -0.035,\n",
        "                \"Núcleo\" if nucleo_mask[i] else \"Descartada\",\n",
        "                ha='center', va='top',\n",
        "                fontsize=10, color=color_nucleo if nucleo_mask[i] else color_descartada, weight='bold')\n",
        "\n",
        "    ax.set_title(f\"Núcleo Top-p para p = {p_umbral:.2f}\", fontsize=16, weight='bold')\n",
        "    ax.set_xlabel(\"Palabras candidatas\", fontsize=13)\n",
        "    ax.set_ylabel(\"Probabilidad individual\", fontsize=13)\n",
        "    ax.set_ylim(-0.08, max(prob_ind_ordenadas)*1.2)\n",
        "    ax.tick_params(axis='x', rotation=28, labelsize=12)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Leyenda más clara\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_handles = [\n",
        "        Patch(facecolor=color_nucleo, edgecolor=edge_nucleo, label='Seleccionada (núcleo Top-p)'),\n",
        "        Patch(facecolor=color_descartada, edgecolor=edge_descartada, label='Descartada')\n",
        "    ]\n",
        "    ax.legend(handles=legend_handles, loc='upper right', fontsize=11)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Explicación mejorada\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"max-width:760px; margin:auto; background:#f6f6f9; padding:14px 28px; border-radius:7px; font-size:1.07em;\">\n",
        "    <b>¿Cómo leer el gráfico?</b>\n",
        "    <ul>\n",
        "      <li>Las barras <span style=\"color:{color_nucleo}; font-weight:bold;\">verdes</span> muestran las palabras seleccionadas por el núcleo Top-p para el valor elegido de p.</li>\n",
        "      <li>Las barras <span style=\"color:{color_descartada}; font-weight:bold;\">rojas</span> son palabras descartadas, nunca elegidas.</li>\n",
        "      <li>Sobre cada barra se ve la <b>probabilidad acumulada</b> hasta esa palabra (clave para entender Top-p).</li>\n",
        "      <li>Debajo del eje X, cada palabra indica si forma parte del \"Núcleo\" o si es \"Descartada\".</li>\n",
        "      <li>Puedes variar p con el slider: a menor p, núcleo más pequeño y texto más predecible; a mayor p, mayor creatividad pero posible menor coherencia.</li>\n",
        "    </ul>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "widgets.interact(\n",
        "    plot_top_p_legible,\n",
        "    p_umbral=widgets.FloatSlider(\n",
        "        value=0.9, min=0.01, max=1.0, step=0.01,\n",
        "        description=\"Umbral p (Top-p):\",\n",
        "        readout_format='.2f',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='80%', margin='10px auto')\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HGS_GwiimzhH",
        "outputId": "f40a6a17-68d1-4ec9-f831-bc88f0e284be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta charset=\"utf-8\">\n",
              "<title>Frequency Penalty en LLMs</title>\n",
              "\n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #2e86de;\n",
              "  --secondary-color: #21a170;\n",
              "  --text-color: #23272f;\n",
              "  --bg-color: #f6f8fa;\n",
              "  --container-bg: #fff;\n",
              "  --border-color: #d6e0ee;\n",
              "  --code-bg: #f3f7fa;\n",
              "  --blockquote-bg: #e7f6ef;\n",
              "  --blockquote-border: #21a170;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #5dade2;\n",
              "  --secondary-color: #45e0b8;\n",
              "  --text-color: #ebedef;\n",
              "  --bg-color: #161a21;\n",
              "  --container-bg: #202634;\n",
              "  --border-color: #303a50;\n",
              "  --code-bg: #1c2331;\n",
              "  --blockquote-bg: #16302d;\n",
              "  --blockquote-border: #45e0b8;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
              "  background: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  margin: 0; padding: 0;\n",
              "  font-size: 1.09em;\n",
              "  transition: background .4s, color .3s;\n",
              "}\n",
              ".llm-container {\n",
              "  max-width: 880px;\n",
              "  margin: 30px auto 30px auto;\n",
              "  background: var(--container-bg);\n",
              "  padding: 36px 32px 34px 32px;\n",
              "  border-radius: 13px;\n",
              "  border-top: 5px solid var(--primary-color);\n",
              "  box-shadow: 0 6px 36px rgba(44, 62, 80, .08);\n",
              "  position: relative;\n",
              "  border-bottom: 1px solid var(--border-color);\n",
              "}\n",
              ".llm-title {\n",
              "  font-size: 2.04em;\n",
              "  color: var(--primary-color);\n",
              "  margin-bottom: .10em;\n",
              "  text-align: center;\n",
              "  font-weight: 700;\n",
              "}\n",
              ".llm-sub {\n",
              "  text-align: center;\n",
              "  font-size: 1.10em;\n",
              "  color: var(--secondary-color);\n",
              "  margin-bottom: 1.8em;\n",
              "  font-weight: 400;\n",
              "  opacity: 0.89;\n",
              "}\n",
              ".llm-h2 {\n",
              "  color: var(--secondary-color);\n",
              "  margin-top: 2.1em;\n",
              "  margin-bottom: .7em;\n",
              "  border-bottom: 2px solid var(--primary-color);\n",
              "  font-size: 1.21em;\n",
              "  font-weight: 600;\n",
              "  padding-bottom: 0.23em;\n",
              "}\n",
              ".llm-list {\n",
              "  margin-top: .7em; margin-bottom:1.5em; padding-left:28px;\n",
              "}\n",
              ".llm-list li { margin-bottom: .57em; }\n",
              ".llm-blockquote {\n",
              "  background: var(--blockquote-bg);\n",
              "  border-left: 4.3px solid var(--blockquote-border);\n",
              "  padding: 12px 20px 10px 20px;\n",
              "  margin: 20px 0 20px 0;\n",
              "  border-radius: 6px;\n",
              "  font-size: 1.02em;\n",
              "  color: var(--text-color);\n",
              "  opacity: 0.93;\n",
              "}\n",
              ".llm-code {\n",
              "  background: var(--code-bg);\n",
              "  color: #345;\n",
              "  font-family: 'Fira Mono', 'Consolas', monospace;\n",
              "  padding: 7px 11px;\n",
              "  border-radius: 6px;\n",
              "  font-size: 0.97em;\n",
              "  border: 1px solid var(--border-color);\n",
              "  display: inline-block;\n",
              "}\n",
              ".llm-summary {\n",
              "  background: var(--bg-color);\n",
              "  border-left: 5px solid var(--primary-color);\n",
              "  margin-top: 2.3em;\n",
              "  padding: 17px 20px;\n",
              "  font-size: 1.05em;\n",
              "  border-radius: 7px;\n",
              "  color: var(--text-color);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--code-bg);\n",
              "  color: var(--primary-color);\n",
              "  border: 1.8px solid var(--secondary-color);\n",
              "  padding: 9px 18px;\n",
              "  border-radius: 7px;\n",
              "  cursor: pointer;\n",
              "  position: absolute;\n",
              "  top: 21px;\n",
              "  right: 22px;\n",
              "  font-size: 1.05em;\n",
              "  font-weight: 500;\n",
              "  box-shadow: 0 2px 6px rgba(44, 62, 80, .10);\n",
              "  z-index: 20;\n",
              "  transition: background .2s, color .2s, border-color .2s, transform .1s;\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "  background-color: var(--secondary-color);\n",
              "  color: var(--container-bg);\n",
              "  border-color: var(--primary-color);\n",
              "  transform: translateY(-1px);\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<div class=\"llm-container\">\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
              "<div class=\"llm-title\">Frequency Penalty en Modelos de Lenguaje</div>\n",
              "<div class=\"llm-sub\">Controlando la repetición y fomentando la diversidad en LLMs (Large Language Models)</div>\n",
              "\n",
              "<div class=\"llm-h2\">¿Por qué es importante el frequency penalty?</div>\n",
              "<p>\n",
              "En la generación de texto automática con <b>modelos de lenguaje de gran tamaño</b> (LLMs), como GPT, Gemini o Llama, puede aparecer un fenómeno conocido como <b>repetición excesiva</b> de palabras o frases. Sin un control específico, el modelo puede tender a seleccionar múltiples veces las mismas palabras, especialmente si son estadísticamente frecuentes, lo que resulta en textos redundantes o poco naturales.<br>\n",
              "El <b>frequency penalty</b> (penalización por frecuencia) es una solución elegante para reducir este problema, ayudando a que el modelo produzca respuestas más variadas y cercanas al lenguaje humano real.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-h2\">¿Cómo funciona la penalización por frecuencia?</div>\n",
              "<ul class=\"llm-list\">\n",
              "<li>\n",
              "Durante la generación, el modelo rastrea cuántas veces cada palabra o <b>token</b> ya apareció en el texto generado.\n",
              "</li>\n",
              "<li>\n",
              "Antes de decidir la siguiente palabra, <b>ajusta las probabilidades</b> de cada candidato: las palabras más repetidas reciben una penalización y se vuelven menos probables.\n",
              "</li>\n",
              "<li>\n",
              "El parámetro <b>frequency penalty</b> define la fuerza de la penalización: valores altos (por ejemplo, 1.5 o 2.0) hacen que las repeticiones sean mucho menos probables.\n",
              "</li>\n",
              "<li>\n",
              "El modelo se ve \"empujado\" a <b>explorar nuevas palabras</b> o frases, resultando en respuestas más creativas y menos monótonas.\n",
              "</li>\n",
              "</ul>\n",
              "\n",
              "<div class=\"llm-h2\">Explicación matemática básica</div>\n",
              "<p>\n",
              "Al calcular las probabilidades, el modelo ajusta así cada palabra candidata:\n",
              "</p>\n",
              "<div class=\"llm-code\">\n",
              "logit_nuevo(token) = logit_original(token) - (penalty × frecuencia(token_en_texto))\n",
              "</div>\n",
              "<ul class=\"llm-list\">\n",
              "  <li><b>penalty</b>: valor definido por el usuario (0 = sin penalización, 2 = máxima penalización).</li>\n",
              "  <li><b>frecuencia(token_en_texto)</b>: número de veces que el token ya apareció.</li>\n",
              "</ul>\n",
              "\n",
              "<div class=\"llm-blockquote\">\n",
              "<b>Ejemplo conceptual:</b><br>\n",
              "Si la palabra “helado” ya apareció 3 veces y el penalty es 1.2, su logit bajará en 3.6 unidades, reduciendo drásticamente la probabilidad de volver a seleccionarla. Esto incentiva al modelo a buscar alternativas.\n",
              "</div>\n",
              "\n",
              "<div class=\"llm-h2\">Ventajas clave del frequency penalty</div>\n",
              "<ul class=\"llm-list\">\n",
              "<li><b>Evita repeticiones</b>: Fundamental en textos largos y conversaciones para evitar bucles o redundancias.</li>\n",
              "<li><b>Promueve creatividad</b>: El modelo explora términos menos habituales, enriqueciendo la generación.</li>\n",
              "<li><b>Flexible y ajustable</b>: El parámetro puede calibrarse para poesía, código, listas o prosa libre.</li>\n",
              "<li><b>Sinérgico</b>: Complementa a otras técnicas como <b>temperature</b>, <b>top-k</b> y <b>top-p</b>.</li>\n",
              "</ul>\n",
              "\n",
              "<div class=\"llm-h2\">Implementación en Python y frameworks de IA</div>\n",
              "<p>\n",
              "La mayoría de los frameworks modernos (Hugging Face, OpenAI, Cohere, Anthropic, Google) permiten usar <b>frequency_penalty</b> al generar texto:\n",
              "</p>\n",
              "<div class=\"llm-code\">\n",
              "output = model.generate(\n",
              "    prompt=\"El clima está muy...\",\n",
              "    max_new_tokens=30,\n",
              "    frequency_penalty=1.1,\n",
              "    temperature=0.8,\n",
              "    top_p=0.9\n",
              ")\n",
              "</div>\n",
              "<p>\n",
              "Basta ajustar el parámetro para lograr el balance ideal entre coherencia y diversidad.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-summary\">\n",
              "<b>En resumen:</b> <br>\n",
              "La penalización por frecuencia es una herramienta esencial para expertos en NLP y desarrollo de aplicaciones conversacionales, permitiendo controlar el estilo, la diversidad y la naturalidad del texto generado por los LLMs. Gracias a ella, los modelos son capaces de evitar repeticiones y producir respuestas mucho más humanas.\n",
              "</div>\n",
              "\n",
              "<div style=\"margin-top:16px; font-size:1em; color:#7b838d;\">\n",
              "<i>Dato extra: Los mejores asistentes virtuales, chatbots de empresas y generadores de texto usan <b>frequency penalty</b> para mejorar la experiencia de usuario. ¡Prueba ajustar este parámetro para ver la diferencia!</i>\n",
              "</div>\n",
              "\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "function applyInitialTheme() {\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let useDarkMode = false;\n",
              "    if (savedTheme) {\n",
              "        useDarkMode = savedTheme === \"dark\";\n",
              "    } else {\n",
              "        useDarkMode = prefersDark;\n",
              "    }\n",
              "    if (useDarkMode) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
              "        }\n",
              "    } else {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
              "        }\n",
              "    }\n",
              "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = applyInitialTheme;\n",
              "if (window.matchMedia) {\n",
              "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
              "        if (!localStorage.getItem(\"theme\")) {\n",
              "            applyInitialTheme();\n",
              "        }\n",
              "    });\n",
              "}\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #2e86de;\n",
        "  --secondary-color: #21a170;\n",
        "  --text-color: #23272f;\n",
        "  --bg-color: #f6f8fa;\n",
        "  --container-bg: #fff;\n",
        "  --border-color: #d6e0ee;\n",
        "  --code-bg: #f3f7fa;\n",
        "  --blockquote-bg: #e7f6ef;\n",
        "  --blockquote-border: #21a170;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #5dade2;\n",
        "  --secondary-color: #45e0b8;\n",
        "  --text-color: #ebedef;\n",
        "  --bg-color: #161a21;\n",
        "  --container-bg: #202634;\n",
        "  --border-color: #303a50;\n",
        "  --code-bg: #1c2331;\n",
        "  --blockquote-bg: #16302d;\n",
        "  --blockquote-border: #45e0b8;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "  background: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  margin: 0; padding: 0;\n",
        "  font-size: 1.09em;\n",
        "  transition: background .4s, color .3s;\n",
        "}\n",
        ".llm-container {\n",
        "  max-width: 880px;\n",
        "  margin: 30px auto 30px auto;\n",
        "  background: var(--container-bg);\n",
        "  padding: 36px 32px 34px 32px;\n",
        "  border-radius: 13px;\n",
        "  border-top: 5px solid var(--primary-color);\n",
        "  box-shadow: 0 6px 36px rgba(44, 62, 80, .08);\n",
        "  position: relative;\n",
        "  border-bottom: 1px solid var(--border-color);\n",
        "}\n",
        ".llm-title {\n",
        "  font-size: 2.04em;\n",
        "  color: var(--primary-color);\n",
        "  margin-bottom: .10em;\n",
        "  text-align: center;\n",
        "  font-weight: 700;\n",
        "}\n",
        ".llm-sub {\n",
        "  text-align: center;\n",
        "  font-size: 1.10em;\n",
        "  color: var(--secondary-color);\n",
        "  margin-bottom: 1.8em;\n",
        "  font-weight: 400;\n",
        "  opacity: 0.89;\n",
        "}\n",
        ".llm-h2 {\n",
        "  color: var(--secondary-color);\n",
        "  margin-top: 2.1em;\n",
        "  margin-bottom: .7em;\n",
        "  border-bottom: 2px solid var(--primary-color);\n",
        "  font-size: 1.21em;\n",
        "  font-weight: 600;\n",
        "  padding-bottom: 0.23em;\n",
        "}\n",
        ".llm-list {\n",
        "  margin-top: .7em; margin-bottom:1.5em; padding-left:28px;\n",
        "}\n",
        ".llm-list li { margin-bottom: .57em; }\n",
        ".llm-blockquote {\n",
        "  background: var(--blockquote-bg);\n",
        "  border-left: 4.3px solid var(--blockquote-border);\n",
        "  padding: 12px 20px 10px 20px;\n",
        "  margin: 20px 0 20px 0;\n",
        "  border-radius: 6px;\n",
        "  font-size: 1.02em;\n",
        "  color: var(--text-color);\n",
        "  opacity: 0.93;\n",
        "}\n",
        ".llm-code {\n",
        "  background: var(--code-bg);\n",
        "  color: #345;\n",
        "  font-family: 'Fira Mono', 'Consolas', monospace;\n",
        "  padding: 7px 11px;\n",
        "  border-radius: 6px;\n",
        "  font-size: 0.97em;\n",
        "  border: 1px solid var(--border-color);\n",
        "  display: inline-block;\n",
        "}\n",
        ".llm-summary {\n",
        "  background: var(--bg-color);\n",
        "  border-left: 5px solid var(--primary-color);\n",
        "  margin-top: 2.3em;\n",
        "  padding: 17px 20px;\n",
        "  font-size: 1.05em;\n",
        "  border-radius: 7px;\n",
        "  color: var(--text-color);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--code-bg);\n",
        "  color: var(--primary-color);\n",
        "  border: 1.8px solid var(--secondary-color);\n",
        "  padding: 9px 18px;\n",
        "  border-radius: 7px;\n",
        "  cursor: pointer;\n",
        "  position: absolute;\n",
        "  top: 21px;\n",
        "  right: 22px;\n",
        "  font-size: 1.05em;\n",
        "  font-weight: 500;\n",
        "  box-shadow: 0 2px 6px rgba(44, 62, 80, .10);\n",
        "  z-index: 20;\n",
        "  transition: background .2s, color .2s, border-color .2s, transform .1s;\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "  background-color: var(--secondary-color);\n",
        "  color: var(--container-bg);\n",
        "  border-color: var(--primary-color);\n",
        "  transform: translateY(-1px);\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "function applyInitialTheme() {\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let useDarkMode = false;\n",
        "    if (savedTheme) {\n",
        "        useDarkMode = savedTheme === \"dark\";\n",
        "    } else {\n",
        "        useDarkMode = prefersDark;\n",
        "    }\n",
        "    if (useDarkMode) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
        "        }\n",
        "    } else {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
        "        }\n",
        "    }\n",
        "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = applyInitialTheme;\n",
        "if (window.matchMedia) {\n",
        "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
        "        if (!localStorage.getItem(\"theme\")) {\n",
        "            applyInitialTheme();\n",
        "        }\n",
        "    });\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "html_content = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Frequency Penalty en LLMs</title>\n",
        "{css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"llm-container\">\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
        "<div class=\"llm-title\">Frequency Penalty en Modelos de Lenguaje</div>\n",
        "<div class=\"llm-sub\">Controlando la repetición y fomentando la diversidad en LLMs (Large Language Models)</div>\n",
        "\n",
        "<div class=\"llm-h2\">¿Por qué es importante el frequency penalty?</div>\n",
        "<p>\n",
        "En la generación de texto automática con <b>modelos de lenguaje de gran tamaño</b> (LLMs), como GPT, Gemini o Llama, puede aparecer un fenómeno conocido como <b>repetición excesiva</b> de palabras o frases. Sin un control específico, el modelo puede tender a seleccionar múltiples veces las mismas palabras, especialmente si son estadísticamente frecuentes, lo que resulta en textos redundantes o poco naturales.<br>\n",
        "El <b>frequency penalty</b> (penalización por frecuencia) es una solución elegante para reducir este problema, ayudando a que el modelo produzca respuestas más variadas y cercanas al lenguaje humano real.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-h2\">¿Cómo funciona la penalización por frecuencia?</div>\n",
        "<ul class=\"llm-list\">\n",
        "<li>\n",
        "Durante la generación, el modelo rastrea cuántas veces cada palabra o <b>token</b> ya apareció en el texto generado.\n",
        "</li>\n",
        "<li>\n",
        "Antes de decidir la siguiente palabra, <b>ajusta las probabilidades</b> de cada candidato: las palabras más repetidas reciben una penalización y se vuelven menos probables.\n",
        "</li>\n",
        "<li>\n",
        "El parámetro <b>frequency penalty</b> define la fuerza de la penalización: valores altos (por ejemplo, 1.5 o 2.0) hacen que las repeticiones sean mucho menos probables.\n",
        "</li>\n",
        "<li>\n",
        "El modelo se ve \"empujado\" a <b>explorar nuevas palabras</b> o frases, resultando en respuestas más creativas y menos monótonas.\n",
        "</li>\n",
        "</ul>\n",
        "\n",
        "<div class=\"llm-h2\">Explicación matemática básica</div>\n",
        "<p>\n",
        "Al calcular las probabilidades, el modelo ajusta así cada palabra candidata:\n",
        "</p>\n",
        "<div class=\"llm-code\">\n",
        "logit_nuevo(token) = logit_original(token) - (penalty × frecuencia(token_en_texto))\n",
        "</div>\n",
        "<ul class=\"llm-list\">\n",
        "  <li><b>penalty</b>: valor definido por el usuario (0 = sin penalización, 2 = máxima penalización).</li>\n",
        "  <li><b>frecuencia(token_en_texto)</b>: número de veces que el token ya apareció.</li>\n",
        "</ul>\n",
        "\n",
        "<div class=\"llm-blockquote\">\n",
        "<b>Ejemplo conceptual:</b><br>\n",
        "Si la palabra “helado” ya apareció 3 veces y el penalty es 1.2, su logit bajará en 3.6 unidades, reduciendo drásticamente la probabilidad de volver a seleccionarla. Esto incentiva al modelo a buscar alternativas.\n",
        "</div>\n",
        "\n",
        "<div class=\"llm-h2\">Ventajas clave del frequency penalty</div>\n",
        "<ul class=\"llm-list\">\n",
        "<li><b>Evita repeticiones</b>: Fundamental en textos largos y conversaciones para evitar bucles o redundancias.</li>\n",
        "<li><b>Promueve creatividad</b>: El modelo explora términos menos habituales, enriqueciendo la generación.</li>\n",
        "<li><b>Flexible y ajustable</b>: El parámetro puede calibrarse para poesía, código, listas o prosa libre.</li>\n",
        "<li><b>Sinérgico</b>: Complementa a otras técnicas como <b>temperature</b>, <b>top-k</b> y <b>top-p</b>.</li>\n",
        "</ul>\n",
        "\n",
        "<div class=\"llm-h2\">Implementación en Python y frameworks de IA</div>\n",
        "<p>\n",
        "La mayoría de los frameworks modernos (Hugging Face, OpenAI, Cohere, Anthropic, Google) permiten usar <b>frequency_penalty</b> al generar texto:\n",
        "</p>\n",
        "<div class=\"llm-code\">\n",
        "output = model.generate(\n",
        "    prompt=\"El clima está muy...\",\n",
        "    max_new_tokens=30,\n",
        "    frequency_penalty=1.1,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9\n",
        ")\n",
        "</div>\n",
        "<p>\n",
        "Basta ajustar el parámetro para lograr el balance ideal entre coherencia y diversidad.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-summary\">\n",
        "<b>En resumen:</b> <br>\n",
        "La penalización por frecuencia es una herramienta esencial para expertos en NLP y desarrollo de aplicaciones conversacionales, permitiendo controlar el estilo, la diversidad y la naturalidad del texto generado por los LLMs. Gracias a ella, los modelos son capaces de evitar repeticiones y producir respuestas mucho más humanas.\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top:16px; font-size:1em; color:#7b838d;\">\n",
        "<i>Dato extra: Los mejores asistentes virtuales, chatbots de empresas y generadores de texto usan <b>frequency penalty</b> para mejorar la experiencia de usuario. ¡Prueba ajustar este parámetro para ver la diferencia!</i>\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976,
          "referenced_widgets": [
            "87ae7560c9ec446c96c885efbfacc417",
            "796f1ba3351c4d96ac70198d5e0c7945",
            "acfada3d57094982b762e45cab4815c5",
            "5ab10b9628764040bf8261caaf333760",
            "2ac9f348a48142c4bc7537e4aff13c47",
            "8d2c8555e5e745989b6a78eb30a61c97",
            "0e93f3fe653446a2b9ed01fac232f153"
          ]
        },
        "id": "p6Y_jiG-q8XI",
        "outputId": "ea590bcb-7f3c-4697-f949-6d78195c29e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ae7560c9ec446c96c885efbfacc417",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(FloatSlider(value=1.0, description='Penalización por frecuencia:', layout=Layout(margin=…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>plot_frequency_penalty</b><br/>def plot_frequency_penalty(frequency_penalty=1.0)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-42-48a392a6e47f&gt;</a>&lt;no docstring&gt;</pre></div>"
            ],
            "text/plain": [
              "<function __main__.plot_frequency_penalty(frequency_penalty=1.0)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# Palabras y logits iniciales simulados (como si vinieran de un modelo de lenguaje)\n",
        "tokens = [\"café\", \"té\", \"agua\", \"jugo\", \"mate\"]\n",
        "logits_original = np.array([2.0, 1.6, 1.3, 0.8, 0.5])  # Cualquier valor realista\n",
        "frecuencias_iniciales = np.array([2, 0, 1, 3, 0])      # Ejemplo: café y jugo ya se repitieron\n",
        "\n",
        "def plot_frequency_penalty(frequency_penalty=1.0):\n",
        "    clear_output(wait=True)\n",
        "    # Copiar frecuencias para esta simulación\n",
        "    frecuencias = frecuencias_iniciales.copy()\n",
        "\n",
        "    # Aplicar penalización\n",
        "    penalizaciones = frequency_penalty * frecuencias\n",
        "    logits_ajustados = logits_original - penalizaciones\n",
        "\n",
        "    # Calcular probabilidades con softmax antes y después de penalización\n",
        "    def softmax(x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum()\n",
        "\n",
        "    probs_original = softmax(logits_original)\n",
        "    probs_ajustadas = softmax(logits_ajustados)\n",
        "\n",
        "    # Visualización\n",
        "    ancho = 0.37\n",
        "    x = np.arange(len(tokens))\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Barras originales (sin penalización, más translúcidas)\n",
        "    ax.bar(x - ancho/2, probs_original, ancho, label='Probabilidad original', color='#b2bec3', alpha=0.48, edgecolor='#636e72', linewidth=2, zorder=1)\n",
        "    # Barras ajustadas (con penalización)\n",
        "    ax.bar(x + ancho/2, probs_ajustadas, ancho, label='Probabilidad ajustada (con penalización)', color='#00b894', alpha=0.88, edgecolor='#0984e3', linewidth=2, zorder=2)\n",
        "\n",
        "    # Texto encima de cada barra ajustada: frecuencia, penalización, probabilidad\n",
        "    for i in range(len(tokens)):\n",
        "        ax.text(x[i] + ancho/2, probs_ajustadas[i] + 0.011,\n",
        "                f\"{probs_ajustadas[i]:.2f}\", ha='center', va='bottom', fontsize=10, color=\"#0984e3\", fontweight='bold')\n",
        "        # Penalización debajo del eje x\n",
        "        ax.text(x[i], -0.055,\n",
        "                f\"Freq={frecuencias[i]}\\nPenaliz={penalizaciones[i]:.1f}\",\n",
        "                ha='center', va='top', fontsize=9,\n",
        "                color=\"#636e72\" if frecuencias[i]==0 else \"#d35400\", fontweight='bold')\n",
        "\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(tokens, fontsize=13)\n",
        "    ax.set_ylim(-0.12, max(max(probs_original), max(probs_ajustadas))*1.20)\n",
        "    ax.set_ylabel(\"Probabilidad de selección\", fontsize=13)\n",
        "    ax.set_title(f\"Efecto de Frequency Penalty = {frequency_penalty:.2f} en la selección de palabras\", fontsize=15, weight='bold', color='#2d3436')\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.grid(axis='y', alpha=0.33)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Explicación didáctica interactiva\n",
        "    explicacion = f\"\"\"\n",
        "    <div style=\"max-width:820px; margin:auto; background:#f7fafc; border-left:5px solid #21a170; padding:18px 30px 10px 30px; border-radius:9px; font-size:1.11em;\">\n",
        "    <b>Interpretación de la penalización por frecuencia (<span style='color:#21a170;'>frequency penalty</span>):</b>\n",
        "    <ul>\n",
        "      <li>Cada palabra tiene una frecuencia de aparición (abajo, en gris o naranja si es mayor a cero).</li>\n",
        "      <li>El <b>logit ajustado</b> resta <code>frequency_penalty × frecuencia</code> al logit original de cada palabra.</li>\n",
        "      <li>Las barras <span style=\"color:#b2bec3; font-weight:bold;\">gris</span> muestran la probabilidad <u>original</u> (sin penalización), las <span style=\"color:#00b894; font-weight:bold;\">verdes</span> la probabilidad <u>ajustada</u>.</li>\n",
        "      <li>Las palabras que más se repiten sufren una caída de probabilidad: el modelo prefiere explorar alternativas menos frecuentes.</li>\n",
        "      <li>Sube el parámetro “frequency penalty” para ver cómo el modelo favorece más la diversidad y penaliza la repetición.</li>\n",
        "    </ul>\n",
        "    <b>¿Para qué sirve esto?</b> <br>\n",
        "    Ayuda a evitar respuestas repetitivas y a generar textos más variados y naturales.\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(explicacion))\n",
        "\n",
        "widgets.interact(\n",
        "    plot_frequency_penalty,\n",
        "    frequency_penalty=widgets.FloatSlider(\n",
        "        value=1.0, min=0.0, max=2.0, step=0.05,\n",
        "        description=\"Penalización por frecuencia:\",\n",
        "        readout_format='.2f',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='80%', margin='10px auto')\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OgEECNKEsO1P",
        "outputId": "e13cbe05-c77b-474c-cb48-df55937f1b8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<meta charset=\"utf-8\">\n",
              "<title>Presence Penalty en LLMs</title>\n",
              "\n",
              "<style>\n",
              ":root {\n",
              "  --primary-color: #a14be3;\n",
              "  --secondary-color: #128f76;\n",
              "  --text-color: #262b32;\n",
              "  --bg-color: #f5f6fb;\n",
              "  --container-bg: #fff;\n",
              "  --border-color: #dadcec;\n",
              "  --code-bg: #f3f0fb;\n",
              "  --blockquote-bg: #f0f8f4;\n",
              "  --blockquote-border: #128f76;\n",
              "}\n",
              "body.dark-mode {\n",
              "  --primary-color: #d7a6fa;\n",
              "  --secondary-color: #1fe6b1;\n",
              "  --text-color: #ebe9f4;\n",
              "  --bg-color: #23203a;\n",
              "  --container-bg: #2a2740;\n",
              "  --border-color: #47387b;\n",
              "  --code-bg: #251c32;\n",
              "  --blockquote-bg: #1e3431;\n",
              "  --blockquote-border: #1fe6b1;\n",
              "}\n",
              "body {\n",
              "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
              "  background: var(--bg-color);\n",
              "  color: var(--text-color);\n",
              "  margin: 0; padding: 0;\n",
              "  font-size: 1.11em;\n",
              "  transition: background .4s, color .3s;\n",
              "}\n",
              ".llm-container {\n",
              "  max-width: 900px;\n",
              "  margin: 32px auto 36px auto;\n",
              "  background: var(--container-bg);\n",
              "  padding: 38px 34px 36px 34px;\n",
              "  border-radius: 13px;\n",
              "  border-top: 6px solid var(--primary-color);\n",
              "  box-shadow: 0 6px 36px rgba(70, 30, 160, .07);\n",
              "  position: relative;\n",
              "  border-bottom: 1px solid var(--border-color);\n",
              "}\n",
              ".llm-title {\n",
              "  font-size: 2.1em;\n",
              "  color: var(--primary-color);\n",
              "  margin-bottom: .12em;\n",
              "  text-align: center;\n",
              "  font-weight: 700;\n",
              "  letter-spacing: 0.01em;\n",
              "}\n",
              ".llm-sub {\n",
              "  text-align: center;\n",
              "  font-size: 1.12em;\n",
              "  color: var(--secondary-color);\n",
              "  margin-bottom: 2em;\n",
              "  font-weight: 400;\n",
              "  opacity: 0.91;\n",
              "}\n",
              ".llm-h2 {\n",
              "  color: var(--secondary-color);\n",
              "  margin-top: 2.2em;\n",
              "  margin-bottom: .8em;\n",
              "  border-bottom: 2px solid var(--primary-color);\n",
              "  font-size: 1.23em;\n",
              "  font-weight: 600;\n",
              "  padding-bottom: 0.25em;\n",
              "}\n",
              ".llm-list {\n",
              "  margin-top: .8em; margin-bottom:1.6em; padding-left:30px;\n",
              "}\n",
              ".llm-list li { margin-bottom: .6em; }\n",
              ".llm-blockquote {\n",
              "  background: var(--blockquote-bg);\n",
              "  border-left: 5px solid var(--blockquote-border);\n",
              "  padding: 13px 24px 12px 24px;\n",
              "  margin: 22px 0 23px 0;\n",
              "  border-radius: 6px;\n",
              "  font-size: 1.03em;\n",
              "  color: var(--text-color);\n",
              "  opacity: 0.95;\n",
              "}\n",
              ".llm-code {\n",
              "  background: var(--code-bg);\n",
              "  color: #5b42a7;\n",
              "  font-family: 'Fira Mono', 'Consolas', monospace;\n",
              "  padding: 8px 13px;\n",
              "  border-radius: 7px;\n",
              "  font-size: 0.98em;\n",
              "  border: 1px solid var(--border-color);\n",
              "  display: inline-block;\n",
              "}\n",
              ".llm-summary {\n",
              "  background: var(--bg-color);\n",
              "  border-left: 6px solid var(--primary-color);\n",
              "  margin-top: 2.4em;\n",
              "  padding: 19px 22px 16px 22px;\n",
              "  font-size: 1.06em;\n",
              "  border-radius: 8px;\n",
              "  color: var(--text-color);\n",
              "}\n",
              ".theme-toggle {\n",
              "  background-color: var(--code-bg);\n",
              "  color: var(--primary-color);\n",
              "  border: 2px solid var(--secondary-color);\n",
              "  padding: 10px 19px;\n",
              "  border-radius: 8px;\n",
              "  cursor: pointer;\n",
              "  position: absolute;\n",
              "  top: 25px;\n",
              "  right: 27px;\n",
              "  font-size: 1.07em;\n",
              "  font-weight: 500;\n",
              "  box-shadow: 0 2px 9px rgba(80, 60, 130, .08);\n",
              "  z-index: 20;\n",
              "  transition: background .2s, color .2s, border-color .2s, transform .1s;\n",
              "}\n",
              ".theme-toggle:hover {\n",
              "  background-color: var(--secondary-color);\n",
              "  color: var(--container-bg);\n",
              "  border-color: var(--primary-color);\n",
              "  transform: translateY(-1px);\n",
              "}\n",
              "</style>\n",
              "\n",
              "</head>\n",
              "<body>\n",
              "<div class=\"llm-container\">\n",
              "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
              "<div class=\"llm-title\">Presence Penalty en Modelos de Lenguaje</div>\n",
              "<div class=\"llm-sub\">Fomentando la inclusión y diversidad temática en la generación de texto con LLMs</div>\n",
              "\n",
              "<div class=\"llm-h2\">¿Qué es el presence penalty?</div>\n",
              "<p>\n",
              "El <b>presence penalty</b> es una técnica avanzada usada en la generación de texto con <b>modelos de lenguaje de gran tamaño</b> (LLMs), como GPT, Gemini o Llama, cuyo objetivo es <b>promover la aparición de ciertas palabras o temas</b> en el texto generado. Es particularmente útil cuando se requiere que el modelo <b>incluya conceptos, términos o nombres específicos</b> para satisfacer criterios de contenido, estilo o personalización.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-h2\">¿Cómo funciona el presence penalty?</div>\n",
              "<ul class=\"llm-list\">\n",
              "  <li>Durante la generación, el modelo evalúa la presencia previa de palabras o tokens clave en el texto generado hasta el momento.</li>\n",
              "  <li>Si una palabra no ha aparecido aún (o solo ha aparecido pocas veces), el modelo <b>aumenta la probabilidad de seleccionarla</b> en los próximos pasos, modificando los logits (valores base de predicción).</li>\n",
              "  <li>El parámetro <b>presence penalty</b> define la magnitud de este impulso: valores altos incentivan fuertemente la aparición de palabras aún no utilizadas.</li>\n",
              "  <li>Esto garantiza que el modelo “explore” más su vocabulario y cubra los temas deseados, ayudando a generar textos más completos o personalizados.</li>\n",
              "</ul>\n",
              "\n",
              "<div class=\"llm-h2\">¿En qué se diferencia del frequency penalty?</div>\n",
              "<p>\n",
              "Mientras que el <b>frequency penalty</b> penaliza la repetición excesiva de palabras ya mencionadas, el <b>presence penalty</b> actúa principalmente sobre aquellas palabras <b>que aún no han aparecido</b> en el texto. Así, ambos parámetros se complementan: uno reduce repeticiones, el otro fomenta diversidad y cobertura temática.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-h2\">Explicación matemática básica</div>\n",
              "<p>\n",
              "Al calcular la probabilidad de cada token candidato, el modelo puede ajustar así su logit:\n",
              "</p>\n",
              "<div class=\"llm-code\">\n",
              "logit_nuevo(token) = logit_original(token) - (presence_penalty × presencia(token_en_texto))\n",
              "</div>\n",
              "<ul class=\"llm-list\">\n",
              "  <li><b>presence_penalty</b>: valor configurable por el usuario, normalmente entre 0 y 2.</li>\n",
              "  <li><b>presencia(token_en_texto)</b>: indicador (0 si no apareció, 1 o más si ya apareció).</li>\n",
              "</ul>\n",
              "<p>\n",
              "Por ejemplo, si queremos asegurar la inclusión de la palabra “sostenibilidad” y aún no ha aparecido, el modelo la verá como una opción “fresca” y elevará su probabilidad relativa para que sea más fácil que la elija en los siguientes pasos.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-blockquote\">\n",
              "<b>Ejemplo conceptual:</b><br>\n",
              "<strong>Sin penalización de presencia:</strong>  \n",
              "“La inteligencia artificial transforma la educación y la medicina.”<br>\n",
              "<strong>Con penalización de presencia sobre “inclusión” y “diversidad”:</strong><br>\n",
              "“La inteligencia artificial promueve la <b>inclusión</b> y la <b>diversidad</b> en la educación y la medicina.”\n",
              "</div>\n",
              "\n",
              "<div class=\"llm-h2\">¿Para qué sirve en la práctica?</div>\n",
              "<ul class=\"llm-list\">\n",
              "<li><b>Personalización de respuestas:</b> Obliga al modelo a tocar temas, nombres, lugares o conceptos clave (por ejemplo, en generación de resúmenes, informes o textos temáticos).</li>\n",
              "<li><b>Control de estilo o tono:</b> Facilita que el texto generado cumpla requisitos de branding, narrativa, enfoque o compliance.</li>\n",
              "<li><b>Generación de textos completos:</b> Evita omisiones y fomenta que el modelo cubra todos los puntos requeridos en la consigna.</li>\n",
              "<li><b>IA conversacional avanzada:</b> Asegura que el chatbot o asistente incluya mensajes clave del negocio.</li>\n",
              "</ul>\n",
              "\n",
              "<div class=\"llm-h2\">Uso en frameworks y ejemplos de código</div>\n",
              "<p>\n",
              "Tanto <b>Hugging Face</b> como <b>OpenAI</b> y otros frameworks modernos admiten el uso de <b>presence_penalty</b> en la generación de texto:\n",
              "</p>\n",
              "<div class=\"llm-code\">\n",
              "output = model.generate(\n",
              "    prompt=\"Describe el impacto de la IA en la sociedad.\",\n",
              "    max_new_tokens=60,\n",
              "    presence_penalty=1.2,\n",
              "    temperature=0.7,\n",
              "    top_p=0.95\n",
              ")\n",
              "</div>\n",
              "<p>\n",
              "Ajustando este parámetro puedes guiar a los LLMs para que mencionen explícitamente ideas, conceptos o vocabulario de interés en las respuestas.\n",
              "</p>\n",
              "\n",
              "<div class=\"llm-summary\">\n",
              "<b>En resumen:</b><br>\n",
              "La penalización de presencia (<b>presence penalty</b>) es una herramienta clave para guiar, enriquecer y personalizar la generación de texto automática con LLMs, permitiendo que los modelos incluyan de forma controlada los términos, ideas o estilos que el usuario considera fundamentales.\n",
              "</div>\n",
              "\n",
              "<div style=\"margin-top:18px; font-size:1em; color:#8475b1;\">\n",
              "<i>¿Sabías que los chatbots de empresas líderes y generadores de contenido automático usan <b>presence penalty</b> para cumplir requisitos de compliance, branding o experiencia de usuario personalizada? ¡Experimenta ajustando este parámetro para ver el impacto en tus propios proyectos!</i>\n",
              "</div>\n",
              "\n",
              "</div>\n",
              "\n",
              "<script>\n",
              "function toggleTheme() {\n",
              "    const body = document.body;\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
              "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
              "    if (themeToggleButton) {\n",
              "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
              "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "function applyInitialTheme() {\n",
              "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
              "    const savedTheme = localStorage.getItem(\"theme\");\n",
              "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    let useDarkMode = false;\n",
              "    if (savedTheme) {\n",
              "        useDarkMode = savedTheme === \"dark\";\n",
              "    } else {\n",
              "        useDarkMode = prefersDark;\n",
              "    }\n",
              "    if (useDarkMode) {\n",
              "        document.body.classList.add(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
              "        }\n",
              "    } else {\n",
              "        document.body.classList.remove(\"dark-mode\");\n",
              "        if (themeToggleButton) {\n",
              "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
              "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
              "        }\n",
              "    }\n",
              "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
              "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
              "    }\n",
              "}\n",
              "window.onload = applyInitialTheme;\n",
              "if (window.matchMedia) {\n",
              "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
              "        if (!localStorage.getItem(\"theme\")) {\n",
              "            applyInitialTheme();\n",
              "        }\n",
              "    });\n",
              "}\n",
              "</script>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "css_styles = \"\"\"\n",
        "<style>\n",
        ":root {\n",
        "  --primary-color: #a14be3;\n",
        "  --secondary-color: #128f76;\n",
        "  --text-color: #262b32;\n",
        "  --bg-color: #f5f6fb;\n",
        "  --container-bg: #fff;\n",
        "  --border-color: #dadcec;\n",
        "  --code-bg: #f3f0fb;\n",
        "  --blockquote-bg: #f0f8f4;\n",
        "  --blockquote-border: #128f76;\n",
        "}\n",
        "body.dark-mode {\n",
        "  --primary-color: #d7a6fa;\n",
        "  --secondary-color: #1fe6b1;\n",
        "  --text-color: #ebe9f4;\n",
        "  --bg-color: #23203a;\n",
        "  --container-bg: #2a2740;\n",
        "  --border-color: #47387b;\n",
        "  --code-bg: #251c32;\n",
        "  --blockquote-bg: #1e3431;\n",
        "  --blockquote-border: #1fe6b1;\n",
        "}\n",
        "body {\n",
        "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "  background: var(--bg-color);\n",
        "  color: var(--text-color);\n",
        "  margin: 0; padding: 0;\n",
        "  font-size: 1.11em;\n",
        "  transition: background .4s, color .3s;\n",
        "}\n",
        ".llm-container {\n",
        "  max-width: 900px;\n",
        "  margin: 32px auto 36px auto;\n",
        "  background: var(--container-bg);\n",
        "  padding: 38px 34px 36px 34px;\n",
        "  border-radius: 13px;\n",
        "  border-top: 6px solid var(--primary-color);\n",
        "  box-shadow: 0 6px 36px rgba(70, 30, 160, .07);\n",
        "  position: relative;\n",
        "  border-bottom: 1px solid var(--border-color);\n",
        "}\n",
        ".llm-title {\n",
        "  font-size: 2.1em;\n",
        "  color: var(--primary-color);\n",
        "  margin-bottom: .12em;\n",
        "  text-align: center;\n",
        "  font-weight: 700;\n",
        "  letter-spacing: 0.01em;\n",
        "}\n",
        ".llm-sub {\n",
        "  text-align: center;\n",
        "  font-size: 1.12em;\n",
        "  color: var(--secondary-color);\n",
        "  margin-bottom: 2em;\n",
        "  font-weight: 400;\n",
        "  opacity: 0.91;\n",
        "}\n",
        ".llm-h2 {\n",
        "  color: var(--secondary-color);\n",
        "  margin-top: 2.2em;\n",
        "  margin-bottom: .8em;\n",
        "  border-bottom: 2px solid var(--primary-color);\n",
        "  font-size: 1.23em;\n",
        "  font-weight: 600;\n",
        "  padding-bottom: 0.25em;\n",
        "}\n",
        ".llm-list {\n",
        "  margin-top: .8em; margin-bottom:1.6em; padding-left:30px;\n",
        "}\n",
        ".llm-list li { margin-bottom: .6em; }\n",
        ".llm-blockquote {\n",
        "  background: var(--blockquote-bg);\n",
        "  border-left: 5px solid var(--blockquote-border);\n",
        "  padding: 13px 24px 12px 24px;\n",
        "  margin: 22px 0 23px 0;\n",
        "  border-radius: 6px;\n",
        "  font-size: 1.03em;\n",
        "  color: var(--text-color);\n",
        "  opacity: 0.95;\n",
        "}\n",
        ".llm-code {\n",
        "  background: var(--code-bg);\n",
        "  color: #5b42a7;\n",
        "  font-family: 'Fira Mono', 'Consolas', monospace;\n",
        "  padding: 8px 13px;\n",
        "  border-radius: 7px;\n",
        "  font-size: 0.98em;\n",
        "  border: 1px solid var(--border-color);\n",
        "  display: inline-block;\n",
        "}\n",
        ".llm-summary {\n",
        "  background: var(--bg-color);\n",
        "  border-left: 6px solid var(--primary-color);\n",
        "  margin-top: 2.4em;\n",
        "  padding: 19px 22px 16px 22px;\n",
        "  font-size: 1.06em;\n",
        "  border-radius: 8px;\n",
        "  color: var(--text-color);\n",
        "}\n",
        ".theme-toggle {\n",
        "  background-color: var(--code-bg);\n",
        "  color: var(--primary-color);\n",
        "  border: 2px solid var(--secondary-color);\n",
        "  padding: 10px 19px;\n",
        "  border-radius: 8px;\n",
        "  cursor: pointer;\n",
        "  position: absolute;\n",
        "  top: 25px;\n",
        "  right: 27px;\n",
        "  font-size: 1.07em;\n",
        "  font-weight: 500;\n",
        "  box-shadow: 0 2px 9px rgba(80, 60, 130, .08);\n",
        "  z-index: 20;\n",
        "  transition: background .2s, color .2s, border-color .2s, transform .1s;\n",
        "}\n",
        ".theme-toggle:hover {\n",
        "  background-color: var(--secondary-color);\n",
        "  color: var(--container-bg);\n",
        "  border-color: var(--primary-color);\n",
        "  transform: translateY(-1px);\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "javascript_code = \"\"\"\n",
        "<script>\n",
        "function toggleTheme() {\n",
        "    const body = document.body;\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const isDarkMode = body.classList.toggle(\"dark-mode\");\n",
        "    localStorage.setItem(\"theme\", isDarkMode ? \"dark\" : \"light\");\n",
        "    if (themeToggleButton) {\n",
        "        themeToggleButton.textContent = isDarkMode ? \"☀️ Modo Claro\" : \"🌙 Modo Oscuro\";\n",
        "        themeToggleButton.setAttribute(\"aria-pressed\", isDarkMode ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "function applyInitialTheme() {\n",
        "    const themeToggleButton = document.getElementById(\"theme-toggle-btn\");\n",
        "    const savedTheme = localStorage.getItem(\"theme\");\n",
        "    const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
        "    let useDarkMode = false;\n",
        "    if (savedTheme) {\n",
        "        useDarkMode = savedTheme === \"dark\";\n",
        "    } else {\n",
        "        useDarkMode = prefersDark;\n",
        "    }\n",
        "    if (useDarkMode) {\n",
        "        document.body.classList.add(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"☀️ Modo Claro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"true\");\n",
        "        }\n",
        "    } else {\n",
        "        document.body.classList.remove(\"dark-mode\");\n",
        "        if (themeToggleButton) {\n",
        "             themeToggleButton.textContent = \"🌙 Modo Oscuro\";\n",
        "             themeToggleButton.setAttribute(\"aria-pressed\", \"false\");\n",
        "        }\n",
        "    }\n",
        "    if (themeToggleButton && !themeToggleButton.hasAttribute('aria-pressed')) {\n",
        "         themeToggleButton.setAttribute(\"aria-pressed\", document.body.classList.contains(\"dark-mode\") ? \"true\" : \"false\");\n",
        "    }\n",
        "}\n",
        "window.onload = applyInitialTheme;\n",
        "if (window.matchMedia) {\n",
        "    window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {\n",
        "        if (!localStorage.getItem(\"theme\")) {\n",
        "            applyInitialTheme();\n",
        "        }\n",
        "    });\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "html_content = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Presence Penalty en LLMs</title>\n",
        "{css_styles}\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"llm-container\">\n",
        "<button id=\"theme-toggle-btn\" class=\"theme-toggle\" onclick=\"toggleTheme()\" title=\"Cambiar tema de color\">🌙 Modo Oscuro</button>\n",
        "<div class=\"llm-title\">Presence Penalty en Modelos de Lenguaje</div>\n",
        "<div class=\"llm-sub\">Fomentando la inclusión y diversidad temática en la generación de texto con LLMs</div>\n",
        "\n",
        "<div class=\"llm-h2\">¿Qué es el presence penalty?</div>\n",
        "<p>\n",
        "El <b>presence penalty</b> es una técnica avanzada usada en la generación de texto con <b>modelos de lenguaje de gran tamaño</b> (LLMs), como GPT, Gemini o Llama, cuyo objetivo es <b>promover la aparición de ciertas palabras o temas</b> en el texto generado. Es particularmente útil cuando se requiere que el modelo <b>incluya conceptos, términos o nombres específicos</b> para satisfacer criterios de contenido, estilo o personalización.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-h2\">¿Cómo funciona el presence penalty?</div>\n",
        "<ul class=\"llm-list\">\n",
        "  <li>Durante la generación, el modelo evalúa la presencia previa de palabras o tokens clave en el texto generado hasta el momento.</li>\n",
        "  <li>Si una palabra no ha aparecido aún (o solo ha aparecido pocas veces), el modelo <b>aumenta la probabilidad de seleccionarla</b> en los próximos pasos, modificando los logits (valores base de predicción).</li>\n",
        "  <li>El parámetro <b>presence penalty</b> define la magnitud de este impulso: valores altos incentivan fuertemente la aparición de palabras aún no utilizadas.</li>\n",
        "  <li>Esto garantiza que el modelo “explore” más su vocabulario y cubra los temas deseados, ayudando a generar textos más completos o personalizados.</li>\n",
        "</ul>\n",
        "\n",
        "<div class=\"llm-h2\">¿En qué se diferencia del frequency penalty?</div>\n",
        "<p>\n",
        "Mientras que el <b>frequency penalty</b> penaliza la repetición excesiva de palabras ya mencionadas, el <b>presence penalty</b> actúa principalmente sobre aquellas palabras <b>que aún no han aparecido</b> en el texto. Así, ambos parámetros se complementan: uno reduce repeticiones, el otro fomenta diversidad y cobertura temática.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-h2\">Explicación matemática básica</div>\n",
        "<p>\n",
        "Al calcular la probabilidad de cada token candidato, el modelo puede ajustar así su logit:\n",
        "</p>\n",
        "<div class=\"llm-code\">\n",
        "logit_nuevo(token) = logit_original(token) - (presence_penalty × presencia(token_en_texto))\n",
        "</div>\n",
        "<ul class=\"llm-list\">\n",
        "  <li><b>presence_penalty</b>: valor configurable por el usuario, normalmente entre 0 y 2.</li>\n",
        "  <li><b>presencia(token_en_texto)</b>: indicador (0 si no apareció, 1 o más si ya apareció).</li>\n",
        "</ul>\n",
        "<p>\n",
        "Por ejemplo, si queremos asegurar la inclusión de la palabra “sostenibilidad” y aún no ha aparecido, el modelo la verá como una opción “fresca” y elevará su probabilidad relativa para que sea más fácil que la elija en los siguientes pasos.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-blockquote\">\n",
        "<b>Ejemplo conceptual:</b><br>\n",
        "<strong>Sin penalización de presencia:</strong>\n",
        "“La inteligencia artificial transforma la educación y la medicina.”<br>\n",
        "<strong>Con penalización de presencia sobre “inclusión” y “diversidad”:</strong><br>\n",
        "“La inteligencia artificial promueve la <b>inclusión</b> y la <b>diversidad</b> en la educación y la medicina.”\n",
        "</div>\n",
        "\n",
        "<div class=\"llm-h2\">¿Para qué sirve en la práctica?</div>\n",
        "<ul class=\"llm-list\">\n",
        "<li><b>Personalización de respuestas:</b> Obliga al modelo a tocar temas, nombres, lugares o conceptos clave (por ejemplo, en generación de resúmenes, informes o textos temáticos).</li>\n",
        "<li><b>Control de estilo o tono:</b> Facilita que el texto generado cumpla requisitos de branding, narrativa, enfoque o compliance.</li>\n",
        "<li><b>Generación de textos completos:</b> Evita omisiones y fomenta que el modelo cubra todos los puntos requeridos en la consigna.</li>\n",
        "<li><b>IA conversacional avanzada:</b> Asegura que el chatbot o asistente incluya mensajes clave del negocio.</li>\n",
        "</ul>\n",
        "\n",
        "<div class=\"llm-h2\">Uso en frameworks y ejemplos de código</div>\n",
        "<p>\n",
        "Tanto <b>Hugging Face</b> como <b>OpenAI</b> y otros frameworks modernos admiten el uso de <b>presence_penalty</b> en la generación de texto:\n",
        "</p>\n",
        "<div class=\"llm-code\">\n",
        "output = model.generate(\n",
        "    prompt=\"Describe el impacto de la IA en la sociedad.\",\n",
        "    max_new_tokens=60,\n",
        "    presence_penalty=1.2,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95\n",
        ")\n",
        "</div>\n",
        "<p>\n",
        "Ajustando este parámetro puedes guiar a los LLMs para que mencionen explícitamente ideas, conceptos o vocabulario de interés en las respuestas.\n",
        "</p>\n",
        "\n",
        "<div class=\"llm-summary\">\n",
        "<b>En resumen:</b><br>\n",
        "La penalización de presencia (<b>presence penalty</b>) es una herramienta clave para guiar, enriquecer y personalizar la generación de texto automática con LLMs, permitiendo que los modelos incluyan de forma controlada los términos, ideas o estilos que el usuario considera fundamentales.\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top:18px; font-size:1em; color:#8475b1;\">\n",
        "<i>¿Sabías que los chatbots de empresas líderes y generadores de contenido automático usan <b>presence penalty</b> para cumplir requisitos de compliance, branding o experiencia de usuario personalizada? ¡Experimenta ajustando este parámetro para ver el impacto en tus propios proyectos!</i>\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "{javascript_code}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_content))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "383ffbf8a4194ba299d7aec0f384bdf5",
            "967a90ee97c4426ca316c227193d5431",
            "b9045c94b32245a39bba713fd31fb49f",
            "618e7243bf1941c98f6d3cbda23259f7",
            "d625c6c1a7ea446fa4eb6aca15abbfb7",
            "094411ddc09d4689a56e2725ef74c9bb",
            "af5fae887b0f4e80895f9fe68e55a67a",
            "bbc9e7302163478dafdcc04e01cd66ad",
            "4c99c5c6a6924f7b8799799016ea5be4",
            "80df98d71d034621bdcf1949cf5cf568",
            "55a2adf6c5244ec58fb5d74c3570628d",
            "4c9386238a274fd991f4ee58858bb003",
            "4c79c5782af84c559f598b72d755e76e",
            "ede0175dd50e4ba98e020c91089b5d40",
            "fd72ad1ad32e4a3999cba4a98e2c7bea",
            "5fa21ebb10284c55aebffe1f24f06e18",
            "0767b4bee7cb4a39afeb21c8bdf1fce3",
            "e617d595913d4e64b1c591f32db64a06",
            "1b4af8e63e9d4f4e9c99b32f520c531c",
            "55b90d87adb548368e03730616ea7e4c",
            "f7cc8366a0514ab6b4a8fc2be4284abe",
            "7b529ec5255040acb5e2115a246a870e",
            "7f32158ab25a40e2a201d6eefd5cc846",
            "3b4c4789a24b4a1c97de3e1985506cd5",
            "04b97afa6e6a4f8c872e16dee4263279",
            "e20133045a904c6ea4b6a0dda85a78f2",
            "4d8339e8794a487c9bd5b5ad52bef204",
            "d0b35f1adddf456e8be99b8d9ed961c7"
          ]
        },
        "id": "mMwu6MEkwQ42",
        "outputId": "6cdd3194-b305-42f3-ce5c-cb94f92221b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "383ffbf8a4194ba299d7aec0f384bdf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(VBox(children=(HTML(value='<h2>Panel de Control de Promoción de Palabras</h2>'), SelectMultiple…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Setup: Importar librerías necesarias\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import Counter\n",
        "import numpy as np # Para np.random.choice si se prefiere\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### 1. Configuración Inicial de Palabras\n",
        "#@markdown Define tu lista de palabras iniciales, separadas por comas.\n",
        "initial_words_str = \"manzana, banana, cereza, d\\xE1til, higo, uva, kiwi, lim\\xF3n, mango, naranja\" #@param {type:\"string\"}\n",
        "#@markdown Define el peso base para todas las palabras (antes de la promoción).\n",
        "base_weight = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "# Convertir la cadena de palabras a una lista\n",
        "initial_words = [word.strip() for word in initial_words_str.split(',') if word.strip()]\n",
        "\n",
        "# Validar que haya palabras\n",
        "if not initial_words:\n",
        "    print(\"Error: Por favor, ingresa al menos una palabra en 'Configuración Inicial de Palabras'.\")\n",
        "    # Detener la ejecución si no hay palabras para evitar errores posteriores.\n",
        "    # En Colab, esto no detendrá el script completo, pero sí la lógica principal.\n",
        "    # Podrías usar raise Exception(\"...\") si quieres una detención más abrupta.\n",
        "    initial_words = [\"ejemplo_palabra_1\", \"ejemplo_palabra_2\"] # Fallback\n",
        "    print(f\"Usando palabras de ejemplo: {initial_words}\")\n",
        "\n",
        "# Inicializar pesos: un diccionario palabra -> peso\n",
        "word_weights = {word: float(base_weight) for word in initial_words}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### 2. Parámetros de Interacción y Visualización\n",
        "#@markdown Factor por el cual se multiplicará el peso de las palabras promovidas.\n",
        "promotion_factor_default = 5.0 #@param {type:\"slider\", min:1.1, max:20, step:0.1}\n",
        "#@markdown Número de palabras a muestrear cuando se presione el botón \"Muestrear\".\n",
        "num_samples_default = 100 #@param {type:\"integer\"}\n",
        "\n",
        "# --- Widgets para la Interacción ---\n",
        "\n",
        "# Selector múltiple para elegir palabras a promover\n",
        "word_selector = widgets.SelectMultiple(\n",
        "    options=initial_words,\n",
        "    value=[], # Inicialmente ninguna palabra promovida\n",
        "    description='Promover:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='auto', height='150px') # Ajustar tamaño\n",
        ")\n",
        "\n",
        "# Slider para el factor de promoción\n",
        "promotion_slider = widgets.FloatSlider(\n",
        "    value=promotion_factor_default,\n",
        "    min=1.0, # Mínimo 1 (sin promoción)\n",
        "    max=20.0,\n",
        "    step=0.1,\n",
        "    description='Factor Promoción:',\n",
        "    continuous_update=False # Actualizar solo al soltar el slider\n",
        ")\n",
        "\n",
        "# Botón para muestrear\n",
        "sample_button = widgets.Button(\n",
        "    description=f\"Muestrear {num_samples_default} Palabras\",\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip=f'Haz clic para seleccionar {num_samples_default} palabras según las probabilidades actuales'\n",
        ")\n",
        "\n",
        "# Output widget para el gráfico\n",
        "plot_output = widgets.Output()\n",
        "# Output widget para los resultados del muestreo\n",
        "sample_output = widgets.Output()\n",
        "\n",
        "\n",
        "# --- Lógica de Cálculo y Actualización ---\n",
        "\n",
        "def calculate_probabilities(current_weights_dict):\n",
        "    \"\"\"Calcula las probabilidades basadas en los pesos.\"\"\"\n",
        "    total_weight = sum(current_weights_dict.values())\n",
        "    if total_weight == 0:\n",
        "        # Si todos los pesos son cero, asigna probabilidad uniforme (o cero)\n",
        "        num_words = len(current_weights_dict)\n",
        "        return {word: 1/num_words if num_words > 0 else 0.0 for word in current_weights_dict}\n",
        "\n",
        "    probabilities = {word: weight / total_weight for word, weight in current_weights_dict.items()}\n",
        "    return probabilities\n",
        "\n",
        "def update_visualization_and_probabilities(change=None):\n",
        "    \"\"\"Actualiza los pesos, calcula probabilidades y redibuja el gráfico.\"\"\"\n",
        "    promoted_words_selected = word_selector.value\n",
        "    current_promotion_factor = promotion_slider.value\n",
        "\n",
        "    # Reiniciar pesos al base_weight\n",
        "    current_weights = {word: float(base_weight) for word in initial_words}\n",
        "\n",
        "    # Aplicar promoción\n",
        "    for word in promoted_words_selected:\n",
        "        if word in current_weights: # Asegurarse que la palabra aún existe\n",
        "            current_weights[word] *= current_promotion_factor\n",
        "\n",
        "    probabilities = calculate_probabilities(current_weights)\n",
        "\n",
        "    # Actualizar el estado global para el muestreo (opcional, pero útil)\n",
        "    # Podríamos pasar esto como argumento, pero para un script de Colab así es más simple.\n",
        "    # Usaremos un atributo en un objeto global simple para evitar 'global' explícito en funciones anidadas\n",
        "    if not hasattr(update_visualization_and_probabilities, 'current_probabilities_dict'):\n",
        "        update_visualization_and_probabilities.current_probabilities_dict = {}\n",
        "    update_visualization_and_probabilities.current_probabilities_dict = probabilities\n",
        "\n",
        "    with plot_output:\n",
        "        clear_output(wait=True) # Limpiar el output anterior antes de dibujar\n",
        "        if not probabilities:\n",
        "            print(\"No hay palabras o probabilidades para mostrar.\")\n",
        "            return\n",
        "\n",
        "        words = list(probabilities.keys())\n",
        "        probs = list(probabilities.values())\n",
        "\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        bars = plt.bar(words, probs, color=['skyblue' if word not in promoted_words_selected else 'salmon' for word in words])\n",
        "\n",
        "        plt.xlabel(\"Palabras\", fontsize=14)\n",
        "        plt.ylabel(\"Probabilidad de Selección\", fontsize=14)\n",
        "        plt.title(f\"Probabilidad de Selección (Promoción x{current_promotion_factor:.1f})\", fontsize=16)\n",
        "        plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
        "        plt.yticks(fontsize=10)\n",
        "        plt.ylim(0, max(probs) * 1.15 if probs else 0.1) # Ajustar límite Y dinámicamente, con un mínimo\n",
        "\n",
        "        # Añadir texto de probabilidad encima de cada barra\n",
        "        for bar in bars:\n",
        "            yval = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.005, f\"{yval:.2%}\", ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout() # Ajusta el plot para que todo quepa bien\n",
        "        plt.show()\n",
        "\n",
        "def on_sample_button_clicked(b):\n",
        "    \"\"\"Maneja el evento de clic del botón de muestreo.\"\"\"\n",
        "    with sample_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Obtener las probabilidades actuales\n",
        "        # Asegurarse de que 'current_probabilities_dict' exista y no esté vacío.\n",
        "        if not hasattr(update_visualization_and_probabilities, 'current_probabilities_dict') or \\\n",
        "           not update_visualization_and_probabilities.current_probabilities_dict:\n",
        "            print(\"No hay probabilidades calculadas. Por favor, ajusta los parámetros primero.\")\n",
        "            # Forzar una actualización si es la primera vez\n",
        "            update_visualization_and_probabilities()\n",
        "            # Si sigue vacío, salir\n",
        "            if not update_visualization_and_probabilities.current_probabilities_dict:\n",
        "                 return\n",
        "\n",
        "\n",
        "        probabilities_dict = update_visualization_and_probabilities.current_probabilities_dict\n",
        "\n",
        "        words_list = list(probabilities_dict.keys())\n",
        "        probs_list = list(probabilities_dict.values())\n",
        "\n",
        "        # Verificar si la suma de probabilidades es válida para np.random.choice o random.choices\n",
        "        if not words_list or abs(sum(probs_list) - 1.0) > 1e-5 and sum(probs_list) != 0:\n",
        "             # Si la suma no es 1 (y no es 0), podría haber un problema.\n",
        "             # random.choices lo normaliza internamente, pero es bueno estar al tanto.\n",
        "             # np.random.choice requiere que sumen 1, o lanzará error.\n",
        "             if sum(probs_list) == 0:\n",
        "                print(\"No se pueden muestrear palabras, todas las probabilidades son cero.\")\n",
        "                return\n",
        "             print(f\"Advertencia: La suma de probabilidades es {sum(probs_list):.4f}, se normalizará para el muestreo.\")\n",
        "        elif sum(probs_list) == 0 and len(words_list) > 0:\n",
        "             print(\"No se pueden muestrear palabras, todas las probabilidades son cero.\")\n",
        "             return\n",
        "        elif not words_list:\n",
        "            print(\"No hay palabras para muestrear.\")\n",
        "            return\n",
        "\n",
        "\n",
        "        # Usar random.choices (Python 3.6+) que maneja pesos no normalizados\n",
        "        try:\n",
        "            # Asegurar que num_samples_default sea un entero positivo\n",
        "            num_to_sample = max(1, int(num_samples_default))\n",
        "            sampled_words = random.choices(words_list, weights=probs_list, k=num_to_sample)\n",
        "        except ValueError as e:\n",
        "            # Esto podría pasar si todos los pesos son 0, o la lista de palabras está vacía.\n",
        "            print(f\"Error durante el muestreo: {e}\")\n",
        "            print(f\"Palabras: {words_list}, Pesos/Probabilidades: {probs_list}\")\n",
        "            return\n",
        "\n",
        "\n",
        "        # Contar la frecuencia de las palabras muestreadas\n",
        "        word_counts = Counter(sampled_words)\n",
        "\n",
        "        print(f\"--- Muestra de {num_to_sample} Palabras ({len(word_counts)} únicas) ---\")\n",
        "        # Ordenar por frecuencia descendente\n",
        "        for word, count in word_counts.most_common():\n",
        "            percentage = (count / num_to_sample) * 100\n",
        "            original_prob = probabilities_dict.get(word, 0) * 100\n",
        "            print(f\"- {word}: {count} veces ({percentage:.1f}%) (Prob. teórica: {original_prob:.1f}%)\")\n",
        "\n",
        "        # También se podría mostrar un pequeño gráfico de barras del muestreo si se desea\n",
        "        # plt.figure(figsize=(8,5))\n",
        "        # plt.bar(word_counts.keys(), word_counts.values(), color='lightgreen')\n",
        "        # plt.title(\"Distribución de Palabras Muestreadas\")\n",
        "        # plt.xticks(rotation=45, ha=\"right\")\n",
        "        # plt.tight_layout()\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "# --- Conectar Widgets a Funciones ---\n",
        "# .observe() se usa para ejecutar una función cuando el 'value' de un widget cambia.\n",
        "word_selector.observe(update_visualization_and_probabilities, names='value')\n",
        "promotion_slider.observe(update_visualization_and_probabilities, names='value')\n",
        "sample_button.on_click(on_sample_button_clicked)\n",
        "\n",
        "\n",
        "# --- Mostrar la Interfaz ---\n",
        "# Organizar los widgets para una mejor presentación usando VBox y HBox\n",
        "# Controles en la parte superior\n",
        "controls_box = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>Panel de Control de Promoción de Palabras</h2>\"),\n",
        "    word_selector,\n",
        "    promotion_slider\n",
        "])\n",
        "\n",
        "# Sección de muestreo\n",
        "sampling_box = widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Muestreo Basado en Probabilidades</h3>\"),\n",
        "    sample_button,\n",
        "    sample_output\n",
        "])\n",
        "\n",
        "# Layout final\n",
        "ui = widgets.VBox([\n",
        "    controls_box,\n",
        "    plot_output, # El gráfico se mostrará aquí\n",
        "    widgets.HTML(\"<hr>\"), # Separador\n",
        "    sampling_box\n",
        "])\n",
        "\n",
        "# Validar si estamos en un entorno que puede mostrar widgets (como Colab o Jupyter)\n",
        "try:\n",
        "    get_ipython() # Intenta obtener el intérprete de IPython\n",
        "    # Mostrar la UI\n",
        "    display(ui)\n",
        "    # Llamar una vez para la visualización inicial\n",
        "    update_visualization_and_probabilities()\n",
        "except NameError:\n",
        "    print(\"Este script está diseñado para ejecutarse en un entorno IPython/Jupyter/Colab.\")\n",
        "    print(\"No se pueden mostrar los widgets interactivos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gGdq4lcY8P2x",
        "outputId": "91c6b3f2-7b94-465f-984a-4911c26f68a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "  <meta charset=\"UTF-8\">\n",
              "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "  <title>Glosario de Términos - Clase II: Conceptos LLM</title>\n",
              "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
              "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
              "  <style>\n",
              "    :root {\n",
              "      /* Tema claro */\n",
              "      --bg-primary: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
              "      --bg-secondary: #ffffff;\n",
              "      --bg-tertiary: #f8fafc;\n",
              "      --bg-quaternary: #f1f5f9;\n",
              "      --text-primary: #1e293b;\n",
              "      --text-secondary: #64748b;\n",
              "      --text-accent: #3b82f6;\n",
              "      --border-color: #e2e8f0;\n",
              "      --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n",
              "      --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);\n",
              "      --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);\n",
              "      --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);\n",
              "\n",
              "      --color-blue: #3b82f6;\n",
              "      --color-emerald: #10b981;\n",
              "      --color-purple: #8b5cf6;\n",
              "      --color-rose: #f43f5e;\n",
              "      --color-amber: #f59e0b;\n",
              "      --color-indigo: #6366f1;\n",
              "      --color-cyan: #06b6d4;\n",
              "    }\n",
              "\n",
              "    [data-theme=\"dark\"] {\n",
              "      --bg-primary: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);\n",
              "      --bg-secondary: #1e293b;\n",
              "      --bg-tertiary: #334155;\n",
              "      --bg-quaternary: #475569;\n",
              "      --text-primary: #f1f5f9;\n",
              "      --text-secondary: #94a3b8;\n",
              "      --text-accent: #60a5fa;\n",
              "      --border-color: #475569;\n",
              "      --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.3);\n",
              "      --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.3), 0 2px 4px -2px rgb(0 0 0 / 0.3);\n",
              "      --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.3), 0 4px 6px -4px rgb(0 0 0 / 0.3);\n",
              "      --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.3), 0 8px 10px -6px rgb(0 0 0 / 0.3);\n",
              "    }\n",
              "\n",
              "    * {\n",
              "      margin: 0;\n",
              "      padding: 0;\n",
              "      box-sizing: border-box;\n",
              "    }\n",
              "\n",
              "    html {\n",
              "        scroll-behavior: smooth;\n",
              "    }\n",
              "\n",
              "    body {\n",
              "      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
              "      line-height: 1.7;\n",
              "      background: var(--bg-primary);\n",
              "      color: var(--text-primary);\n",
              "      min-height: 100vh;\n",
              "      overflow-x: hidden;\n",
              "      transition: background 0.3s ease, color 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .container {\n",
              "      max-width: 1200px;\n",
              "      margin: 0 auto;\n",
              "      padding: 2rem;\n",
              "      position: relative;\n",
              "    }\n",
              "\n",
              "    .header {\n",
              "      text-align: center;\n",
              "      margin-bottom: 3rem;\n",
              "      position: relative;\n",
              "      z-index: 10;\n",
              "    }\n",
              "\n",
              "    .header::before {\n",
              "      content: '';\n",
              "      position: absolute;\n",
              "      top: -50px;\n",
              "      left: 50%;\n",
              "      transform: translateX(-50%);\n",
              "      width: 120px;\n",
              "      height: 120px;\n",
              "      background: var(--color-purple);\n",
              "      border-radius: 50%;\n",
              "      opacity: 0.1;\n",
              "      animation: pulse 3s ease-in-out infinite;\n",
              "    }\n",
              "\n",
              "    @keyframes pulse {\n",
              "      0%, 100% { transform: translateX(-50%) scale(1); opacity: 0.1; }\n",
              "      50% { transform: translateX(-50%) scale(1.2); opacity: 0.2; }\n",
              "    }\n",
              "\n",
              "    .main-title {\n",
              "      font-size: clamp(2.5rem, 5vw, 3.5rem);\n",
              "      font-weight: 700;\n",
              "      background: linear-gradient(135deg, var(--color-purple), var(--color-indigo));\n",
              "      -webkit-background-clip: text;\n",
              "      -webkit-text-fill-color: transparent;\n",
              "      background-clip: text;\n",
              "      margin-bottom: 0.5rem;\n",
              "      position: relative;\n",
              "    }\n",
              "\n",
              "    .subtitle {\n",
              "      font-size: 1.25rem;\n",
              "      color: var(--text-secondary);\n",
              "      font-weight: 400;\n",
              "      max-width: 600px;\n",
              "      margin: 0 auto 1.5rem auto;\n",
              "    }\n",
              "\n",
              "    .academic-info {\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      justify-content: center;\n",
              "      flex-wrap: wrap;\n",
              "      gap: 1rem;\n",
              "      font-size: 0.95rem;\n",
              "      color: var(--text-secondary);\n",
              "      background: var(--bg-secondary);\n",
              "      padding: 1rem 1.5rem;\n",
              "      border-radius: 1rem;\n",
              "      border: 1px solid var(--border-color);\n",
              "      box-shadow: var(--shadow-sm);\n",
              "      max-width: fit-content;\n",
              "      margin: 0 auto;\n",
              "      transition: all 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .academic-info:hover {\n",
              "      transform: translateY(-2px);\n",
              "      box-shadow: var(--shadow-md);\n",
              "      border-color: var(--text-accent);\n",
              "    }\n",
              "\n",
              "    .academic-badge {\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      gap: 0.5rem;\n",
              "      padding: 0.5rem 0.75rem;\n",
              "      background: var(--bg-tertiary);\n",
              "      border-radius: 0.5rem;\n",
              "      border: 1px solid var(--border-color);\n",
              "      font-weight: 500;\n",
              "    }\n",
              "\n",
              "    .academic-badge i {\n",
              "      color: var(--text-accent);\n",
              "      font-size: 0.9rem;\n",
              "    }\n",
              "\n",
              "    .academic-badge strong {\n",
              "      color: var(--text-primary);\n",
              "    }\n",
              "\n",
              "    .theme-toggle {\n",
              "      position: fixed;\n",
              "      top: 2rem;\n",
              "      right: 2rem;\n",
              "      width: 60px;\n",
              "      height: 60px;\n",
              "      border: 2px solid var(--border-color);\n",
              "      border-radius: 50%;\n",
              "      background: var(--bg-secondary);\n",
              "      box-shadow: var(--shadow-lg);\n",
              "      cursor: pointer;\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      justify-content: center;\n",
              "      font-size: 1.5rem;\n",
              "      color: var(--text-primary);\n",
              "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
              "      z-index: 1000;\n",
              "      backdrop-filter: blur(10px);\n",
              "    }\n",
              "\n",
              "    .theme-toggle:hover {\n",
              "      transform: translateY(-2px) scale(1.05);\n",
              "      box-shadow: var(--shadow-xl);\n",
              "      background: var(--text-accent);\n",
              "      color: white;\n",
              "    }\n",
              "\n",
              "    .theme-toggle:active {\n",
              "      transform: translateY(0) scale(0.95);\n",
              "    }\n",
              "\n",
              "    .theme-icon {\n",
              "      transition: all 0.3s ease;\n",
              "      position: absolute;\n",
              "    }\n",
              "\n",
              "    .theme-toggle .fa-sun {\n",
              "      opacity: 0;\n",
              "      transform: rotate(-90deg) scale(0.5);\n",
              "    }\n",
              "\n",
              "    .theme-toggle .fa-moon {\n",
              "      opacity: 1;\n",
              "      transform: rotate(0deg) scale(1);\n",
              "    }\n",
              "\n",
              "    [data-theme=\"dark\"] .theme-toggle .fa-moon {\n",
              "      opacity: 0;\n",
              "      transform: rotate(90deg) scale(0.5);\n",
              "    }\n",
              "\n",
              "    [data-theme=\"dark\"] .theme-toggle .fa-sun {\n",
              "      opacity: 1;\n",
              "      transform: rotate(0deg) scale(1);\n",
              "    }\n",
              "\n",
              "    .stats-container {\n",
              "      display: grid;\n",
              "      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
              "      gap: 1rem;\n",
              "      margin-bottom: 2rem;\n",
              "    }\n",
              "\n",
              "    .stat-card {\n",
              "      background: var(--bg-secondary);\n",
              "      padding: 1.5rem;\n",
              "      border-radius: 1rem;\n",
              "      border: 1px solid var(--border-color);\n",
              "      box-shadow: var(--shadow-sm);\n",
              "      text-align: center;\n",
              "      transition: all 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .stat-card:hover {\n",
              "      transform: translateY(-2px);\n",
              "      box-shadow: var(--shadow-md);\n",
              "    }\n",
              "\n",
              "    .stat-number {\n",
              "      font-size: 2rem;\n",
              "      font-weight: 700;\n",
              "      color: var(--color-purple);\n",
              "      display: block;\n",
              "    }\n",
              "\n",
              "    .stat-label {\n",
              "      font-size: 0.9rem;\n",
              "      color: var(--text-secondary);\n",
              "      margin-top: 0.5rem;\n",
              "    }\n",
              "\n",
              "    .search-container {\n",
              "      margin-bottom: 2rem;\n",
              "      position: relative;\n",
              "      max-width: 500px;\n",
              "      margin-left: auto;\n",
              "      margin-right: auto;\n",
              "    }\n",
              "\n",
              "    .search-input {\n",
              "      width: 100%;\n",
              "      padding: 1rem 1rem 1rem 3rem;\n",
              "      font-size: 1rem;\n",
              "      border: 2px solid var(--border-color);\n",
              "      border-radius: 2rem;\n",
              "      background: var(--bg-secondary);\n",
              "      color: var(--text-primary);\n",
              "      transition: all 0.3s ease;\n",
              "      outline: none;\n",
              "    }\n",
              "\n",
              "    .search-input:focus {\n",
              "      border-color: var(--color-purple);\n",
              "      box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.1);\n",
              "      transform: translateY(-1px);\n",
              "    }\n",
              "\n",
              "    .search-icon {\n",
              "      position: absolute;\n",
              "      left: 1.25rem;\n",
              "      top: 50%;\n",
              "      transform: translateY(-50%);\n",
              "      color: var(--text-secondary);\n",
              "      font-size: 1rem;\n",
              "      transition: color 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .search-input:focus + .search-icon {\n",
              "      color: var(--color-purple);\n",
              "    }\n",
              "\n",
              "    .alphabet-filter {\n",
              "      display: flex;\n",
              "      justify-content: center;\n",
              "      flex-wrap: wrap;\n",
              "      gap: 0.5rem;\n",
              "      margin-bottom: 2rem;\n",
              "      padding: 1.5rem;\n",
              "      background: var(--bg-secondary);\n",
              "      border-radius: 1rem;\n",
              "      box-shadow: var(--shadow-md);\n",
              "      border: 1px solid var(--border-color);\n",
              "    }\n",
              "\n",
              "    .letter-btn {\n",
              "      width: 40px;\n",
              "      height: 40px;\n",
              "      border: 1px solid var(--border-color);\n",
              "      border-radius: 50%;\n",
              "      background: var(--bg-tertiary);\n",
              "      color: var(--text-secondary);\n",
              "      font-weight: 500;\n",
              "      cursor: pointer;\n",
              "      transition: all 0.3s ease;\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      justify-content: center;\n",
              "    }\n",
              "\n",
              "    .letter-btn:hover {\n",
              "      background: var(--color-purple);\n",
              "      color: white;\n",
              "      transform: translateY(-2px);\n",
              "      box-shadow: var(--shadow-md);\n",
              "      border-color: var(--color-purple);\n",
              "    }\n",
              "\n",
              "    .letter-btn.active {\n",
              "      background: var(--color-purple);\n",
              "      color: white;\n",
              "      border-color: var(--color-purple);\n",
              "      box-shadow: var(--shadow-md);\n",
              "    }\n",
              "\n",
              "    .clear-filter {\n",
              "      padding: 0.5rem 1rem;\n",
              "      background: var(--color-rose);\n",
              "      color: white;\n",
              "      border: none;\n",
              "      border-radius: 1rem;\n",
              "      font-size: 0.9rem;\n",
              "      cursor: pointer;\n",
              "      transition: all 0.3s ease;\n",
              "      font-weight: 500;\n",
              "      display: inline-flex;\n",
              "      align-items: center;\n",
              "      gap: 0.3rem;\n",
              "    }\n",
              "\n",
              "    .clear-filter:hover {\n",
              "      background: #dc2626;\n",
              "      transform: translateY(-1px);\n",
              "      box-shadow: var(--shadow-sm);\n",
              "    }\n",
              "\n",
              "    .term-counter {\n",
              "      text-align: center;\n",
              "      margin-bottom: 1.5rem;\n",
              "      padding: 0.75rem 1.5rem;\n",
              "      background: var(--bg-secondary);\n",
              "      border-radius: 2rem;\n",
              "      border: 1px solid var(--border-color);\n",
              "      color: var(--text-secondary);\n",
              "      font-size: 0.95rem;\n",
              "      font-weight: 500;\n",
              "      max-width: fit-content;\n",
              "      margin-left: auto;\n",
              "      margin-right: auto;\n",
              "      box-shadow: var(--shadow-sm);\n",
              "      display: inline-flex;\n",
              "      align-items: center;\n",
              "      gap: 0.5rem;\n",
              "    }\n",
              "\n",
              "    .glossary-grid {\n",
              "      display: grid;\n",
              "      grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));\n",
              "      gap: 1.5rem;\n",
              "      margin-top: 2rem;\n",
              "    }\n",
              "\n",
              "    .term-card {\n",
              "      background: var(--bg-secondary);\n",
              "      border-radius: 1rem;\n",
              "      padding: 1.5rem;\n",
              "      box-shadow: var(--shadow-md);\n",
              "      border: 1px solid var(--border-color);\n",
              "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
              "      position: relative;\n",
              "      overflow: hidden;\n",
              "    }\n",
              "\n",
              "    .term-card::before {\n",
              "      content: '';\n",
              "      position: absolute;\n",
              "      top: 0;\n",
              "      left: 0;\n",
              "      width: 4px;\n",
              "      height: 100%;\n",
              "      background: linear-gradient(45deg, var(--color-purple), var(--color-indigo));\n",
              "      transition: width 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .term-card:hover {\n",
              "      transform: translateY(-4px);\n",
              "      box-shadow: var(--shadow-xl);\n",
              "      border-color: var(--color-purple);\n",
              "    }\n",
              "\n",
              "    .term-card:hover::before {\n",
              "      width: 8px;\n",
              "    }\n",
              "\n",
              "    .term-name {\n",
              "      font-size: 1.25rem;\n",
              "      font-weight: 600;\n",
              "      color: var(--color-purple);\n",
              "      margin-bottom: 0.75rem;\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      gap: 0.5rem;\n",
              "    }\n",
              "\n",
              "    .term-icon {\n",
              "      font-size: 1rem;\n",
              "      color: var(--color-indigo);\n",
              "      flex-shrink: 0;\n",
              "    }\n",
              "\n",
              "    .term-definition {\n",
              "      color: var(--text-primary);\n",
              "      line-height: 1.8;\n",
              "      font-size: 0.95rem;\n",
              "    }\n",
              "\n",
              "    .term-category {\n",
              "      position: absolute;\n",
              "      top: 1rem;\n",
              "      right: 1rem;\n",
              "      padding: 0.25rem 0.75rem;\n",
              "      background: var(--color-amber);\n",
              "      color: white;\n",
              "      font-size: 0.75rem;\n",
              "      font-weight: 500;\n",
              "      border-radius: 1rem;\n",
              "      text-transform: uppercase;\n",
              "      letter-spacing: 0.5px;\n",
              "      box-shadow: var(--shadow-sm);\n",
              "    }\n",
              "\n",
              "    .floating-shapes {\n",
              "      position: fixed;\n",
              "      top: 0;\n",
              "      left: 0;\n",
              "      width: 100%;\n",
              "      height: 100%;\n",
              "      pointer-events: none;\n",
              "      z-index: -1;\n",
              "      overflow: hidden;\n",
              "    }\n",
              "\n",
              "    .shape {\n",
              "      position: absolute;\n",
              "      border-radius: 50%;\n",
              "      opacity: 0.03;\n",
              "      animation: float 8s ease-in-out infinite;\n",
              "      backdrop-filter: blur(1px);\n",
              "    }\n",
              "\n",
              "    .shape:nth-child(1) { width: 100px; height: 100px; top: 20%; left: 10%; background: var(--color-purple); animation-delay: 0s; }\n",
              "    .shape:nth-child(2) { width: 150px; height: 150px; top: 60%; right: 15%; background: var(--color-indigo); animation-delay: 2s; }\n",
              "    .shape:nth-child(3) { width: 80px; height: 80px; bottom: 20%; left: 20%; background: var(--color-cyan); animation-delay: 4s; }\n",
              "    .shape:nth-child(4) { width: 120px; height: 120px; top: 40%; right: 40%; background: var(--color-emerald); animation-delay: 6s; }\n",
              "\n",
              "    @keyframes float {\n",
              "      0%, 100% { transform: translateY(0) rotate(0deg); }\n",
              "      25% { transform: translateY(-30px) rotate(90deg); }\n",
              "      50% { transform: translateY(-20px) rotate(180deg); }\n",
              "      75% { transform: translateY(-40px) rotate(270deg); }\n",
              "    }\n",
              "\n",
              "    .term-card.hidden { display: none; }\n",
              "    .term-card.visible { display: block; animation: fadeInCard 0.5s ease forwards; }\n",
              "\n",
              "    @keyframes fadeInCard {\n",
              "      from { opacity: 0; transform: translateY(10px); }\n",
              "      to { opacity: 1; transform: translateY(0); }\n",
              "    }\n",
              "\n",
              "    .no-results {\n",
              "      text-align: center;\n",
              "      padding: 3rem;\n",
              "      color: var(--text-secondary);\n",
              "      font-size: 1.1rem;\n",
              "      grid-column: 1 / -1;\n",
              "      background: var(--bg-secondary);\n",
              "      border-radius: 1rem;\n",
              "      border: 2px dashed var(--border-color);\n",
              "      display: flex;\n",
              "      flex-direction: column;\n",
              "      align-items: center;\n",
              "      justify-content: center;\n",
              "    }\n",
              "    .no-results i { font-size: 3rem; margin-bottom: 1rem; color: var(--color-purple); opacity: 0.3; }\n",
              "\n",
              "    @media (max-width: 768px) {\n",
              "      .container { padding: 1rem; }\n",
              "      .glossary-grid { grid-template-columns: 1fr; gap: 1rem; }\n",
              "      .alphabet-filter { padding: 1rem; gap: 0.25rem; }\n",
              "      .letter-btn { width: 35px; height: 35px; font-size: 0.9rem; }\n",
              "      .theme-toggle { width: 50px; height: 50px; top: 1rem; right: 1rem; font-size: 1.25rem; }\n",
              "      .main-title { font-size: 2rem; }\n",
              "      .stats-container { grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); }\n",
              "      .academic-info { flex-direction: column; align-items: stretch; }\n",
              "      .academic-badge { justify-content: center; }\n",
              "    }\n",
              "\n",
              "    .fade-in { opacity: 0; transform: translateY(20px); animation: fadeInUp 0.6s ease forwards; }\n",
              "    .term-card.fade-in { animation: fadeInUp 0.6s ease forwards; animation-delay: calc(var(--card-index) * 0.05s); }\n",
              "\n",
              "    @keyframes fadeInUp { to { opacity: 1; transform: translateY(0); } }\n",
              "\n",
              "    ::-webkit-scrollbar { width: 8px; }\n",
              "    ::-webkit-scrollbar-track { background: var(--bg-tertiary); border-radius: 4px; }\n",
              "    ::-webkit-scrollbar-thumb { background: var(--text-secondary); border-radius: 4px; transition: background 0.3s ease; }\n",
              "    ::-webkit-scrollbar-thumb:hover { background: var(--text-primary); }\n",
              "  </style>\n",
              "</head>\n",
              "<body data-theme=\"light\">\n",
              "  <div class=\"floating-shapes\">\n",
              "    <div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div>\n",
              "  </div>\n",
              "\n",
              "  <button class=\"theme-toggle\" id=\"themeToggleButton\" title=\"Cambiar tema\" aria-label=\"Cambiar tema\">\n",
              "    <i class=\"fas fa-moon theme-icon\"></i>\n",
              "    <i class=\"fas fa-sun theme-icon\"></i>\n",
              "  </button>\n",
              "\n",
              "  <div class=\"container\">\n",
              "    <header class=\"header\">\n",
              "      <h1 class=\"main-title fade-in\">Glosario de Términos</h1>\n",
              "      <p class=\"subtitle fade-in\">Clase II: Conceptos LLM</p>\n",
              "\n",
              "      <div class=\"academic-info fade-in\">\n",
              "        <div class=\"academic-badge\">\n",
              "          <i class=\"fas fa-graduation-cap\"></i>\n",
              "          <span><strong>Curso:</strong> IA Fundamentals</span>\n",
              "        </div>\n",
              "        <div class=\"academic-badge\">\n",
              "          <i class=\"fas fa-book-open\"></i>\n",
              "          <span><strong>Clase:</strong> 2</span>\n",
              "        </div>\n",
              "      </div>\n",
              "    </header>\n",
              "\n",
              "    <div class=\"stats-container fade-in\">\n",
              "      <div class=\"stat-card\">\n",
              "        <span class=\"stat-number\" id=\"totalTerms\">28</span>\n",
              "        <div class=\"stat-label\">Términos Totales</div>\n",
              "      </div>\n",
              "      <div class=\"stat-card\">\n",
              "        <span class=\"stat-number\" id=\"categoriesCount\">7</span> <!-- Ajustado según categorías asignadas -->\n",
              "        <div class=\"stat-label\">Categorías</div>\n",
              "      </div>\n",
              "      <div class=\"stat-card\">\n",
              "        <span class=\"stat-number\" id=\"visibleTerms\">28</span>\n",
              "        <div class=\"stat-label\">Términos Visibles</div>\n",
              "      </div>\n",
              "    </div>\n",
              "\n",
              "    <div class=\"search-container fade-in\">\n",
              "      <input type=\"text\" class=\"search-input\" placeholder=\"Buscar término o definición...\" id=\"searchInput\" autocomplete=\"off\">\n",
              "      <i class=\"fas fa-search search-icon\"></i>\n",
              "    </div>\n",
              "\n",
              "    <div class=\"alphabet-filter fade-in\">\n",
              "      <button class=\"letter-btn\" data-letter=\"A\">A</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"B\">B</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"C\">C</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"D\">D</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"E\">E</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"F\">F</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"G\">G</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"I\">I</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"L\">L</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"M\">M</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"N\">N</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"O\">O</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"P\">P</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"R\">R</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"S\">S</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"T\">T</button>\n",
              "      <button class=\"letter-btn\" data-letter=\"V\">V</button>\n",
              "      <button class=\"clear-filter\" id=\"clearFilterButton\">\n",
              "        <i class=\"fas fa-times\"></i> Limpiar\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "    <div class=\"term-counter fade-in\">\n",
              "      <i class=\"fas fa-list-ul\"></i>\n",
              "      <span id=\"termCount\">28 términos encontrados</span>\n",
              "    </div>\n",
              "\n",
              "    <div class=\"glossary-grid\" id=\"glossaryGrid\">\n",
              "\n",
              "      <div class=\"term-card fade-in\" data-term=\"auto-atención (self-attention)\" style=\"--card-index: 0;\">\n",
              "        <div class=\"term-category\">Mecanismos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-project-diagram term-icon\"></i>Auto-atención (self-attention)</h3>\n",
              "        <p class=\"term-definition\">Mecanismo del Transformer que pondera la importancia relativa de cada token respecto a los demás para capturar dependencias de largo alcance en la secuencia.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"aprendizaje profundo\" style=\"--card-index: 1;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-brain term-icon\"></i>Aprendizaje profundo</h3>\n",
              "        <p class=\"term-definition\">Conjunto de técnicas de redes neuronales de muchas capas que optimizan millones o miles de millones de parámetros para extraer representaciones jerárquicas del lenguaje.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"aprendizaje auto-supervisado (no supervisado)\" style=\"--card-index: 2;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-user-cog term-icon\"></i>Aprendizaje auto-supervisado (no supervisado)</h3>\n",
              "        <p class=\"term-definition\">En el pre-entrenamiento el propio texto suministra la señal de entrenamiento (p. ej. predecir la siguiente palabra) sin necesidad de etiquetas humanas.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"analogías vectoriales\" style=\"--card-index: 3;\">\n",
              "        <div class=\"term-category\">Propiedades</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-vector-square term-icon\"></i>Analogías vectoriales</h3>\n",
              "        <p class=\"term-definition\">Propiedad emergente del espacio de embeddings donde operaciones aritméticas aproximan relaciones semánticas (rey – hombre + mujer ≈ reina).</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"bert\" style=\"--card-index: 4;\">\n",
              "        <div class=\"term-category\">Modelos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-robot term-icon\"></i>BERT</h3>\n",
              "        <p class=\"term-definition\">Modelo bidireccional basado en Transformer que se pre-entrena con MLM y NSP para generar representaciones contextuales. Véanse “MLM” y “NSP”.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"clm (causal language modeling)\" style=\"--card-index: 5;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-stream term-icon\"></i>CLM (Causal Language Modeling)</h3>\n",
              "        <p class=\"term-definition\">Tarea de pre-entrenamiento típica de GPT: predecir el siguiente token dado todo el contexto precedente, generando texto de manera autoregresiva.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"corpus textual\" style=\"--card-index: 6;\">\n",
              "        <div class=\"term-category\">Datos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-book-reader term-icon\"></i>Corpus textual</h3>\n",
              "        <p class=\"term-definition\">Colección masiva y heterogénea de textos (Internet, libros, artículos) sobre la que se realiza el pre-entrenamiento, origen de gran parte del conocimiento y de los sesgos.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"decodificación\" style=\"--card-index: 7;\">\n",
              "        <div class=\"term-category\">Procesamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-undo term-icon\"></i>Decodificación</h3>\n",
              "        <p class=\"term-definition\">Proceso inverso a la tokenización: convierte la secuencia de IDs de token generados en texto legible para el usuario.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"embedding\" style=\"--card-index: 8;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-cubes term-icon\"></i>Embedding</h3>\n",
              "        <p class=\"term-definition\">Vector denso de alta dimensión que representa un token en el espacio latente; se aprende durante el pre-entrenamiento y captura similitud semántica.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"espacio latente\" style=\"--card-index: 9;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-draw-polygon term-icon\"></i>Espacio latente</h3>\n",
              "        <p class=\"term-definition\">Espacio vectorial continuo donde viven los embeddings; su geometría refleja relaciones semánticas y sintácticas entre tokens.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"fine-tuning\" style=\"--card-index: 10;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-sliders-h term-icon\"></i>Fine-tuning</h3>\n",
              "        <p class=\"term-definition\">Segundo entrenamiento, de menor coste, en un corpus pequeño y específico que ajusta las representaciones generales del modelo a una tarea concreta.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"generación autoregresiva\" style=\"--card-index: 11;\">\n",
              "        <div class=\"term-category\">Mecanismos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-redo-alt term-icon\"></i>Generación autoregresiva</h3>\n",
              "        <p class=\"term-definition\">Modo de inferencia en que el modelo predice un token, lo añade al contexto y repite el ciclo hasta completar la respuesta.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"gpu / tpu\" style=\"--card-index: 12;\">\n",
              "        <div class=\"term-category\">Hardware</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-microchip term-icon\"></i>GPU / TPU</h3>\n",
              "        <p class=\"term-definition\">Hardware especializado (gráficas y unidades tensoriales) que permite el entrenamiento y la inferencia paralela de los Transformers a gran escala.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"interpretabilidad\" style=\"--card-index: 13;\">\n",
              "        <div class=\"term-category\">Desafíos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-search-plus term-icon\"></i>Interpretabilidad</h3>\n",
              "        <p class=\"term-definition\">Grado en que se puede explicar por qué el modelo elige una salida; sigue siendo un reto, pues los LLMs se comportan como “cajas negras”.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"llm (large language model)\" style=\"--card-index: 14;\">\n",
              "        <div class=\"term-category\">Modelos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-comments term-icon\"></i>LLM (Large Language Model)</h3>\n",
              "        <p class=\"term-definition\">Red neuronal de muy gran tamaño (cientos de millones-billones de parámetros) entrenada para modelar lenguaje natural y capaz de múltiples tareas lingüísticas.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"mlm (masked language modeling)\" style=\"--card-index: 15;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-mask term-icon\"></i>MLM (Masked Language Modeling)</h3>\n",
              "        <p class=\"term-definition\">Tarea de pre-entrenamiento de BERT: algunos tokens se sustituyen por `[MASK]` y el modelo debe predecir los originales usando el contexto a ambos lados.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"nsp (next sentence prediction)\" style=\"--card-index: 16;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-arrow-right term-icon\"></i>NSP (Next Sentence Prediction)</h3>\n",
              "        <p class=\"term-definition\">Objetivo adicional de BERT cuyo fin es aprender relaciones entre oraciones consecutivas del texto.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"oov (out-of-vocabulary)\" style=\"--card-index: 17;\">\n",
              "        <div class=\"term-category\">Procesamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-question-circle term-icon\"></i>OOV (Out-of-Vocabulary)</h3>\n",
              "        <p class=\"term-definition\">Tokens que no existen en el vocabulario del modelo; los enfoques de subpalabras reducen la incidencia de OOV.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"parámetros\" style=\"--card-index: 18;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-cogs term-icon\"></i>Parámetros</h3>\n",
              "        <p class=\"term-definition\">Pesos numéricos ajustables (embeddings y matrices internas) que el modelo optimiza; su cantidad determina la capacidad y el costo de computación.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"pre-entrenamiento\" style=\"--card-index: 19;\">\n",
              "        <div class=\"term-category\">Entrenamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-dumbbell term-icon\"></i>Pre-entrenamiento</h3>\n",
              "        <p class=\"term-definition\">Fase inicial donde el modelo aprende patrones lingüísticos generales y conocimiento del mundo a partir de un corpus gigantesco mediante tareas de CLM, MLM o NSP.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"prompt\" style=\"--card-index: 20;\">\n",
              "        <div class=\"term-category\">Interacción</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-terminal term-icon\"></i>Prompt</h3>\n",
              "        <p class=\"term-definition\">Texto inicial, pregunta o instrucción que proporciona el usuario y que define contexto, formato y tono de la respuesta.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"red neuronal\" style=\"--card-index: 21;\">\n",
              "        <div class=\"term-category\">Arquitectura</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-network-wired term-icon\"></i>Red neuronal</h3>\n",
              "        <p class=\"term-definition\">Estructura de capas de procesamiento (en LLMs, mayormente Transformer) que calcula funciones no lineales sobre los embeddings para modelar el lenguaje.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"representaciones lingüísticas\" style=\"--card-index: 22;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-language term-icon\"></i>Representaciones lingüísticas</h3>\n",
              "        <p class=\"term-definition\">Estructuras internas (sobre todo embeddings y capas contextualizadas) que codifican sintaxis, semántica y conocimiento.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"sesgo\" style=\"--card-index: 23;\">\n",
              "        <div class=\"term-category\">Desafíos</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-balance-scale-left term-icon\"></i>Sesgo</h3>\n",
              "        <p class=\"term-definition\">Patrones indeseados heredados del corpus que pueden amplificar estereotipos de género, raza u otros; mitigarlos es un desafío activo.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"token\" style=\"--card-index: 24;\">\n",
              "        <div class=\"term-category\">Procesamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-tag term-icon\"></i>Token</h3>\n",
              "        <p class=\"term-definition\">Unidad mínima de texto (palabra, subpalabra, carácter o símbolo) que el modelo procesa tras la tokenización.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"tokenización\" style=\"--card-index: 25;\">\n",
              "        <div class=\"term-category\">Procesamiento</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-cut term-icon\"></i>Tokenización</h3>\n",
              "        <p class=\"term-definition\">Proceso que divide el texto crudo en tokens y asigna a cada uno un ID numérico; es la puerta de entrada de cualquier modelo de lenguaje.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"transformer\" style=\"--card-index: 26;\">\n",
              "        <div class=\"term-category\">Arquitectura</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-sitemap term-icon\"></i>Transformer</h3>\n",
              "        <p class=\"term-definition\">Arquitectura dominante en LLMs compuesta por bloques de auto-atención y capas feed-forward, capaz de procesar todas las posiciones de la secuencia en paralelo.</p>\n",
              "      </div>\n",
              "      <div class=\"term-card fade-in\" data-term=\"ventana de contexto (context window)\" style=\"--card-index: 27;\">\n",
              "        <div class=\"term-category\">Conceptos Fund.</div>\n",
              "        <h3 class=\"term-name\"><i class=\"fas fa-window-maximize term-icon\"></i>Ventana de contexto (context window)</h3>\n",
              "        <p class=\"term-definition\">Número máximo de tokens (entrada + salida) que el modelo puede manejar en una sola pasada; limitarla evita desbordar memoria y costes.</p>\n",
              "      </div>\n",
              "\n",
              "      <div class=\"no-results hidden\">\n",
              "        <i class=\"fas fa-search-minus\"></i>\n",
              "        <p>No se encontraron términos que coincidan con su búsqueda o filtro.</p>\n",
              "      </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n",
              "\n",
              "  <script>\n",
              "    (function() {\n",
              "        let currentSessionTheme = 'light'; \n",
              "\n",
              "        function applyInitialTheme() {\n",
              "            document.body.setAttribute('data-theme', currentSessionTheme);\n",
              "        }\n",
              "\n",
              "        function toggleTheme() {\n",
              "            const currentThemeFromBody = document.body.getAttribute('data-theme');\n",
              "            const newTheme = currentThemeFromBody === 'dark' ? 'light' : 'dark';\n",
              "            document.body.setAttribute('data-theme', newTheme);\n",
              "            currentSessionTheme = newTheme;\n",
              "        }\n",
              "\n",
              "        const themeToggleButton = document.getElementById('themeToggleButton');\n",
              "        const searchInput = document.getElementById('searchInput');\n",
              "        const glossaryGrid = document.getElementById('glossaryGrid');\n",
              "        const termCards = Array.from(glossaryGrid.querySelectorAll('.term-card:not(.no-results)'));\n",
              "        const termCountElement = document.getElementById('termCount');\n",
              "        const alphabetFilter = document.querySelector('.alphabet-filter');\n",
              "        const letterButtons = alphabetFilter.querySelectorAll('.letter-btn');\n",
              "        const clearFilterButton = document.getElementById('clearFilterButton');\n",
              "        const noResultsElement = glossaryGrid.querySelector('.no-results');\n",
              "\n",
              "        const totalTermsElement = document.getElementById('totalTerms');\n",
              "        const categoriesCountElement = document.getElementById('categoriesCount');\n",
              "        const visibleTermsElement = document.getElementById('visibleTerms');\n",
              "\n",
              "        let currentFilterLetter = null;\n",
              "\n",
              "        function countUniqueCategories() {\n",
              "            const categories = new Set();\n",
              "            termCards.forEach(card => {\n",
              "                const categoryElement = card.querySelector('.term-category');\n",
              "                if (categoryElement && categoryElement.textContent.trim() !== \"\") { // Ensure category exists and is not empty\n",
              "                    categories.add(categoryElement.textContent.trim());\n",
              "                }\n",
              "            });\n",
              "            return categories.size;\n",
              "        }\n",
              "\n",
              "        function updateStats(visibleCount) {\n",
              "            if (totalTermsElement) totalTermsElement.textContent = termCards.length;\n",
              "            \n",
              "            const uniqueCategories = countUniqueCategories();\n",
              "            if (categoriesCountElement) categoriesCountElement.textContent = uniqueCategories > 0 ? uniqueCategories : \"N/A\"; // Show N/A if no categories\n",
              "            \n",
              "            if (visibleTermsElement) visibleTermsElement.textContent = visibleCount;\n",
              "        }\n",
              "\n",
              "        function filterTerms() {\n",
              "            if (!searchInput || !glossaryGrid) return;\n",
              "            const searchTerm = searchInput.value.toLowerCase().trim();\n",
              "            let visibleCount = 0;\n",
              "\n",
              "            termCards.forEach(card => {\n",
              "                const termName = card.dataset.term.toLowerCase();\n",
              "                const termDefinitionElement = card.querySelector('.term-definition');\n",
              "                if (!termDefinitionElement) return;\n",
              "                const termDefinition = termDefinitionElement.textContent.toLowerCase();\n",
              "\n",
              "                const matchesSearch = termName.includes(searchTerm) || termDefinition.includes(searchTerm);\n",
              "                const matchesLetter = !currentFilterLetter || termName.startsWith(currentFilterLetter.toLowerCase());\n",
              "\n",
              "                if (matchesSearch && matchesLetter) {\n",
              "                    card.classList.remove('hidden');\n",
              "                    card.classList.add('visible');\n",
              "                    visibleCount++;\n",
              "                } else {\n",
              "                    card.classList.add('hidden');\n",
              "                    card.classList.remove('visible');\n",
              "                }\n",
              "            });\n",
              "\n",
              "            if(termCountElement) termCountElement.innerHTML = `<i class=\"fas fa-list-ul\"></i> ${visibleCount} término${visibleCount !== 1 ? 's' : ''} encontrado${visibleCount !== 1 ? 's' : ''}`;\n",
              "            updateStats(visibleCount);\n",
              "\n",
              "            if (noResultsElement) {\n",
              "                if (visibleCount === 0 && (searchTerm || currentFilterLetter)) {\n",
              "                    noResultsElement.classList.remove('hidden');\n",
              "                } else {\n",
              "                    noResultsElement.classList.add('hidden');\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function filterByLetter(letter) {\n",
              "            if (currentFilterLetter === letter) {\n",
              "                currentFilterLetter = null;\n",
              "                letterButtons.forEach(btn => btn.classList.remove('active'));\n",
              "            } else {\n",
              "                currentFilterLetter = letter;\n",
              "                letterButtons.forEach(btn => {\n",
              "                    btn.classList.toggle('active', btn.dataset.letter === letter);\n",
              "                });\n",
              "            }\n",
              "            filterTerms();\n",
              "        }\n",
              "\n",
              "        function clearAllFilters() {\n",
              "            if(searchInput) searchInput.value = '';\n",
              "            currentFilterLetter = null;\n",
              "            letterButtons.forEach(btn => btn.classList.remove('active'));\n",
              "            filterTerms();\n",
              "        }\n",
              "\n",
              "        if (themeToggleButton) {\n",
              "            themeToggleButton.addEventListener('click', toggleTheme);\n",
              "        }\n",
              "        if (searchInput) {\n",
              "            searchInput.addEventListener('input', filterTerms);\n",
              "        }\n",
              "        letterButtons.forEach(button => {\n",
              "            button.addEventListener('click', () => filterByLetter(button.dataset.letter));\n",
              "        });\n",
              "        if (clearFilterButton) {\n",
              "            clearFilterButton.addEventListener('click', clearAllFilters);\n",
              "        }\n",
              "\n",
              "        applyInitialTheme();\n",
              "        filterTerms(); // Initial filter to set up counts\n",
              "\n",
              "        // Set --card-index for staggered animation\n",
              "        termCards.forEach((card, index) => {\n",
              "            card.style.setProperty('--card-index', index);\n",
              "        });\n",
              "    })();\n",
              "  </script>\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Importar las funciones necesarias de IPython para mostrar HTML\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Definir el contenido HTML del Glosario con diseño mejorado y nuevos términos\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>Glosario de Términos - Clase II: Conceptos LLM</title>\n",
        "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
        "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
        "  <style>\n",
        "    :root {\n",
        "      /* Tema claro */\n",
        "      --bg-primary: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "      --bg-secondary: #ffffff;\n",
        "      --bg-tertiary: #f8fafc;\n",
        "      --bg-quaternary: #f1f5f9;\n",
        "      --text-primary: #1e293b;\n",
        "      --text-secondary: #64748b;\n",
        "      --text-accent: #3b82f6;\n",
        "      --border-color: #e2e8f0;\n",
        "      --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n",
        "      --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);\n",
        "      --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);\n",
        "      --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);\n",
        "\n",
        "      --color-blue: #3b82f6;\n",
        "      --color-emerald: #10b981;\n",
        "      --color-purple: #8b5cf6;\n",
        "      --color-rose: #f43f5e;\n",
        "      --color-amber: #f59e0b;\n",
        "      --color-indigo: #6366f1;\n",
        "      --color-cyan: #06b6d4;\n",
        "    }\n",
        "\n",
        "    [data-theme=\"dark\"] {\n",
        "      --bg-primary: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);\n",
        "      --bg-secondary: #1e293b;\n",
        "      --bg-tertiary: #334155;\n",
        "      --bg-quaternary: #475569;\n",
        "      --text-primary: #f1f5f9;\n",
        "      --text-secondary: #94a3b8;\n",
        "      --text-accent: #60a5fa;\n",
        "      --border-color: #475569;\n",
        "      --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.3);\n",
        "      --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.3), 0 2px 4px -2px rgb(0 0 0 / 0.3);\n",
        "      --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.3), 0 4px 6px -4px rgb(0 0 0 / 0.3);\n",
        "      --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.3), 0 8px 10px -6px rgb(0 0 0 / 0.3);\n",
        "    }\n",
        "\n",
        "    * {\n",
        "      margin: 0;\n",
        "      padding: 0;\n",
        "      box-sizing: border-box;\n",
        "    }\n",
        "\n",
        "    html {\n",
        "        scroll-behavior: smooth;\n",
        "    }\n",
        "\n",
        "    body {\n",
        "      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
        "      line-height: 1.7;\n",
        "      background: var(--bg-primary);\n",
        "      color: var(--text-primary);\n",
        "      min-height: 100vh;\n",
        "      overflow-x: hidden;\n",
        "      transition: background 0.3s ease, color 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .container {\n",
        "      max-width: 1200px;\n",
        "      margin: 0 auto;\n",
        "      padding: 2rem;\n",
        "      position: relative;\n",
        "    }\n",
        "\n",
        "    .header {\n",
        "      text-align: center;\n",
        "      margin-bottom: 3rem;\n",
        "      position: relative;\n",
        "      z-index: 10;\n",
        "    }\n",
        "\n",
        "    .header::before {\n",
        "      content: '';\n",
        "      position: absolute;\n",
        "      top: -50px;\n",
        "      left: 50%;\n",
        "      transform: translateX(-50%);\n",
        "      width: 120px;\n",
        "      height: 120px;\n",
        "      background: var(--color-purple);\n",
        "      border-radius: 50%;\n",
        "      opacity: 0.1;\n",
        "      animation: pulse 3s ease-in-out infinite;\n",
        "    }\n",
        "\n",
        "    @keyframes pulse {\n",
        "      0%, 100% { transform: translateX(-50%) scale(1); opacity: 0.1; }\n",
        "      50% { transform: translateX(-50%) scale(1.2); opacity: 0.2; }\n",
        "    }\n",
        "\n",
        "    .main-title {\n",
        "      font-size: clamp(2.5rem, 5vw, 3.5rem);\n",
        "      font-weight: 700;\n",
        "      background: linear-gradient(135deg, var(--color-purple), var(--color-indigo));\n",
        "      -webkit-background-clip: text;\n",
        "      -webkit-text-fill-color: transparent;\n",
        "      background-clip: text;\n",
        "      margin-bottom: 0.5rem;\n",
        "      position: relative;\n",
        "    }\n",
        "\n",
        "    .subtitle {\n",
        "      font-size: 1.25rem;\n",
        "      color: var(--text-secondary);\n",
        "      font-weight: 400;\n",
        "      max-width: 600px;\n",
        "      margin: 0 auto 1.5rem auto;\n",
        "    }\n",
        "\n",
        "    .academic-info {\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "      flex-wrap: wrap;\n",
        "      gap: 1rem;\n",
        "      font-size: 0.95rem;\n",
        "      color: var(--text-secondary);\n",
        "      background: var(--bg-secondary);\n",
        "      padding: 1rem 1.5rem;\n",
        "      border-radius: 1rem;\n",
        "      border: 1px solid var(--border-color);\n",
        "      box-shadow: var(--shadow-sm);\n",
        "      max-width: fit-content;\n",
        "      margin: 0 auto;\n",
        "      transition: all 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .academic-info:hover {\n",
        "      transform: translateY(-2px);\n",
        "      box-shadow: var(--shadow-md);\n",
        "      border-color: var(--text-accent);\n",
        "    }\n",
        "\n",
        "    .academic-badge {\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      gap: 0.5rem;\n",
        "      padding: 0.5rem 0.75rem;\n",
        "      background: var(--bg-tertiary);\n",
        "      border-radius: 0.5rem;\n",
        "      border: 1px solid var(--border-color);\n",
        "      font-weight: 500;\n",
        "    }\n",
        "\n",
        "    .academic-badge i {\n",
        "      color: var(--text-accent);\n",
        "      font-size: 0.9rem;\n",
        "    }\n",
        "\n",
        "    .academic-badge strong {\n",
        "      color: var(--text-primary);\n",
        "    }\n",
        "\n",
        "    .theme-toggle {\n",
        "      position: fixed;\n",
        "      top: 2rem;\n",
        "      right: 2rem;\n",
        "      width: 60px;\n",
        "      height: 60px;\n",
        "      border: 2px solid var(--border-color);\n",
        "      border-radius: 50%;\n",
        "      background: var(--bg-secondary);\n",
        "      box-shadow: var(--shadow-lg);\n",
        "      cursor: pointer;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "      font-size: 1.5rem;\n",
        "      color: var(--text-primary);\n",
        "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "      z-index: 1000;\n",
        "      backdrop-filter: blur(10px);\n",
        "    }\n",
        "\n",
        "    .theme-toggle:hover {\n",
        "      transform: translateY(-2px) scale(1.05);\n",
        "      box-shadow: var(--shadow-xl);\n",
        "      background: var(--text-accent);\n",
        "      color: white;\n",
        "    }\n",
        "\n",
        "    .theme-toggle:active {\n",
        "      transform: translateY(0) scale(0.95);\n",
        "    }\n",
        "\n",
        "    .theme-icon {\n",
        "      transition: all 0.3s ease;\n",
        "      position: absolute;\n",
        "    }\n",
        "\n",
        "    .theme-toggle .fa-sun {\n",
        "      opacity: 0;\n",
        "      transform: rotate(-90deg) scale(0.5);\n",
        "    }\n",
        "\n",
        "    .theme-toggle .fa-moon {\n",
        "      opacity: 1;\n",
        "      transform: rotate(0deg) scale(1);\n",
        "    }\n",
        "\n",
        "    [data-theme=\"dark\"] .theme-toggle .fa-moon {\n",
        "      opacity: 0;\n",
        "      transform: rotate(90deg) scale(0.5);\n",
        "    }\n",
        "\n",
        "    [data-theme=\"dark\"] .theme-toggle .fa-sun {\n",
        "      opacity: 1;\n",
        "      transform: rotate(0deg) scale(1);\n",
        "    }\n",
        "\n",
        "    .stats-container {\n",
        "      display: grid;\n",
        "      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
        "      gap: 1rem;\n",
        "      margin-bottom: 2rem;\n",
        "    }\n",
        "\n",
        "    .stat-card {\n",
        "      background: var(--bg-secondary);\n",
        "      padding: 1.5rem;\n",
        "      border-radius: 1rem;\n",
        "      border: 1px solid var(--border-color);\n",
        "      box-shadow: var(--shadow-sm);\n",
        "      text-align: center;\n",
        "      transition: all 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .stat-card:hover {\n",
        "      transform: translateY(-2px);\n",
        "      box-shadow: var(--shadow-md);\n",
        "    }\n",
        "\n",
        "    .stat-number {\n",
        "      font-size: 2rem;\n",
        "      font-weight: 700;\n",
        "      color: var(--color-purple);\n",
        "      display: block;\n",
        "    }\n",
        "\n",
        "    .stat-label {\n",
        "      font-size: 0.9rem;\n",
        "      color: var(--text-secondary);\n",
        "      margin-top: 0.5rem;\n",
        "    }\n",
        "\n",
        "    .search-container {\n",
        "      margin-bottom: 2rem;\n",
        "      position: relative;\n",
        "      max-width: 500px;\n",
        "      margin-left: auto;\n",
        "      margin-right: auto;\n",
        "    }\n",
        "\n",
        "    .search-input {\n",
        "      width: 100%;\n",
        "      padding: 1rem 1rem 1rem 3rem;\n",
        "      font-size: 1rem;\n",
        "      border: 2px solid var(--border-color);\n",
        "      border-radius: 2rem;\n",
        "      background: var(--bg-secondary);\n",
        "      color: var(--text-primary);\n",
        "      transition: all 0.3s ease;\n",
        "      outline: none;\n",
        "    }\n",
        "\n",
        "    .search-input:focus {\n",
        "      border-color: var(--color-purple);\n",
        "      box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.1);\n",
        "      transform: translateY(-1px);\n",
        "    }\n",
        "\n",
        "    .search-icon {\n",
        "      position: absolute;\n",
        "      left: 1.25rem;\n",
        "      top: 50%;\n",
        "      transform: translateY(-50%);\n",
        "      color: var(--text-secondary);\n",
        "      font-size: 1rem;\n",
        "      transition: color 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .search-input:focus + .search-icon {\n",
        "      color: var(--color-purple);\n",
        "    }\n",
        "\n",
        "    .alphabet-filter {\n",
        "      display: flex;\n",
        "      justify-content: center;\n",
        "      flex-wrap: wrap;\n",
        "      gap: 0.5rem;\n",
        "      margin-bottom: 2rem;\n",
        "      padding: 1.5rem;\n",
        "      background: var(--bg-secondary);\n",
        "      border-radius: 1rem;\n",
        "      box-shadow: var(--shadow-md);\n",
        "      border: 1px solid var(--border-color);\n",
        "    }\n",
        "\n",
        "    .letter-btn {\n",
        "      width: 40px;\n",
        "      height: 40px;\n",
        "      border: 1px solid var(--border-color);\n",
        "      border-radius: 50%;\n",
        "      background: var(--bg-tertiary);\n",
        "      color: var(--text-secondary);\n",
        "      font-weight: 500;\n",
        "      cursor: pointer;\n",
        "      transition: all 0.3s ease;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "    }\n",
        "\n",
        "    .letter-btn:hover {\n",
        "      background: var(--color-purple);\n",
        "      color: white;\n",
        "      transform: translateY(-2px);\n",
        "      box-shadow: var(--shadow-md);\n",
        "      border-color: var(--color-purple);\n",
        "    }\n",
        "\n",
        "    .letter-btn.active {\n",
        "      background: var(--color-purple);\n",
        "      color: white;\n",
        "      border-color: var(--color-purple);\n",
        "      box-shadow: var(--shadow-md);\n",
        "    }\n",
        "\n",
        "    .clear-filter {\n",
        "      padding: 0.5rem 1rem;\n",
        "      background: var(--color-rose);\n",
        "      color: white;\n",
        "      border: none;\n",
        "      border-radius: 1rem;\n",
        "      font-size: 0.9rem;\n",
        "      cursor: pointer;\n",
        "      transition: all 0.3s ease;\n",
        "      font-weight: 500;\n",
        "      display: inline-flex;\n",
        "      align-items: center;\n",
        "      gap: 0.3rem;\n",
        "    }\n",
        "\n",
        "    .clear-filter:hover {\n",
        "      background: #dc2626;\n",
        "      transform: translateY(-1px);\n",
        "      box-shadow: var(--shadow-sm);\n",
        "    }\n",
        "\n",
        "    .term-counter {\n",
        "      text-align: center;\n",
        "      margin-bottom: 1.5rem;\n",
        "      padding: 0.75rem 1.5rem;\n",
        "      background: var(--bg-secondary);\n",
        "      border-radius: 2rem;\n",
        "      border: 1px solid var(--border-color);\n",
        "      color: var(--text-secondary);\n",
        "      font-size: 0.95rem;\n",
        "      font-weight: 500;\n",
        "      max-width: fit-content;\n",
        "      margin-left: auto;\n",
        "      margin-right: auto;\n",
        "      box-shadow: var(--shadow-sm);\n",
        "      display: inline-flex;\n",
        "      align-items: center;\n",
        "      gap: 0.5rem;\n",
        "    }\n",
        "\n",
        "    .glossary-grid {\n",
        "      display: grid;\n",
        "      grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));\n",
        "      gap: 1.5rem;\n",
        "      margin-top: 2rem;\n",
        "    }\n",
        "\n",
        "    .term-card {\n",
        "      background: var(--bg-secondary);\n",
        "      border-radius: 1rem;\n",
        "      padding: 1.5rem;\n",
        "      box-shadow: var(--shadow-md);\n",
        "      border: 1px solid var(--border-color);\n",
        "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "      position: relative;\n",
        "      overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .term-card::before {\n",
        "      content: '';\n",
        "      position: absolute;\n",
        "      top: 0;\n",
        "      left: 0;\n",
        "      width: 4px;\n",
        "      height: 100%;\n",
        "      background: linear-gradient(45deg, var(--color-purple), var(--color-indigo));\n",
        "      transition: width 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .term-card:hover {\n",
        "      transform: translateY(-4px);\n",
        "      box-shadow: var(--shadow-xl);\n",
        "      border-color: var(--color-purple);\n",
        "    }\n",
        "\n",
        "    .term-card:hover::before {\n",
        "      width: 8px;\n",
        "    }\n",
        "\n",
        "    .term-name {\n",
        "      font-size: 1.25rem;\n",
        "      font-weight: 600;\n",
        "      color: var(--color-purple);\n",
        "      margin-bottom: 0.75rem;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      gap: 0.5rem;\n",
        "    }\n",
        "\n",
        "    .term-icon {\n",
        "      font-size: 1rem;\n",
        "      color: var(--color-indigo);\n",
        "      flex-shrink: 0;\n",
        "    }\n",
        "\n",
        "    .term-definition {\n",
        "      color: var(--text-primary);\n",
        "      line-height: 1.8;\n",
        "      font-size: 0.95rem;\n",
        "    }\n",
        "\n",
        "    .term-category {\n",
        "      position: absolute;\n",
        "      top: 1rem;\n",
        "      right: 1rem;\n",
        "      padding: 0.25rem 0.75rem;\n",
        "      background: var(--color-amber);\n",
        "      color: white;\n",
        "      font-size: 0.75rem;\n",
        "      font-weight: 500;\n",
        "      border-radius: 1rem;\n",
        "      text-transform: uppercase;\n",
        "      letter-spacing: 0.5px;\n",
        "      box-shadow: var(--shadow-sm);\n",
        "    }\n",
        "\n",
        "    .floating-shapes {\n",
        "      position: fixed;\n",
        "      top: 0;\n",
        "      left: 0;\n",
        "      width: 100%;\n",
        "      height: 100%;\n",
        "      pointer-events: none;\n",
        "      z-index: -1;\n",
        "      overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .shape {\n",
        "      position: absolute;\n",
        "      border-radius: 50%;\n",
        "      opacity: 0.03;\n",
        "      animation: float 8s ease-in-out infinite;\n",
        "      backdrop-filter: blur(1px);\n",
        "    }\n",
        "\n",
        "    .shape:nth-child(1) { width: 100px; height: 100px; top: 20%; left: 10%; background: var(--color-purple); animation-delay: 0s; }\n",
        "    .shape:nth-child(2) { width: 150px; height: 150px; top: 60%; right: 15%; background: var(--color-indigo); animation-delay: 2s; }\n",
        "    .shape:nth-child(3) { width: 80px; height: 80px; bottom: 20%; left: 20%; background: var(--color-cyan); animation-delay: 4s; }\n",
        "    .shape:nth-child(4) { width: 120px; height: 120px; top: 40%; right: 40%; background: var(--color-emerald); animation-delay: 6s; }\n",
        "\n",
        "    @keyframes float {\n",
        "      0%, 100% { transform: translateY(0) rotate(0deg); }\n",
        "      25% { transform: translateY(-30px) rotate(90deg); }\n",
        "      50% { transform: translateY(-20px) rotate(180deg); }\n",
        "      75% { transform: translateY(-40px) rotate(270deg); }\n",
        "    }\n",
        "\n",
        "    .term-card.hidden { display: none; }\n",
        "    .term-card.visible { display: block; animation: fadeInCard 0.5s ease forwards; }\n",
        "\n",
        "    @keyframes fadeInCard {\n",
        "      from { opacity: 0; transform: translateY(10px); }\n",
        "      to { opacity: 1; transform: translateY(0); }\n",
        "    }\n",
        "\n",
        "    .no-results {\n",
        "      text-align: center;\n",
        "      padding: 3rem;\n",
        "      color: var(--text-secondary);\n",
        "      font-size: 1.1rem;\n",
        "      grid-column: 1 / -1;\n",
        "      background: var(--bg-secondary);\n",
        "      border-radius: 1rem;\n",
        "      border: 2px dashed var(--border-color);\n",
        "      display: flex;\n",
        "      flex-direction: column;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "    }\n",
        "    .no-results i { font-size: 3rem; margin-bottom: 1rem; color: var(--color-purple); opacity: 0.3; }\n",
        "\n",
        "    @media (max-width: 768px) {\n",
        "      .container { padding: 1rem; }\n",
        "      .glossary-grid { grid-template-columns: 1fr; gap: 1rem; }\n",
        "      .alphabet-filter { padding: 1rem; gap: 0.25rem; }\n",
        "      .letter-btn { width: 35px; height: 35px; font-size: 0.9rem; }\n",
        "      .theme-toggle { width: 50px; height: 50px; top: 1rem; right: 1rem; font-size: 1.25rem; }\n",
        "      .main-title { font-size: 2rem; }\n",
        "      .stats-container { grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); }\n",
        "      .academic-info { flex-direction: column; align-items: stretch; }\n",
        "      .academic-badge { justify-content: center; }\n",
        "    }\n",
        "\n",
        "    .fade-in { opacity: 0; transform: translateY(20px); animation: fadeInUp 0.6s ease forwards; }\n",
        "    .term-card.fade-in { animation: fadeInUp 0.6s ease forwards; animation-delay: calc(var(--card-index) * 0.05s); }\n",
        "\n",
        "    @keyframes fadeInUp { to { opacity: 1; transform: translateY(0); } }\n",
        "\n",
        "    ::-webkit-scrollbar { width: 8px; }\n",
        "    ::-webkit-scrollbar-track { background: var(--bg-tertiary); border-radius: 4px; }\n",
        "    ::-webkit-scrollbar-thumb { background: var(--text-secondary); border-radius: 4px; transition: background 0.3s ease; }\n",
        "    ::-webkit-scrollbar-thumb:hover { background: var(--text-primary); }\n",
        "  </style>\n",
        "</head>\n",
        "<body data-theme=\"light\">\n",
        "  <div class=\"floating-shapes\">\n",
        "    <div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div><div class=\"shape\"></div>\n",
        "  </div>\n",
        "\n",
        "  <button class=\"theme-toggle\" id=\"themeToggleButton\" title=\"Cambiar tema\" aria-label=\"Cambiar tema\">\n",
        "    <i class=\"fas fa-moon theme-icon\"></i>\n",
        "    <i class=\"fas fa-sun theme-icon\"></i>\n",
        "  </button>\n",
        "\n",
        "  <div class=\"container\">\n",
        "    <header class=\"header\">\n",
        "      <h1 class=\"main-title fade-in\">Glosario de Términos</h1>\n",
        "      <p class=\"subtitle fade-in\">Clase II: Conceptos LLM</p>\n",
        "\n",
        "      <div class=\"academic-info fade-in\">\n",
        "        <div class=\"academic-badge\">\n",
        "          <i class=\"fas fa-graduation-cap\"></i>\n",
        "          <span><strong>Curso:</strong> IA Fundamentals</span>\n",
        "        </div>\n",
        "        <div class=\"academic-badge\">\n",
        "          <i class=\"fas fa-book-open\"></i>\n",
        "          <span><strong>Clase:</strong> 2</span>\n",
        "        </div>\n",
        "      </div>\n",
        "    </header>\n",
        "\n",
        "    <div class=\"stats-container fade-in\">\n",
        "      <div class=\"stat-card\">\n",
        "        <span class=\"stat-number\" id=\"totalTerms\">28</span>\n",
        "        <div class=\"stat-label\">Términos Totales</div>\n",
        "      </div>\n",
        "      <div class=\"stat-card\">\n",
        "        <span class=\"stat-number\" id=\"categoriesCount\">7</span> <!-- Ajustado según categorías asignadas -->\n",
        "        <div class=\"stat-label\">Categorías</div>\n",
        "      </div>\n",
        "      <div class=\"stat-card\">\n",
        "        <span class=\"stat-number\" id=\"visibleTerms\">28</span>\n",
        "        <div class=\"stat-label\">Términos Visibles</div>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"search-container fade-in\">\n",
        "      <input type=\"text\" class=\"search-input\" placeholder=\"Buscar término o definición...\" id=\"searchInput\" autocomplete=\"off\">\n",
        "      <i class=\"fas fa-search search-icon\"></i>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"alphabet-filter fade-in\">\n",
        "      <button class=\"letter-btn\" data-letter=\"A\">A</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"B\">B</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"C\">C</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"D\">D</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"E\">E</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"F\">F</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"G\">G</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"I\">I</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"L\">L</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"M\">M</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"N\">N</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"O\">O</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"P\">P</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"R\">R</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"S\">S</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"T\">T</button>\n",
        "      <button class=\"letter-btn\" data-letter=\"V\">V</button>\n",
        "      <button class=\"clear-filter\" id=\"clearFilterButton\">\n",
        "        <i class=\"fas fa-times\"></i> Limpiar\n",
        "      </button>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"term-counter fade-in\">\n",
        "      <i class=\"fas fa-list-ul\"></i>\n",
        "      <span id=\"termCount\">28 términos encontrados</span>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"glossary-grid\" id=\"glossaryGrid\">\n",
        "\n",
        "      <div class=\"term-card fade-in\" data-term=\"auto-atención (self-attention)\" style=\"--card-index: 0;\">\n",
        "        <div class=\"term-category\">Mecanismos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-project-diagram term-icon\"></i>Auto-atención (self-attention)</h3>\n",
        "        <p class=\"term-definition\">Mecanismo del Transformer que pondera la importancia relativa de cada token respecto a los demás para capturar dependencias de largo alcance en la secuencia.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"aprendizaje profundo\" style=\"--card-index: 1;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-brain term-icon\"></i>Aprendizaje profundo</h3>\n",
        "        <p class=\"term-definition\">Conjunto de técnicas de redes neuronales de muchas capas que optimizan millones o miles de millones de parámetros para extraer representaciones jerárquicas del lenguaje.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"aprendizaje auto-supervisado (no supervisado)\" style=\"--card-index: 2;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-user-cog term-icon\"></i>Aprendizaje auto-supervisado (no supervisado)</h3>\n",
        "        <p class=\"term-definition\">En el pre-entrenamiento el propio texto suministra la señal de entrenamiento (p. ej. predecir la siguiente palabra) sin necesidad de etiquetas humanas.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"analogías vectoriales\" style=\"--card-index: 3;\">\n",
        "        <div class=\"term-category\">Propiedades</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-vector-square term-icon\"></i>Analogías vectoriales</h3>\n",
        "        <p class=\"term-definition\">Propiedad emergente del espacio de embeddings donde operaciones aritméticas aproximan relaciones semánticas (rey – hombre + mujer ≈ reina).</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"bert\" style=\"--card-index: 4;\">\n",
        "        <div class=\"term-category\">Modelos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-robot term-icon\"></i>BERT</h3>\n",
        "        <p class=\"term-definition\">Modelo bidireccional basado en Transformer que se pre-entrena con MLM y NSP para generar representaciones contextuales. Véanse “MLM” y “NSP”.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"clm (causal language modeling)\" style=\"--card-index: 5;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-stream term-icon\"></i>CLM (Causal Language Modeling)</h3>\n",
        "        <p class=\"term-definition\">Tarea de pre-entrenamiento típica de GPT: predecir el siguiente token dado todo el contexto precedente, generando texto de manera autoregresiva.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"corpus textual\" style=\"--card-index: 6;\">\n",
        "        <div class=\"term-category\">Datos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-book-reader term-icon\"></i>Corpus textual</h3>\n",
        "        <p class=\"term-definition\">Colección masiva y heterogénea de textos (Internet, libros, artículos) sobre la que se realiza el pre-entrenamiento, origen de gran parte del conocimiento y de los sesgos.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"decodificación\" style=\"--card-index: 7;\">\n",
        "        <div class=\"term-category\">Procesamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-undo term-icon\"></i>Decodificación</h3>\n",
        "        <p class=\"term-definition\">Proceso inverso a la tokenización: convierte la secuencia de IDs de token generados en texto legible para el usuario.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"embedding\" style=\"--card-index: 8;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-cubes term-icon\"></i>Embedding</h3>\n",
        "        <p class=\"term-definition\">Vector denso de alta dimensión que representa un token en el espacio latente; se aprende durante el pre-entrenamiento y captura similitud semántica.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"espacio latente\" style=\"--card-index: 9;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-draw-polygon term-icon\"></i>Espacio latente</h3>\n",
        "        <p class=\"term-definition\">Espacio vectorial continuo donde viven los embeddings; su geometría refleja relaciones semánticas y sintácticas entre tokens.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"fine-tuning\" style=\"--card-index: 10;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-sliders-h term-icon\"></i>Fine-tuning</h3>\n",
        "        <p class=\"term-definition\">Segundo entrenamiento, de menor coste, en un corpus pequeño y específico que ajusta las representaciones generales del modelo a una tarea concreta.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"generación autoregresiva\" style=\"--card-index: 11;\">\n",
        "        <div class=\"term-category\">Mecanismos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-redo-alt term-icon\"></i>Generación autoregresiva</h3>\n",
        "        <p class=\"term-definition\">Modo de inferencia en que el modelo predice un token, lo añade al contexto y repite el ciclo hasta completar la respuesta.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"gpu / tpu\" style=\"--card-index: 12;\">\n",
        "        <div class=\"term-category\">Hardware</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-microchip term-icon\"></i>GPU / TPU</h3>\n",
        "        <p class=\"term-definition\">Hardware especializado (gráficas y unidades tensoriales) que permite el entrenamiento y la inferencia paralela de los Transformers a gran escala.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"interpretabilidad\" style=\"--card-index: 13;\">\n",
        "        <div class=\"term-category\">Desafíos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-search-plus term-icon\"></i>Interpretabilidad</h3>\n",
        "        <p class=\"term-definition\">Grado en que se puede explicar por qué el modelo elige una salida; sigue siendo un reto, pues los LLMs se comportan como “cajas negras”.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"llm (large language model)\" style=\"--card-index: 14;\">\n",
        "        <div class=\"term-category\">Modelos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-comments term-icon\"></i>LLM (Large Language Model)</h3>\n",
        "        <p class=\"term-definition\">Red neuronal de muy gran tamaño (cientos de millones-billones de parámetros) entrenada para modelar lenguaje natural y capaz de múltiples tareas lingüísticas.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"mlm (masked language modeling)\" style=\"--card-index: 15;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-mask term-icon\"></i>MLM (Masked Language Modeling)</h3>\n",
        "        <p class=\"term-definition\">Tarea de pre-entrenamiento de BERT: algunos tokens se sustituyen por `[MASK]` y el modelo debe predecir los originales usando el contexto a ambos lados.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"nsp (next sentence prediction)\" style=\"--card-index: 16;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-arrow-right term-icon\"></i>NSP (Next Sentence Prediction)</h3>\n",
        "        <p class=\"term-definition\">Objetivo adicional de BERT cuyo fin es aprender relaciones entre oraciones consecutivas del texto.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"oov (out-of-vocabulary)\" style=\"--card-index: 17;\">\n",
        "        <div class=\"term-category\">Procesamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-question-circle term-icon\"></i>OOV (Out-of-Vocabulary)</h3>\n",
        "        <p class=\"term-definition\">Tokens que no existen en el vocabulario del modelo; los enfoques de subpalabras reducen la incidencia de OOV.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"parámetros\" style=\"--card-index: 18;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-cogs term-icon\"></i>Parámetros</h3>\n",
        "        <p class=\"term-definition\">Pesos numéricos ajustables (embeddings y matrices internas) que el modelo optimiza; su cantidad determina la capacidad y el costo de computación.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"pre-entrenamiento\" style=\"--card-index: 19;\">\n",
        "        <div class=\"term-category\">Entrenamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-dumbbell term-icon\"></i>Pre-entrenamiento</h3>\n",
        "        <p class=\"term-definition\">Fase inicial donde el modelo aprende patrones lingüísticos generales y conocimiento del mundo a partir de un corpus gigantesco mediante tareas de CLM, MLM o NSP.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"prompt\" style=\"--card-index: 20;\">\n",
        "        <div class=\"term-category\">Interacción</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-terminal term-icon\"></i>Prompt</h3>\n",
        "        <p class=\"term-definition\">Texto inicial, pregunta o instrucción que proporciona el usuario y que define contexto, formato y tono de la respuesta.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"red neuronal\" style=\"--card-index: 21;\">\n",
        "        <div class=\"term-category\">Arquitectura</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-network-wired term-icon\"></i>Red neuronal</h3>\n",
        "        <p class=\"term-definition\">Estructura de capas de procesamiento (en LLMs, mayormente Transformer) que calcula funciones no lineales sobre los embeddings para modelar el lenguaje.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"representaciones lingüísticas\" style=\"--card-index: 22;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-language term-icon\"></i>Representaciones lingüísticas</h3>\n",
        "        <p class=\"term-definition\">Estructuras internas (sobre todo embeddings y capas contextualizadas) que codifican sintaxis, semántica y conocimiento.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"sesgo\" style=\"--card-index: 23;\">\n",
        "        <div class=\"term-category\">Desafíos</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-balance-scale-left term-icon\"></i>Sesgo</h3>\n",
        "        <p class=\"term-definition\">Patrones indeseados heredados del corpus que pueden amplificar estereotipos de género, raza u otros; mitigarlos es un desafío activo.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"token\" style=\"--card-index: 24;\">\n",
        "        <div class=\"term-category\">Procesamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-tag term-icon\"></i>Token</h3>\n",
        "        <p class=\"term-definition\">Unidad mínima de texto (palabra, subpalabra, carácter o símbolo) que el modelo procesa tras la tokenización.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"tokenización\" style=\"--card-index: 25;\">\n",
        "        <div class=\"term-category\">Procesamiento</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-cut term-icon\"></i>Tokenización</h3>\n",
        "        <p class=\"term-definition\">Proceso que divide el texto crudo en tokens y asigna a cada uno un ID numérico; es la puerta de entrada de cualquier modelo de lenguaje.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"transformer\" style=\"--card-index: 26;\">\n",
        "        <div class=\"term-category\">Arquitectura</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-sitemap term-icon\"></i>Transformer</h3>\n",
        "        <p class=\"term-definition\">Arquitectura dominante en LLMs compuesta por bloques de auto-atención y capas feed-forward, capaz de procesar todas las posiciones de la secuencia en paralelo.</p>\n",
        "      </div>\n",
        "      <div class=\"term-card fade-in\" data-term=\"ventana de contexto (context window)\" style=\"--card-index: 27;\">\n",
        "        <div class=\"term-category\">Conceptos Fund.</div>\n",
        "        <h3 class=\"term-name\"><i class=\"fas fa-window-maximize term-icon\"></i>Ventana de contexto (context window)</h3>\n",
        "        <p class=\"term-definition\">Número máximo de tokens (entrada + salida) que el modelo puede manejar en una sola pasada; limitarla evita desbordar memoria y costes.</p>\n",
        "      </div>\n",
        "\n",
        "      <div class=\"no-results hidden\">\n",
        "        <i class=\"fas fa-search-minus\"></i>\n",
        "        <p>No se encontraron términos que coincidan con su búsqueda o filtro.</p>\n",
        "      </div>\n",
        "\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    (function() {\n",
        "        let currentSessionTheme = 'light';\n",
        "\n",
        "        function applyInitialTheme() {\n",
        "            document.body.setAttribute('data-theme', currentSessionTheme);\n",
        "        }\n",
        "\n",
        "        function toggleTheme() {\n",
        "            const currentThemeFromBody = document.body.getAttribute('data-theme');\n",
        "            const newTheme = currentThemeFromBody === 'dark' ? 'light' : 'dark';\n",
        "            document.body.setAttribute('data-theme', newTheme);\n",
        "            currentSessionTheme = newTheme;\n",
        "        }\n",
        "\n",
        "        const themeToggleButton = document.getElementById('themeToggleButton');\n",
        "        const searchInput = document.getElementById('searchInput');\n",
        "        const glossaryGrid = document.getElementById('glossaryGrid');\n",
        "        const termCards = Array.from(glossaryGrid.querySelectorAll('.term-card:not(.no-results)'));\n",
        "        const termCountElement = document.getElementById('termCount');\n",
        "        const alphabetFilter = document.querySelector('.alphabet-filter');\n",
        "        const letterButtons = alphabetFilter.querySelectorAll('.letter-btn');\n",
        "        const clearFilterButton = document.getElementById('clearFilterButton');\n",
        "        const noResultsElement = glossaryGrid.querySelector('.no-results');\n",
        "\n",
        "        const totalTermsElement = document.getElementById('totalTerms');\n",
        "        const categoriesCountElement = document.getElementById('categoriesCount');\n",
        "        const visibleTermsElement = document.getElementById('visibleTerms');\n",
        "\n",
        "        let currentFilterLetter = null;\n",
        "\n",
        "        function countUniqueCategories() {\n",
        "            const categories = new Set();\n",
        "            termCards.forEach(card => {\n",
        "                const categoryElement = card.querySelector('.term-category');\n",
        "                if (categoryElement && categoryElement.textContent.trim() !== \"\") { // Ensure category exists and is not empty\n",
        "                    categories.add(categoryElement.textContent.trim());\n",
        "                }\n",
        "            });\n",
        "            return categories.size;\n",
        "        }\n",
        "\n",
        "        function updateStats(visibleCount) {\n",
        "            if (totalTermsElement) totalTermsElement.textContent = termCards.length;\n",
        "\n",
        "            const uniqueCategories = countUniqueCategories();\n",
        "            if (categoriesCountElement) categoriesCountElement.textContent = uniqueCategories > 0 ? uniqueCategories : \"N/A\"; // Show N/A if no categories\n",
        "\n",
        "            if (visibleTermsElement) visibleTermsElement.textContent = visibleCount;\n",
        "        }\n",
        "\n",
        "        function filterTerms() {\n",
        "            if (!searchInput || !glossaryGrid) return;\n",
        "            const searchTerm = searchInput.value.toLowerCase().trim();\n",
        "            let visibleCount = 0;\n",
        "\n",
        "            termCards.forEach(card => {\n",
        "                const termName = card.dataset.term.toLowerCase();\n",
        "                const termDefinitionElement = card.querySelector('.term-definition');\n",
        "                if (!termDefinitionElement) return;\n",
        "                const termDefinition = termDefinitionElement.textContent.toLowerCase();\n",
        "\n",
        "                const matchesSearch = termName.includes(searchTerm) || termDefinition.includes(searchTerm);\n",
        "                const matchesLetter = !currentFilterLetter || termName.startsWith(currentFilterLetter.toLowerCase());\n",
        "\n",
        "                if (matchesSearch && matchesLetter) {\n",
        "                    card.classList.remove('hidden');\n",
        "                    card.classList.add('visible');\n",
        "                    visibleCount++;\n",
        "                } else {\n",
        "                    card.classList.add('hidden');\n",
        "                    card.classList.remove('visible');\n",
        "                }\n",
        "            });\n",
        "\n",
        "            if(termCountElement) termCountElement.innerHTML = `<i class=\"fas fa-list-ul\"></i> ${visibleCount} término${visibleCount !== 1 ? 's' : ''} encontrado${visibleCount !== 1 ? 's' : ''}`;\n",
        "            updateStats(visibleCount);\n",
        "\n",
        "            if (noResultsElement) {\n",
        "                if (visibleCount === 0 && (searchTerm || currentFilterLetter)) {\n",
        "                    noResultsElement.classList.remove('hidden');\n",
        "                } else {\n",
        "                    noResultsElement.classList.add('hidden');\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function filterByLetter(letter) {\n",
        "            if (currentFilterLetter === letter) {\n",
        "                currentFilterLetter = null;\n",
        "                letterButtons.forEach(btn => btn.classList.remove('active'));\n",
        "            } else {\n",
        "                currentFilterLetter = letter;\n",
        "                letterButtons.forEach(btn => {\n",
        "                    btn.classList.toggle('active', btn.dataset.letter === letter);\n",
        "                });\n",
        "            }\n",
        "            filterTerms();\n",
        "        }\n",
        "\n",
        "        function clearAllFilters() {\n",
        "            if(searchInput) searchInput.value = '';\n",
        "            currentFilterLetter = null;\n",
        "            letterButtons.forEach(btn => btn.classList.remove('active'));\n",
        "            filterTerms();\n",
        "        }\n",
        "\n",
        "        if (themeToggleButton) {\n",
        "            themeToggleButton.addEventListener('click', toggleTheme);\n",
        "        }\n",
        "        if (searchInput) {\n",
        "            searchInput.addEventListener('input', filterTerms);\n",
        "        }\n",
        "        letterButtons.forEach(button => {\n",
        "            button.addEventListener('click', () => filterByLetter(button.dataset.letter));\n",
        "        });\n",
        "        if (clearFilterButton) {\n",
        "            clearFilterButton.addEventListener('click', clearAllFilters);\n",
        "        }\n",
        "\n",
        "        applyInitialTheme();\n",
        "        filterTerms(); // Initial filter to set up counts\n",
        "\n",
        "        // Set --card-index for staggered animation\n",
        "        termCards.forEach((card, index) => {\n",
        "            card.style.setProperty('--card-index', index);\n",
        "        });\n",
        "    })();\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Mostrar el HTML en la salida de la celda\n",
        "display(HTML(html_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QWbpJIwu9pwr",
        "outputId": "2f1491c5-5a39-4d23-9e6b-8d08e9a7c2d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "<head>\n",
              "  <meta charset=\"UTF-8\">\n",
              "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "  <title>10 Preguntas Clave sobre LLMs</title>\n",
              "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
              "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
              "  <style>\n",
              "    :root {\n",
              "      /* Tema claro */\n",
              "      --bg-primary-qa: linear-gradient(135deg, #52a7c1 0%, #2e7d8a 100%); /* Tonos azules/verdes */\n",
              "      --bg-secondary-qa: #ffffff;\n",
              "      --bg-tertiary-qa: #f0f9ff; /* Azul muy claro */\n",
              "      --text-primary-qa: #1e293b; /* Azul oscuro/gris */\n",
              "      --text-secondary-qa: #475569; /* Gris azulado */\n",
              "      --text-accent-qa: #0ea5e9; /* Azul cielo */\n",
              "      --border-color-qa: #cbd5e1; /* Gris claro */\n",
              "      --shadow-sm-qa: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n",
              "      --shadow-md-qa: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);\n",
              "      --shadow-lg-qa: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);\n",
              "\n",
              "      --color-blue-qa: #0ea5e9;\n",
              "      --color-green-qa: #22c55e;\n",
              "      --color-purple-qa: #8b5cf6;\n",
              "      --table-border-qa: #dee2e6;\n",
              "      --table-header-bg-qa: #e9ecef;\n",
              "    }\n",
              "\n",
              "    [data-theme=\"dark\"] {\n",
              "      --bg-primary-qa: linear-gradient(135deg, #1e3a8a 0%, #1e293b 100%); /* Azul oscuro a más oscuro */\n",
              "      --bg-secondary-qa: #1e293b; /* Azul muy oscuro */\n",
              "      --bg-tertiary-qa: #334155; /* Gris azulado oscuro */\n",
              "      --text-primary-qa: #e2e8f0; /* Gris muy claro */\n",
              "      --text-secondary-qa: #94a3b8; /* Gris claro */\n",
              "      --text-accent-qa: #38bdf8; /* Azul cielo más brillante */\n",
              "      --border-color-qa: #475569; /* Gris azulado oscuro */\n",
              "      --shadow-sm-qa: 0 1px 2px 0 rgba(0,0,0,0.2);\n",
              "      --shadow-md-qa: 0 4px 6px -1px rgba(0,0,0,0.25), 0 2px 4px -2px rgba(0,0,0,0.2);\n",
              "      --shadow-lg-qa: 0 10px 15px -3px rgba(0,0,0,0.25), 0 4px 6px -4px rgba(0,0,0,0.2);\n",
              "      --table-border-qa: #495057;\n",
              "      --table-header-bg-qa: #343a40;\n",
              "    }\n",
              "\n",
              "    * {\n",
              "      margin: 0;\n",
              "      padding: 0;\n",
              "      box-sizing: border-box;\n",
              "    }\n",
              "\n",
              "    html {\n",
              "        scroll-behavior: smooth;\n",
              "    }\n",
              "\n",
              "    body.qa-body { \n",
              "      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
              "      line-height: 1.8;\n",
              "      background: var(--bg-primary-qa);\n",
              "      color: var(--text-primary-qa);\n",
              "      min-height: 100vh;\n",
              "      overflow-x: hidden;\n",
              "      transition: background 0.3s ease, color 0.3s ease;\n",
              "    }\n",
              "\n",
              "    .qa-container {\n",
              "      max-width: 900px;\n",
              "      margin: 0 auto;\n",
              "      padding: 2rem;\n",
              "      position: relative;\n",
              "    }\n",
              "\n",
              "    .qa-header {\n",
              "      text-align: center;\n",
              "      margin-bottom: 2.5rem;\n",
              "      position: relative;\n",
              "      z-index: 10;\n",
              "    }\n",
              "\n",
              "    .qa-main-title {\n",
              "      font-size: clamp(2.2rem, 4.5vw, 3.2rem);\n",
              "      font-weight: 700;\n",
              "      background: linear-gradient(135deg, var(--color-blue-qa), var(--color-green-qa));\n",
              "      -webkit-background-clip: text;\n",
              "      -webkit-text-fill-color: transparent;\n",
              "      background-clip: text;\n",
              "      margin-bottom: 0.5rem;\n",
              "      position: relative;\n",
              "    }\n",
              "\n",
              "    .qa-subtitle {\n",
              "      font-size: 1.1rem;\n",
              "      color: var(--text-secondary-qa);\n",
              "      font-weight: 400;\n",
              "      max-width: 600px;\n",
              "      margin: 0 auto 1rem auto;\n",
              "    }\n",
              "\n",
              "    .qa-theme-toggle {\n",
              "      position: fixed;\n",
              "      top: 2rem;\n",
              "      right: 2rem;\n",
              "      width: 50px;\n",
              "      height: 50px;\n",
              "      border: 2px solid var(--border-color-qa);\n",
              "      border-radius: 50%;\n",
              "      background: var(--bg-secondary-qa);\n",
              "      box-shadow: var(--shadow-md-qa);\n",
              "      cursor: pointer;\n",
              "      display: flex;\n",
              "      align-items: center;\n",
              "      justify-content: center;\n",
              "      font-size: 1.25rem;\n",
              "      color: var(--text-primary-qa);\n",
              "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
              "      z-index: 1000;\n",
              "    }\n",
              "\n",
              "    .qa-theme-toggle:hover {\n",
              "      transform: translateY(-2px) scale(1.05);\n",
              "      box-shadow: var(--shadow-lg-qa);\n",
              "      background: var(--text-accent-qa);\n",
              "      color: white;\n",
              "    }\n",
              "\n",
              "    .qa-theme-icon {\n",
              "      transition: all 0.3s ease;\n",
              "      position: absolute;\n",
              "    }\n",
              "    .qa-theme-toggle .fa-sun { opacity: 0; transform: rotate(-90deg) scale(0.5); }\n",
              "    .qa-theme-toggle .fa-moon { opacity: 1; transform: rotate(0deg) scale(1); }\n",
              "    [data-theme=\"dark\"] .qa-theme-toggle .fa-moon { opacity: 0; transform: rotate(90deg) scale(0.5); }\n",
              "    [data-theme=\"dark\"] .qa-theme-toggle .fa-sun { opacity: 1; transform: rotate(0deg) scale(1); }\n",
              "\n",
              "\n",
              "    .qa-item {\n",
              "      background: var(--bg-secondary-qa);\n",
              "      margin-bottom: 1.5rem;\n",
              "      border-radius: 0.75rem;\n",
              "      box-shadow: var(--shadow-md-qa);\n",
              "      border: 1px solid var(--border-color-qa);\n",
              "      overflow: hidden;\n",
              "      transition: box-shadow 0.3s ease;\n",
              "    }\n",
              "    .qa-item:hover {\n",
              "        box-shadow: var(--shadow-lg-qa);\n",
              "    }\n",
              "\n",
              "    .qa-question-btn {\n",
              "      display: flex;\n",
              "      justify-content: space-between;\n",
              "      align-items: center;\n",
              "      width: 100%;\n",
              "      padding: 1.25rem 1.5rem;\n",
              "      background: var(--bg-tertiary-qa);\n",
              "      border: none;\n",
              "      text-align: left;\n",
              "      cursor: pointer;\n",
              "      transition: background-color 0.3s ease;\n",
              "    }\n",
              "    .qa-item.expanded .qa-question-btn {\n",
              "        background-color: var(--bg-secondary-qa);\n",
              "        border-bottom: 1px solid var(--border-color-qa); \n",
              "    }\n",
              "\n",
              "    .qa-question-btn:hover {\n",
              "      background-color: var(--bg-quaternary-qa, #eef2ff);\n",
              "    }\n",
              "    [data-theme=\"dark\"] .qa-question-btn:hover {\n",
              "        background-color: var(--bg-quaternary-qa, #3e4c5f);\n",
              "    }\n",
              "\n",
              "    .qa-question-text {\n",
              "      font-size: 1.1rem;\n",
              "      font-weight: 600;\n",
              "      color: var(--text-primary-qa);\n",
              "      margin-right: 1rem;\n",
              "    }\n",
              "\n",
              "    .qa-toggle-icon {\n",
              "      font-size: 1rem;\n",
              "      color: var(--text-accent-qa);\n",
              "      transition: transform 0.3s ease;\n",
              "      flex-shrink: 0;\n",
              "    }\n",
              "\n",
              "    .qa-item.expanded .qa-toggle-icon {\n",
              "      transform: rotate(45deg);\n",
              "    }\n",
              "\n",
              "    .qa-answer-panel {\n",
              "      padding: 1.5rem;\n",
              "      background: var(--bg-secondary-qa);\n",
              "      display: none;\n",
              "    }\n",
              "\n",
              "    .qa-answer-panel.visible {\n",
              "        display: block;\n",
              "        animation: fadeInAnswer 0.5s ease forwards;\n",
              "    }\n",
              "\n",
              "    @keyframes fadeInAnswer {\n",
              "        from { opacity: 0; transform: translateY(-10px); }\n",
              "        to { opacity: 1; transform: translateY(0); }\n",
              "    }\n",
              "\n",
              "    .qa-answer-panel p {\n",
              "      margin-bottom: 1em;\n",
              "      color: var(--text-primary-qa);\n",
              "    }\n",
              "    .qa-answer-panel p:last-child {\n",
              "      margin-bottom: 0;\n",
              "    }\n",
              "    .qa-answer-panel ul {\n",
              "        list-style-position: outside;\n",
              "        padding-left: 1.5rem;\n",
              "        margin-bottom: 1em;\n",
              "    }\n",
              "    .qa-answer-panel li {\n",
              "        margin-bottom: 0.5em;\n",
              "    }\n",
              "    .qa-answer-panel strong, .qa-answer-panel em {\n",
              "        color: var(--text-accent-qa);\n",
              "        font-weight: 600; \n",
              "    }\n",
              "    [data-theme=\"dark\"] .qa-answer-panel strong, [data-theme=\"dark\"] .qa-answer-panel em {\n",
              "        color: var(--color-blue-qa);\n",
              "    }\n",
              "    \n",
              "    /* Estilos para tablas */\n",
              "    .qa-answer-panel table {\n",
              "        width: 100%;\n",
              "        margin-bottom: 1rem;\n",
              "        border-collapse: collapse;\n",
              "        color: var(--text-primary-qa);\n",
              "    }\n",
              "    .qa-answer-panel th, .qa-answer-panel td {\n",
              "        padding: 0.75rem;\n",
              "        text-align: left;\n",
              "        border: 1px solid var(--table-border-qa);\n",
              "    }\n",
              "    .qa-answer-panel th {\n",
              "        background-color: var(--table-header-bg-qa);\n",
              "        font-weight: 600;\n",
              "    }\n",
              "    .qa-answer-panel tr:nth-child(even) {\n",
              "        background-color: var(--bg-tertiary-qa);\n",
              "    }\n",
              "    [data-theme=\"dark\"] .qa-answer-panel tr:nth-child(even) {\n",
              "        background-color: #32383e; /* Un poco más oscuro que el terciario para tema oscuro */\n",
              "    }\n",
              "\n",
              "\n",
              "    .fade-in {\n",
              "      opacity: 0;\n",
              "      transform: translateY(20px);\n",
              "      animation: fadeInUp 0.6s ease forwards;\n",
              "    }\n",
              "\n",
              "    .qa-item.fade-in {\n",
              "        animation: fadeInUp 0.6s ease forwards;\n",
              "        animation-delay: calc(var(--item-index) * 0.07s); /* Un poco más rápido para 10 items */\n",
              "    }\n",
              "\n",
              "    @keyframes fadeInUp {\n",
              "      to {\n",
              "        opacity: 1;\n",
              "        transform: translateY(0);\n",
              "      }\n",
              "    }\n",
              "     @media (max-width: 768px) {\n",
              "      .qa-container { padding: 1.5rem 1rem; }\n",
              "      .qa-main-title { font-size: 1.8rem; }\n",
              "      .qa-subtitle { font-size: 1rem; }\n",
              "      .qa-theme-toggle { top: 1rem; right: 1rem; width: 45px; height: 45px; font-size: 1.1rem;}\n",
              "      .qa-question-text { font-size: 1rem; }\n",
              "      .qa-answer-panel table { font-size: 0.9rem; }\n",
              "      .qa-answer-panel th, .qa-answer-panel td { padding: 0.5rem; }\n",
              "    }\n",
              "\n",
              "  </style>\n",
              "</head>\n",
              "<body class=\"qa-body\" data-theme=\"light\">\n",
              "\n",
              "  <button class=\"qa-theme-toggle\" id=\"qaThemeToggleButton\" title=\"Cambiar tema\" aria-label=\"Cambiar tema\">\n",
              "    <i class=\"fas fa-moon qa-theme-icon\"></i>\n",
              "    <i class=\"fas fa-sun qa-theme-icon\"></i>\n",
              "  </button>\n",
              "\n",
              "  <div class=\"qa-container\">\n",
              "    <header class=\"qa-header\">\n",
              "      <h1 class=\"qa-main-title fade-in\">10 Preguntas Clave sobre LLMs</h1>\n",
              "      <p class=\"qa-subtitle fade-in\">Conceptos Fundamentales de Modelos de Lenguaje Grandes</p>\n",
              "    </header>\n",
              "\n",
              "    <div id=\"qaAccordion\">\n",
              "      <!-- Pregunta 1 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 0;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer1\">\n",
              "          <span class=\"qa-question-text\">1. ¿Qué es el <strong>pre-entrenamiento</strong> de un modelo de lenguaje y cuál es su objetivo principal?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer1\" class=\"qa-answer-panel\">\n",
              "          <p>El pre-entrenamiento es la fase inicial, masiva y <strong>auto-supervisada</strong> en la que un LLM aprende a modelar el lenguaje a partir de un corpus gigantesco y sin etiquetas humanas.</p>\n",
              "          <ul>\n",
              "            <li><strong>Objetivo central:</strong> dotar al modelo de una comprensión amplia de sintaxis, semántica y conocimiento del mundo, construyendo representaciones internas (embeddings) que luego se reutilizan para tareas específicas.</li>\n",
              "            <li>Se entrena con tareas “pretexto” — por ejemplo, predecir la siguiente palabra (CLM) o rellenar palabras enmascaradas (MLM)— optimizando miles de millones de parámetros.</li>\n",
              "          </ul>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 2 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 1;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer2\">\n",
              "          <span class=\"qa-question-text\">2. ¿En qué se diferencian las tareas de <strong>CLM (Causal Language Modeling)</strong> y <strong>MLM (Masked Language Modeling)</strong>?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer2\" class=\"qa-answer-panel\">\n",
              "          <table>\n",
              "            <thead>\n",
              "              <tr>\n",
              "                <th>Aspecto</th>\n",
              "                <th>CLM</th>\n",
              "                <th>MLM</th>\n",
              "              </tr>\n",
              "            </thead>\n",
              "            <tbody>\n",
              "              <tr>\n",
              "                <td>Dirección del contexto</td>\n",
              "                <td>Solo tokens anteriores</td>\n",
              "                <td>Tokens a izquierda y derecha</td>\n",
              "              </tr>\n",
              "              <tr>\n",
              "                <td>Ejemplo típico</td>\n",
              "                <td>GPT</td>\n",
              "                <td>BERT</td>\n",
              "              </tr>\n",
              "              <tr>\n",
              "                <td>Ventaja</td>\n",
              "                <td>Natural para generación de texto</td>\n",
              "                <td>Representaciones bidireccionales más ricas</td>\n",
              "              </tr>\n",
              "              <tr>\n",
              "                <td>Limitación</td>\n",
              "                <td>No ve el futuro, puede perder coherencia global</td>\n",
              "                <td>No sirve directamente para generación autoregresiva</td>\n",
              "              </tr>\n",
              "            </tbody>\n",
              "          </table>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 3 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 2;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer3\">\n",
              "          <span class=\"qa-question-text\">3. Describe la arquitectura <strong>Transformer</strong> y la función del mecanismo de <strong>auto-atención</strong>.</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer3\" class=\"qa-answer-panel\">\n",
              "          <p>El Transformer está formado por bloques repetidos con dos subcapas principales:</p>\n",
              "          <ol>\n",
              "            <li><strong>Multi-Head Self-Attention:</strong> calcula, en paralelo, cuánto debe “mirar” cada token a los demás. Permite capturar dependencias largas con complejidad menor que los RNN y procesar todos los tokens simultáneamente.</li>\n",
              "            <li><strong>Feed-Forward Network:</strong> aplica transformaciones no lineales independientes por posición.</li>\n",
              "          </ol>\n",
              "          <p>Añade normalización de capas y conexiones residuales, lo que facilita el entrenamiento profundo.</p>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 4 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 3;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer4\">\n",
              "          <span class=\"qa-question-text\">4. Explica el <strong>flujo interno</strong> completo que sigue un prompt hasta generar la respuesta.</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer4\" class=\"qa-answer-panel\">\n",
              "          <ol>\n",
              "            <li><strong>Tokenización:</strong> se descompone el texto en tokens y se convierten a IDs numéricos.</li>\n",
              "            <li><strong>Embeddings:</strong> cada ID se mapea a un vector denso en el espacio latente.</li>\n",
              "            <li><strong>Procesamiento contextual (Transformer):</strong> las capas de auto-atención refinan los vectores incorporando contexto global.</li>\n",
              "            <li><strong>Generación autoregresiva:</strong> el modelo produce la distribución de probabilidad y elige el siguiente token.</li>\n",
              "            <li><strong>Decodificación:</strong> los IDs generados se transforman de nuevo en texto legible.</li>\n",
              "          </ol>\n",
              "          <p>El ciclo 3–5 se repite hasta que se emite el token de finalización o se alcanza la longitud máxima.</p>\n",
              "        </div>\n",
              "      </div>\n",
              "      \n",
              "      <!-- Pregunta 5 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 4;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer5\">\n",
              "          <span class=\"qa-question-text\">5. ¿Qué es el <strong>fine-tuning</strong> y por qué resulta menos costoso que entrenar desde cero?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer5\" class=\"qa-answer-panel\">\n",
              "          <p>El fine-tuning consiste en tomar un LLM ya pre-entrenado y ajustarlo con un <strong>corpus mucho más pequeño y etiquetado</strong> para una tarea concreta (clasificación de sentimientos, QA médico, etc.).</p>\n",
              "          <ul>\n",
              "            <li>Requiere menos datos y computación porque parte de representaciones generales sólidas.</li>\n",
              "            <li>Suele emplear unas pocas épocas y puede hacerse en hardware más modesto que el usado para el pre-entrenamiento.</li>\n",
              "          </ul>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 6 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 5;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer6\">\n",
              "          <span class=\"qa-question-text\">6. Cita <strong>tres impactos</strong> positivos y <strong>tres desafíos</strong> éticos o técnicos asociados a los LLM.</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer6\" class=\"qa-answer-panel\">\n",
              "          <p><strong>Impactos:</strong></p>\n",
              "          <ol>\n",
              "            <li>Superan el estado del arte en múltiples benchmarks de NLP.</li>\n",
              "            <li>Democratizan capacidades avanzadas mediante modelos liberados para la comunidad.</li>\n",
              "            <li>Habilitan nuevas aplicaciones creativas (p. ej., generación de código, chat conversacional).</li>\n",
              "          </ol>\n",
              "          <p><strong>Desafíos:</strong></p>\n",
              "          <ol>\n",
              "            <li><strong>Sesgos</strong> aprendidos del corpus que pueden reforzar estereotipos.</li>\n",
              "            <li><strong>Costo computacional y ambiental</strong> del entrenamiento a escala.</li>\n",
              "            <li>Dificultad de <strong>interpretabilidad</strong>, ya que actúan como “cajas negras”.</li>\n",
              "          </ol>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 7 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 6;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer7\">\n",
              "          <span class=\"qa-question-text\">7. En el ejemplo práctico del PDF, ¿por qué el modelo predice “azul” tras “El sol brilla intensamente en el cielo…”?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer7\" class=\"qa-answer-panel\">\n",
              "          <p>Porque tras ver millones de oraciones similares durante el pre-entrenamiento, el modelo ha aprendido una correlación estadística fuerte entre la frase y la palabra “azul”. No “sabe” que el cielo es azul como una verdad consciente, sino que <strong>internaliza la probabilidad</strong> de esa secuencia de tokens.</p>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 8 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 7;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer8\">\n",
              "          <span class=\"qa-question-text\">8. Define “<strong>prompt</strong>” y explica dos buenas prácticas de <strong>ingeniería de prompts</strong> para obtener mejores respuestas.</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer8\" class=\"qa-answer-panel\">\n",
              "          <p>Un prompt es el <strong>texto inicial o instrucción</strong> que se envía al LLM y determina el contexto, tono y formato de la salida.</p>\n",
              "          <p><strong>Buenas prácticas:</strong></p>\n",
              "          <ul>\n",
              "            <li>Ser <strong>específico y claro</strong>: indicar la tarea, el formato deseado y cualquier restricción (longitud, estilo).</li>\n",
              "            <li>Incluir <strong>ejemplos</strong> (few-shot) o un sistema-mensaje que defina el rol del modelo para reducir ambigüedad y mejorar la alineación con la intención.</li>\n",
              "          </ul>\n",
              "        </div>\n",
              "      </div>\n",
              "      \n",
              "      <!-- Pregunta 9 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 8;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer9\">\n",
              "          <span class=\"qa-question-text\">9. ¿Qué es la <strong>ventana de contexto</strong> y cómo limita el uso de un LLM?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer9\" class=\"qa-answer-panel\">\n",
              "          <p>Es el número máximo de tokens (entrada + salida) que el modelo puede procesar en un único paso.</p>\n",
              "          <ul>\n",
              "            <li>Si se supera, se debe truncar o resumir la conversación, lo que puede causar pérdida de información.</li>\n",
              "            <li>Ventanas más grandes incrementan el consumo de memoria y tiempo de inferencia.</li>\n",
              "          </ul>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "      <!-- Pregunta 10 -->\n",
              "      <div class=\"qa-item fade-in\" style=\"--item-index: 9;\">\n",
              "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer10\">\n",
              "          <span class=\"qa-question-text\">10. ¿Qué son los <strong>embeddings</strong> y cómo permiten realizar analogías vectoriales?</span>\n",
              "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
              "        </button>\n",
              "        <div id=\"answer10\" class=\"qa-answer-panel\">\n",
              "          <p>Los embeddings son vectores densos aprendidos que codifican información semántica y sintáctica sobre tokens.</p>\n",
              "          <ul>\n",
              "            <li>Tokens con significados similares aparecen <strong>cerca</strong> en el espacio latente.</li>\n",
              "            <li>La estructura geométrica posibilita analogías: la dirección “rey → reina” es similar a “hombre → mujer”.</li>\n",
              "          </ul>\n",
              "          <p>Esto surge porque el entrenamiento optimiza para predecir tokens en muchos contextos distintos, alineando gradualmente relaciones semánticas.</p>\n",
              "        </div>\n",
              "      </div>\n",
              "\n",
              "    </div> <!-- Fin de qaAccordion -->\n",
              "  </div> <!-- Fin de qa-container -->\n",
              "\n",
              "  <script>\n",
              "    (function() {\n",
              "        let qaCurrentSessionTheme = 'light';\n",
              "\n",
              "        function qaApplyInitialTheme() {\n",
              "            document.body.setAttribute('data-theme', qaCurrentSessionTheme);\n",
              "        }\n",
              "\n",
              "        function qaToggleTheme() {\n",
              "            const currentThemeFromBody = document.body.getAttribute('data-theme');\n",
              "            const newTheme = currentThemeFromBody === 'dark' ? 'light' : 'dark';\n",
              "            document.body.setAttribute('data-theme', newTheme);\n",
              "            qaCurrentSessionTheme = newTheme;\n",
              "        }\n",
              "\n",
              "        const qaThemeToggleButton = document.getElementById('qaThemeToggleButton');\n",
              "        if (qaThemeToggleButton) {\n",
              "            qaThemeToggleButton.addEventListener('click', qaToggleTheme);\n",
              "        }\n",
              "\n",
              "        const qaAccordion = document.getElementById('qaAccordion');\n",
              "        if (qaAccordion) {\n",
              "            const qaItems = qaAccordion.querySelectorAll('.qa-item');\n",
              "            qaItems.forEach((item, index) => {\n",
              "                item.style.setProperty('--item-index', index);\n",
              "                const btn = item.querySelector('.qa-question-btn');\n",
              "                const panel = item.querySelector('.qa-answer-panel');\n",
              "                const icon = btn.querySelector('.qa-toggle-icon');\n",
              "\n",
              "                if (btn && panel && icon) {\n",
              "                    btn.addEventListener('click', () => {\n",
              "                        const isExpanded = btn.getAttribute('aria-expanded') === 'true';\n",
              "                        \n",
              "                        // Opcional: cerrar otros paneles (descomentar para activar)\n",
              "                        /* \n",
              "                        if (!isExpanded) { // Solo si se va a expandir este\n",
              "                            qaItems.forEach(otherItem => {\n",
              "                                if (otherItem !== item) {\n",
              "                                    const otherBtn = otherItem.querySelector('.qa-question-btn');\n",
              "                                    const otherPanel = otherItem.querySelector('.qa-answer-panel');\n",
              "                                    const otherIcon = otherItem.querySelector('.qa-toggle-icon');\n",
              "                                    if (otherBtn.getAttribute('aria-expanded') === 'true') {\n",
              "                                        otherBtn.setAttribute('aria-expanded', 'false');\n",
              "                                        otherPanel.classList.remove('visible');\n",
              "                                        otherItem.classList.remove('expanded');\n",
              "                                        otherIcon.classList.remove('fa-minus');\n",
              "                                        otherIcon.classList.add('fa-plus');\n",
              "                                    }\n",
              "                                }\n",
              "                            });\n",
              "                        }\n",
              "                        */\n",
              "\n",
              "                        btn.setAttribute('aria-expanded', !isExpanded);\n",
              "                        panel.classList.toggle('visible');\n",
              "                        item.classList.toggle('expanded');\n",
              "\n",
              "                        if (!isExpanded) {\n",
              "                            icon.classList.remove('fa-plus');\n",
              "                            icon.classList.add('fa-minus');\n",
              "                        } else {\n",
              "                            icon.classList.remove('fa-minus');\n",
              "                            icon.classList.add('fa-plus');\n",
              "                        }\n",
              "                    });\n",
              "                }\n",
              "            });\n",
              "        }\n",
              "\n",
              "        qaApplyInitialTheme();\n",
              "    })();\n",
              "  </script>\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Importar las funciones necesarias de IPython para mostrar HTML\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Definir el contenido HTML de Preguntas y Respuestas\n",
        "html_content_qa = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"es\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>10 Preguntas Clave sobre LLMs</title>\n",
        "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap\" rel=\"stylesheet\">\n",
        "  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
        "  <style>\n",
        "    :root {\n",
        "      /* Tema claro */\n",
        "      --bg-primary-qa: linear-gradient(135deg, #52a7c1 0%, #2e7d8a 100%); /* Tonos azules/verdes */\n",
        "      --bg-secondary-qa: #ffffff;\n",
        "      --bg-tertiary-qa: #f0f9ff; /* Azul muy claro */\n",
        "      --text-primary-qa: #1e293b; /* Azul oscuro/gris */\n",
        "      --text-secondary-qa: #475569; /* Gris azulado */\n",
        "      --text-accent-qa: #0ea5e9; /* Azul cielo */\n",
        "      --border-color-qa: #cbd5e1; /* Gris claro */\n",
        "      --shadow-sm-qa: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n",
        "      --shadow-md-qa: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);\n",
        "      --shadow-lg-qa: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);\n",
        "\n",
        "      --color-blue-qa: #0ea5e9;\n",
        "      --color-green-qa: #22c55e;\n",
        "      --color-purple-qa: #8b5cf6;\n",
        "      --table-border-qa: #dee2e6;\n",
        "      --table-header-bg-qa: #e9ecef;\n",
        "    }\n",
        "\n",
        "    [data-theme=\"dark\"] {\n",
        "      --bg-primary-qa: linear-gradient(135deg, #1e3a8a 0%, #1e293b 100%); /* Azul oscuro a más oscuro */\n",
        "      --bg-secondary-qa: #1e293b; /* Azul muy oscuro */\n",
        "      --bg-tertiary-qa: #334155; /* Gris azulado oscuro */\n",
        "      --text-primary-qa: #e2e8f0; /* Gris muy claro */\n",
        "      --text-secondary-qa: #94a3b8; /* Gris claro */\n",
        "      --text-accent-qa: #38bdf8; /* Azul cielo más brillante */\n",
        "      --border-color-qa: #475569; /* Gris azulado oscuro */\n",
        "      --shadow-sm-qa: 0 1px 2px 0 rgba(0,0,0,0.2);\n",
        "      --shadow-md-qa: 0 4px 6px -1px rgba(0,0,0,0.25), 0 2px 4px -2px rgba(0,0,0,0.2);\n",
        "      --shadow-lg-qa: 0 10px 15px -3px rgba(0,0,0,0.25), 0 4px 6px -4px rgba(0,0,0,0.2);\n",
        "      --table-border-qa: #495057;\n",
        "      --table-header-bg-qa: #343a40;\n",
        "    }\n",
        "\n",
        "    * {\n",
        "      margin: 0;\n",
        "      padding: 0;\n",
        "      box-sizing: border-box;\n",
        "    }\n",
        "\n",
        "    html {\n",
        "        scroll-behavior: smooth;\n",
        "    }\n",
        "\n",
        "    body.qa-body {\n",
        "      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
        "      line-height: 1.8;\n",
        "      background: var(--bg-primary-qa);\n",
        "      color: var(--text-primary-qa);\n",
        "      min-height: 100vh;\n",
        "      overflow-x: hidden;\n",
        "      transition: background 0.3s ease, color 0.3s ease;\n",
        "    }\n",
        "\n",
        "    .qa-container {\n",
        "      max-width: 900px;\n",
        "      margin: 0 auto;\n",
        "      padding: 2rem;\n",
        "      position: relative;\n",
        "    }\n",
        "\n",
        "    .qa-header {\n",
        "      text-align: center;\n",
        "      margin-bottom: 2.5rem;\n",
        "      position: relative;\n",
        "      z-index: 10;\n",
        "    }\n",
        "\n",
        "    .qa-main-title {\n",
        "      font-size: clamp(2.2rem, 4.5vw, 3.2rem);\n",
        "      font-weight: 700;\n",
        "      background: linear-gradient(135deg, var(--color-blue-qa), var(--color-green-qa));\n",
        "      -webkit-background-clip: text;\n",
        "      -webkit-text-fill-color: transparent;\n",
        "      background-clip: text;\n",
        "      margin-bottom: 0.5rem;\n",
        "      position: relative;\n",
        "    }\n",
        "\n",
        "    .qa-subtitle {\n",
        "      font-size: 1.1rem;\n",
        "      color: var(--text-secondary-qa);\n",
        "      font-weight: 400;\n",
        "      max-width: 600px;\n",
        "      margin: 0 auto 1rem auto;\n",
        "    }\n",
        "\n",
        "    .qa-theme-toggle {\n",
        "      position: fixed;\n",
        "      top: 2rem;\n",
        "      right: 2rem;\n",
        "      width: 50px;\n",
        "      height: 50px;\n",
        "      border: 2px solid var(--border-color-qa);\n",
        "      border-radius: 50%;\n",
        "      background: var(--bg-secondary-qa);\n",
        "      box-shadow: var(--shadow-md-qa);\n",
        "      cursor: pointer;\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "      justify-content: center;\n",
        "      font-size: 1.25rem;\n",
        "      color: var(--text-primary-qa);\n",
        "      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "      z-index: 1000;\n",
        "    }\n",
        "\n",
        "    .qa-theme-toggle:hover {\n",
        "      transform: translateY(-2px) scale(1.05);\n",
        "      box-shadow: var(--shadow-lg-qa);\n",
        "      background: var(--text-accent-qa);\n",
        "      color: white;\n",
        "    }\n",
        "\n",
        "    .qa-theme-icon {\n",
        "      transition: all 0.3s ease;\n",
        "      position: absolute;\n",
        "    }\n",
        "    .qa-theme-toggle .fa-sun { opacity: 0; transform: rotate(-90deg) scale(0.5); }\n",
        "    .qa-theme-toggle .fa-moon { opacity: 1; transform: rotate(0deg) scale(1); }\n",
        "    [data-theme=\"dark\"] .qa-theme-toggle .fa-moon { opacity: 0; transform: rotate(90deg) scale(0.5); }\n",
        "    [data-theme=\"dark\"] .qa-theme-toggle .fa-sun { opacity: 1; transform: rotate(0deg) scale(1); }\n",
        "\n",
        "\n",
        "    .qa-item {\n",
        "      background: var(--bg-secondary-qa);\n",
        "      margin-bottom: 1.5rem;\n",
        "      border-radius: 0.75rem;\n",
        "      box-shadow: var(--shadow-md-qa);\n",
        "      border: 1px solid var(--border-color-qa);\n",
        "      overflow: hidden;\n",
        "      transition: box-shadow 0.3s ease;\n",
        "    }\n",
        "    .qa-item:hover {\n",
        "        box-shadow: var(--shadow-lg-qa);\n",
        "    }\n",
        "\n",
        "    .qa-question-btn {\n",
        "      display: flex;\n",
        "      justify-content: space-between;\n",
        "      align-items: center;\n",
        "      width: 100%;\n",
        "      padding: 1.25rem 1.5rem;\n",
        "      background: var(--bg-tertiary-qa);\n",
        "      border: none;\n",
        "      text-align: left;\n",
        "      cursor: pointer;\n",
        "      transition: background-color 0.3s ease;\n",
        "    }\n",
        "    .qa-item.expanded .qa-question-btn {\n",
        "        background-color: var(--bg-secondary-qa);\n",
        "        border-bottom: 1px solid var(--border-color-qa);\n",
        "    }\n",
        "\n",
        "    .qa-question-btn:hover {\n",
        "      background-color: var(--bg-quaternary-qa, #eef2ff);\n",
        "    }\n",
        "    [data-theme=\"dark\"] .qa-question-btn:hover {\n",
        "        background-color: var(--bg-quaternary-qa, #3e4c5f);\n",
        "    }\n",
        "\n",
        "    .qa-question-text {\n",
        "      font-size: 1.1rem;\n",
        "      font-weight: 600;\n",
        "      color: var(--text-primary-qa);\n",
        "      margin-right: 1rem;\n",
        "    }\n",
        "\n",
        "    .qa-toggle-icon {\n",
        "      font-size: 1rem;\n",
        "      color: var(--text-accent-qa);\n",
        "      transition: transform 0.3s ease;\n",
        "      flex-shrink: 0;\n",
        "    }\n",
        "\n",
        "    .qa-item.expanded .qa-toggle-icon {\n",
        "      transform: rotate(45deg);\n",
        "    }\n",
        "\n",
        "    .qa-answer-panel {\n",
        "      padding: 1.5rem;\n",
        "      background: var(--bg-secondary-qa);\n",
        "      display: none;\n",
        "    }\n",
        "\n",
        "    .qa-answer-panel.visible {\n",
        "        display: block;\n",
        "        animation: fadeInAnswer 0.5s ease forwards;\n",
        "    }\n",
        "\n",
        "    @keyframes fadeInAnswer {\n",
        "        from { opacity: 0; transform: translateY(-10px); }\n",
        "        to { opacity: 1; transform: translateY(0); }\n",
        "    }\n",
        "\n",
        "    .qa-answer-panel p {\n",
        "      margin-bottom: 1em;\n",
        "      color: var(--text-primary-qa);\n",
        "    }\n",
        "    .qa-answer-panel p:last-child {\n",
        "      margin-bottom: 0;\n",
        "    }\n",
        "    .qa-answer-panel ul {\n",
        "        list-style-position: outside;\n",
        "        padding-left: 1.5rem;\n",
        "        margin-bottom: 1em;\n",
        "    }\n",
        "    .qa-answer-panel li {\n",
        "        margin-bottom: 0.5em;\n",
        "    }\n",
        "    .qa-answer-panel strong, .qa-answer-panel em {\n",
        "        color: var(--text-accent-qa);\n",
        "        font-weight: 600;\n",
        "    }\n",
        "    [data-theme=\"dark\"] .qa-answer-panel strong, [data-theme=\"dark\"] .qa-answer-panel em {\n",
        "        color: var(--color-blue-qa);\n",
        "    }\n",
        "\n",
        "    /* Estilos para tablas */\n",
        "    .qa-answer-panel table {\n",
        "        width: 100%;\n",
        "        margin-bottom: 1rem;\n",
        "        border-collapse: collapse;\n",
        "        color: var(--text-primary-qa);\n",
        "    }\n",
        "    .qa-answer-panel th, .qa-answer-panel td {\n",
        "        padding: 0.75rem;\n",
        "        text-align: left;\n",
        "        border: 1px solid var(--table-border-qa);\n",
        "    }\n",
        "    .qa-answer-panel th {\n",
        "        background-color: var(--table-header-bg-qa);\n",
        "        font-weight: 600;\n",
        "    }\n",
        "    .qa-answer-panel tr:nth-child(even) {\n",
        "        background-color: var(--bg-tertiary-qa);\n",
        "    }\n",
        "    [data-theme=\"dark\"] .qa-answer-panel tr:nth-child(even) {\n",
        "        background-color: #32383e; /* Un poco más oscuro que el terciario para tema oscuro */\n",
        "    }\n",
        "\n",
        "\n",
        "    .fade-in {\n",
        "      opacity: 0;\n",
        "      transform: translateY(20px);\n",
        "      animation: fadeInUp 0.6s ease forwards;\n",
        "    }\n",
        "\n",
        "    .qa-item.fade-in {\n",
        "        animation: fadeInUp 0.6s ease forwards;\n",
        "        animation-delay: calc(var(--item-index) * 0.07s); /* Un poco más rápido para 10 items */\n",
        "    }\n",
        "\n",
        "    @keyframes fadeInUp {\n",
        "      to {\n",
        "        opacity: 1;\n",
        "        transform: translateY(0);\n",
        "      }\n",
        "    }\n",
        "     @media (max-width: 768px) {\n",
        "      .qa-container { padding: 1.5rem 1rem; }\n",
        "      .qa-main-title { font-size: 1.8rem; }\n",
        "      .qa-subtitle { font-size: 1rem; }\n",
        "      .qa-theme-toggle { top: 1rem; right: 1rem; width: 45px; height: 45px; font-size: 1.1rem;}\n",
        "      .qa-question-text { font-size: 1rem; }\n",
        "      .qa-answer-panel table { font-size: 0.9rem; }\n",
        "      .qa-answer-panel th, .qa-answer-panel td { padding: 0.5rem; }\n",
        "    }\n",
        "\n",
        "  </style>\n",
        "</head>\n",
        "<body class=\"qa-body\" data-theme=\"light\">\n",
        "\n",
        "  <button class=\"qa-theme-toggle\" id=\"qaThemeToggleButton\" title=\"Cambiar tema\" aria-label=\"Cambiar tema\">\n",
        "    <i class=\"fas fa-moon qa-theme-icon\"></i>\n",
        "    <i class=\"fas fa-sun qa-theme-icon\"></i>\n",
        "  </button>\n",
        "\n",
        "  <div class=\"qa-container\">\n",
        "    <header class=\"qa-header\">\n",
        "      <h1 class=\"qa-main-title fade-in\">10 Preguntas Clave sobre LLMs</h1>\n",
        "      <p class=\"qa-subtitle fade-in\">Conceptos Fundamentales de Modelos de Lenguaje Grandes</p>\n",
        "    </header>\n",
        "\n",
        "    <div id=\"qaAccordion\">\n",
        "      <!-- Pregunta 1 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 0;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer1\">\n",
        "          <span class=\"qa-question-text\">1. ¿Qué es el <strong>pre-entrenamiento</strong> de un modelo de lenguaje y cuál es su objetivo principal?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer1\" class=\"qa-answer-panel\">\n",
        "          <p>El pre-entrenamiento es la fase inicial, masiva y <strong>auto-supervisada</strong> en la que un LLM aprende a modelar el lenguaje a partir de un corpus gigantesco y sin etiquetas humanas.</p>\n",
        "          <ul>\n",
        "            <li><strong>Objetivo central:</strong> dotar al modelo de una comprensión amplia de sintaxis, semántica y conocimiento del mundo, construyendo representaciones internas (embeddings) que luego se reutilizan para tareas específicas.</li>\n",
        "            <li>Se entrena con tareas “pretexto” — por ejemplo, predecir la siguiente palabra (CLM) o rellenar palabras enmascaradas (MLM)— optimizando miles de millones de parámetros.</li>\n",
        "          </ul>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 2 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 1;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer2\">\n",
        "          <span class=\"qa-question-text\">2. ¿En qué se diferencian las tareas de <strong>CLM (Causal Language Modeling)</strong> y <strong>MLM (Masked Language Modeling)</strong>?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer2\" class=\"qa-answer-panel\">\n",
        "          <table>\n",
        "            <thead>\n",
        "              <tr>\n",
        "                <th>Aspecto</th>\n",
        "                <th>CLM</th>\n",
        "                <th>MLM</th>\n",
        "              </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "              <tr>\n",
        "                <td>Dirección del contexto</td>\n",
        "                <td>Solo tokens anteriores</td>\n",
        "                <td>Tokens a izquierda y derecha</td>\n",
        "              </tr>\n",
        "              <tr>\n",
        "                <td>Ejemplo típico</td>\n",
        "                <td>GPT</td>\n",
        "                <td>BERT</td>\n",
        "              </tr>\n",
        "              <tr>\n",
        "                <td>Ventaja</td>\n",
        "                <td>Natural para generación de texto</td>\n",
        "                <td>Representaciones bidireccionales más ricas</td>\n",
        "              </tr>\n",
        "              <tr>\n",
        "                <td>Limitación</td>\n",
        "                <td>No ve el futuro, puede perder coherencia global</td>\n",
        "                <td>No sirve directamente para generación autoregresiva</td>\n",
        "              </tr>\n",
        "            </tbody>\n",
        "          </table>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 3 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 2;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer3\">\n",
        "          <span class=\"qa-question-text\">3. Describe la arquitectura <strong>Transformer</strong> y la función del mecanismo de <strong>auto-atención</strong>.</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer3\" class=\"qa-answer-panel\">\n",
        "          <p>El Transformer está formado por bloques repetidos con dos subcapas principales:</p>\n",
        "          <ol>\n",
        "            <li><strong>Multi-Head Self-Attention:</strong> calcula, en paralelo, cuánto debe “mirar” cada token a los demás. Permite capturar dependencias largas con complejidad menor que los RNN y procesar todos los tokens simultáneamente.</li>\n",
        "            <li><strong>Feed-Forward Network:</strong> aplica transformaciones no lineales independientes por posición.</li>\n",
        "          </ol>\n",
        "          <p>Añade normalización de capas y conexiones residuales, lo que facilita el entrenamiento profundo.</p>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 4 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 3;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer4\">\n",
        "          <span class=\"qa-question-text\">4. Explica el <strong>flujo interno</strong> completo que sigue un prompt hasta generar la respuesta.</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer4\" class=\"qa-answer-panel\">\n",
        "          <ol>\n",
        "            <li><strong>Tokenización:</strong> se descompone el texto en tokens y se convierten a IDs numéricos.</li>\n",
        "            <li><strong>Embeddings:</strong> cada ID se mapea a un vector denso en el espacio latente.</li>\n",
        "            <li><strong>Procesamiento contextual (Transformer):</strong> las capas de auto-atención refinan los vectores incorporando contexto global.</li>\n",
        "            <li><strong>Generación autoregresiva:</strong> el modelo produce la distribución de probabilidad y elige el siguiente token.</li>\n",
        "            <li><strong>Decodificación:</strong> los IDs generados se transforman de nuevo en texto legible.</li>\n",
        "          </ol>\n",
        "          <p>El ciclo 3–5 se repite hasta que se emite el token de finalización o se alcanza la longitud máxima.</p>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 5 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 4;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer5\">\n",
        "          <span class=\"qa-question-text\">5. ¿Qué es el <strong>fine-tuning</strong> y por qué resulta menos costoso que entrenar desde cero?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer5\" class=\"qa-answer-panel\">\n",
        "          <p>El fine-tuning consiste en tomar un LLM ya pre-entrenado y ajustarlo con un <strong>corpus mucho más pequeño y etiquetado</strong> para una tarea concreta (clasificación de sentimientos, QA médico, etc.).</p>\n",
        "          <ul>\n",
        "            <li>Requiere menos datos y computación porque parte de representaciones generales sólidas.</li>\n",
        "            <li>Suele emplear unas pocas épocas y puede hacerse en hardware más modesto que el usado para el pre-entrenamiento.</li>\n",
        "          </ul>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 6 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 5;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer6\">\n",
        "          <span class=\"qa-question-text\">6. Cita <strong>tres impactos</strong> positivos y <strong>tres desafíos</strong> éticos o técnicos asociados a los LLM.</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer6\" class=\"qa-answer-panel\">\n",
        "          <p><strong>Impactos:</strong></p>\n",
        "          <ol>\n",
        "            <li>Superan el estado del arte en múltiples benchmarks de NLP.</li>\n",
        "            <li>Democratizan capacidades avanzadas mediante modelos liberados para la comunidad.</li>\n",
        "            <li>Habilitan nuevas aplicaciones creativas (p. ej., generación de código, chat conversacional).</li>\n",
        "          </ol>\n",
        "          <p><strong>Desafíos:</strong></p>\n",
        "          <ol>\n",
        "            <li><strong>Sesgos</strong> aprendidos del corpus que pueden reforzar estereotipos.</li>\n",
        "            <li><strong>Costo computacional y ambiental</strong> del entrenamiento a escala.</li>\n",
        "            <li>Dificultad de <strong>interpretabilidad</strong>, ya que actúan como “cajas negras”.</li>\n",
        "          </ol>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 7 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 6;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer7\">\n",
        "          <span class=\"qa-question-text\">7. En el ejemplo práctico del PDF, ¿por qué el modelo predice “azul” tras “El sol brilla intensamente en el cielo…”?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer7\" class=\"qa-answer-panel\">\n",
        "          <p>Porque tras ver millones de oraciones similares durante el pre-entrenamiento, el modelo ha aprendido una correlación estadística fuerte entre la frase y la palabra “azul”. No “sabe” que el cielo es azul como una verdad consciente, sino que <strong>internaliza la probabilidad</strong> de esa secuencia de tokens.</p>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 8 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 7;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer8\">\n",
        "          <span class=\"qa-question-text\">8. Define “<strong>prompt</strong>” y explica dos buenas prácticas de <strong>ingeniería de prompts</strong> para obtener mejores respuestas.</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer8\" class=\"qa-answer-panel\">\n",
        "          <p>Un prompt es el <strong>texto inicial o instrucción</strong> que se envía al LLM y determina el contexto, tono y formato de la salida.</p>\n",
        "          <p><strong>Buenas prácticas:</strong></p>\n",
        "          <ul>\n",
        "            <li>Ser <strong>específico y claro</strong>: indicar la tarea, el formato deseado y cualquier restricción (longitud, estilo).</li>\n",
        "            <li>Incluir <strong>ejemplos</strong> (few-shot) o un sistema-mensaje que defina el rol del modelo para reducir ambigüedad y mejorar la alineación con la intención.</li>\n",
        "          </ul>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 9 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 8;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer9\">\n",
        "          <span class=\"qa-question-text\">9. ¿Qué es la <strong>ventana de contexto</strong> y cómo limita el uso de un LLM?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer9\" class=\"qa-answer-panel\">\n",
        "          <p>Es el número máximo de tokens (entrada + salida) que el modelo puede procesar en un único paso.</p>\n",
        "          <ul>\n",
        "            <li>Si se supera, se debe truncar o resumir la conversación, lo que puede causar pérdida de información.</li>\n",
        "            <li>Ventanas más grandes incrementan el consumo de memoria y tiempo de inferencia.</li>\n",
        "          </ul>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "      <!-- Pregunta 10 -->\n",
        "      <div class=\"qa-item fade-in\" style=\"--item-index: 9;\">\n",
        "        <button class=\"qa-question-btn\" aria-expanded=\"false\" aria-controls=\"answer10\">\n",
        "          <span class=\"qa-question-text\">10. ¿Qué son los <strong>embeddings</strong> y cómo permiten realizar analogías vectoriales?</span>\n",
        "          <i class=\"fas fa-plus qa-toggle-icon\"></i>\n",
        "        </button>\n",
        "        <div id=\"answer10\" class=\"qa-answer-panel\">\n",
        "          <p>Los embeddings son vectores densos aprendidos que codifican información semántica y sintáctica sobre tokens.</p>\n",
        "          <ul>\n",
        "            <li>Tokens con significados similares aparecen <strong>cerca</strong> en el espacio latente.</li>\n",
        "            <li>La estructura geométrica posibilita analogías: la dirección “rey → reina” es similar a “hombre → mujer”.</li>\n",
        "          </ul>\n",
        "          <p>Esto surge porque el entrenamiento optimiza para predecir tokens en muchos contextos distintos, alineando gradualmente relaciones semánticas.</p>\n",
        "        </div>\n",
        "      </div>\n",
        "\n",
        "    </div> <!-- Fin de qaAccordion -->\n",
        "  </div> <!-- Fin de qa-container -->\n",
        "\n",
        "  <script>\n",
        "    (function() {\n",
        "        let qaCurrentSessionTheme = 'light';\n",
        "\n",
        "        function qaApplyInitialTheme() {\n",
        "            document.body.setAttribute('data-theme', qaCurrentSessionTheme);\n",
        "        }\n",
        "\n",
        "        function qaToggleTheme() {\n",
        "            const currentThemeFromBody = document.body.getAttribute('data-theme');\n",
        "            const newTheme = currentThemeFromBody === 'dark' ? 'light' : 'dark';\n",
        "            document.body.setAttribute('data-theme', newTheme);\n",
        "            qaCurrentSessionTheme = newTheme;\n",
        "        }\n",
        "\n",
        "        const qaThemeToggleButton = document.getElementById('qaThemeToggleButton');\n",
        "        if (qaThemeToggleButton) {\n",
        "            qaThemeToggleButton.addEventListener('click', qaToggleTheme);\n",
        "        }\n",
        "\n",
        "        const qaAccordion = document.getElementById('qaAccordion');\n",
        "        if (qaAccordion) {\n",
        "            const qaItems = qaAccordion.querySelectorAll('.qa-item');\n",
        "            qaItems.forEach((item, index) => {\n",
        "                item.style.setProperty('--item-index', index);\n",
        "                const btn = item.querySelector('.qa-question-btn');\n",
        "                const panel = item.querySelector('.qa-answer-panel');\n",
        "                const icon = btn.querySelector('.qa-toggle-icon');\n",
        "\n",
        "                if (btn && panel && icon) {\n",
        "                    btn.addEventListener('click', () => {\n",
        "                        const isExpanded = btn.getAttribute('aria-expanded') === 'true';\n",
        "\n",
        "                        // Opcional: cerrar otros paneles (descomentar para activar)\n",
        "                        /*\n",
        "                        if (!isExpanded) { // Solo si se va a expandir este\n",
        "                            qaItems.forEach(otherItem => {\n",
        "                                if (otherItem !== item) {\n",
        "                                    const otherBtn = otherItem.querySelector('.qa-question-btn');\n",
        "                                    const otherPanel = otherItem.querySelector('.qa-answer-panel');\n",
        "                                    const otherIcon = otherItem.querySelector('.qa-toggle-icon');\n",
        "                                    if (otherBtn.getAttribute('aria-expanded') === 'true') {\n",
        "                                        otherBtn.setAttribute('aria-expanded', 'false');\n",
        "                                        otherPanel.classList.remove('visible');\n",
        "                                        otherItem.classList.remove('expanded');\n",
        "                                        otherIcon.classList.remove('fa-minus');\n",
        "                                        otherIcon.classList.add('fa-plus');\n",
        "                                    }\n",
        "                                }\n",
        "                            });\n",
        "                        }\n",
        "                        */\n",
        "\n",
        "                        btn.setAttribute('aria-expanded', !isExpanded);\n",
        "                        panel.classList.toggle('visible');\n",
        "                        item.classList.toggle('expanded');\n",
        "\n",
        "                        if (!isExpanded) {\n",
        "                            icon.classList.remove('fa-plus');\n",
        "                            icon.classList.add('fa-minus');\n",
        "                        } else {\n",
        "                            icon.classList.remove('fa-minus');\n",
        "                            icon.classList.add('fa-plus');\n",
        "                        }\n",
        "                    });\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        qaApplyInitialTheme();\n",
        "    })();\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Mostrar el HTML en la salida de la celda\n",
        "display(HTML(html_content_qa))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}